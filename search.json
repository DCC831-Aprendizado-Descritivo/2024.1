[
  {
    "objectID": "seminario1/artigo2.html",
    "href": "seminario1/artigo2.html",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "O estudo e a an√°lise de s√©ries temporais desempenham um papel crucial em uma ampla gama de campos, desde o monitoramento do varejo at√© a detec√ß√£o de anomalias de seguran√ßa. Ao longo do tempo, observa√ß√µes cont√≠nuas capturam nuances e padr√µes que podem revelar insights valiosos sobre o comportamento de sistemas complexos. Neste contexto, a capacidade de agrupar s√©ries temporais com base em padr√µes similares torna-se fundamental para extrair conhecimento significativo.\n\n\nA motiva√ß√£o por tr√°s dessa abordagem √© multifacetada. No setor de varejo, por exemplo, a identifica√ß√£o de tend√™ncias locais de compra, como picos de vendas durante per√≠odos festivos, pode ser crucial para otimizar estrat√©gias de marketing e estoque. Da mesma forma, em an√°lises financeiras, compreender as tend√™ncias de mercado pode orientar decis√µes de investimento. Em setores como sa√∫de e biomedicina, a an√°lise de varia√ß√µes sazonais e padr√µes de sono pode contribuir para o desenvolvimento de tratamentos mais eficazes. Al√©m disso, o planejamento de recursos, a detec√ß√£o de anomalias de seguran√ßa e a an√°lise de dados ambientais e clim√°ticos tamb√©m se beneficiam significativamente da capacidade de identificar e compreender padr√µes em s√©ries temporais.\nNeste contexto, este artigo aborda a import√¢ncia da abordagem de agrupamento de s√©ries temporais, com foco no algoritmo Z-groupings. Exploraremos como esse m√©todo oferece uma perspectiva √∫nica para a identifica√ß√£o de grupos locais em s√©ries temporais, destacando sua relev√¢ncia e aplicabilidade em diversas √°reas de estudo e pr√°tica. Ao compreendermos melhor as nuances e potenciais aplica√ß√µes do Z-groupings, podemos abrir novas oportunidades para an√°lises mais precisas e insights mais profundos em uma variedade de dom√≠nios.\n\n\n\nO algoritmo Z-groupings n√£o possui comparativos diretos. No entanto, existem alguns m√©todos cl√°ssicos que realizam tarefas compar√°veis:\n\nK-means: Este m√©todo particiona s√©ries temporais em k clusters, onde os clusters representam grupos locais an√°logos aos encontrados pelo Z-groupings.\nAgrupamento Hier√°rquico: Neste m√©todo, as s√©ries temporais s√£o hierarquicamente divididas com base em uma m√©trica de similaridade. Os grupos resultantes s√£o compar√°veis aos grupos locais identificados pelo Z-groupings.\n\nContudo, √© importante ressaltar que esses algoritmos n√£o s√£o diretamente compar√°veis, pois se limitam a encontrar similaridades dentro de uma √∫nica s√©rie temporal, n√£o considerando rela√ß√µes entre diferentes s√©ries.\nJ√° em rela√ß√£o aos algoritmos de minera√ß√£o de sequ√™ncias, fica evidente que ambos compartilham diversas caracter√≠sticas fundamentais. Ambos os m√©todos t√™m a capacidade de identificar padr√µes sequenciais em conjuntos de dados, baseando-se na frequ√™ncia de ocorr√™ncia desses padr√µes. Al√©m disso, ambos utilizam o conceito de suporte para filtrar padr√µes menos frequentes, priorizando aqueles que s√£o mais relevantes para a an√°lise.\nEntretanto, ao analisar as diferen√ßas entre o Z-groupings e seus equivalentes na minera√ß√£o de sequ√™ncia, destacam-se aspectos distintivos que delineiam a aplica√ß√£o espec√≠fica do Z-groupings em contextos de s√©ries temporais. Enquanto muitos algoritmos de minera√ß√£o de sequ√™ncia s√£o aplic√°veis a diversos tipos de dados, o Z-groupings √© especialmente projetado para lidar com s√©ries temporais. Sua funcionalidade principal reside na capacidade de agrupar sequ√™ncias temporais em grupos locais, visando identificar associa√ß√µes significativas entre os padr√µes temporais presentes nos dados. Essa abordagem mais focalizada confere ao Z-groupings uma vantagem significativa em cen√°rios onde a compreens√£o das rela√ß√µes temporais √© crucial para a an√°lise e interpreta√ß√£o dos dados.\nEssas nuances ressaltam a import√¢ncia do Z-groupings como uma ferramenta especializada e eficaz para a an√°lise de s√©ries temporais, oferecendo insights valiosos e facilitando a descoberta de padr√µes e associa√ß√µes relevantes nos dados.\n\n\n\nSer√£o examinados tr√™s casos espec√≠ficos que destacam a versatilidade e utilidade do Z-groupings: o agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias, a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento usando agrupamento de s√©ries temporais, e a an√°lise de consumo de medicamentos para otimiza√ß√£o da log√≠stica de distribui√ß√£o. Cada uma dessas aplica√ß√µes oferece uma perspectiva √∫nica sobre como o Z-groupings pode ser empregado para abordar desafios complexos e promover impactos significativos em diversos setores.\n\n\nO agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias √© uma aplica√ß√£o-chave das redes inteligentes, impulsionadas pela converg√™ncia de sistemas computacionais, de medi√ß√£o e de comunica√ß√£o. Os medidores inteligentes, respons√°veis por capturar e transmitir dados de consumo em intervalos regulares, geram uma quantidade substancial de informa√ß√µes. A an√°lise desses dados, conhecida como agrupamento de curvas de carga, √© essencial para extrair insights relevantes. Neste contexto, o Z-groupings e outros algoritmos semelhantes emergem como ferramentas valiosas.\nAs implica√ß√µes dessa aplica√ß√£o s√£o diversas:\n\nPrevis√£o de demanda de energia: Identificar padr√µes de consumo semelhantes entre diferentes regi√µes possibilita prever com mais precis√£o a demanda futura de energia. Isso facilita o planejamento da produ√ß√£o e distribui√ß√£o de eletricidade pelas empresas de energia.\nDetec√ß√£o de anomalias: Ao conhecer os padr√µes de consumo t√≠picos, torna-se mais f√°cil detectar anomalias que possam indicar falhas nos equipamentos, problemas de efici√™ncia energ√©tica ou atividades suspeitas, como roubo de energia.\nPotencial para discrimina√ß√£o: O uso das informa√ß√µes sobre padr√µes de consumo para segmentar clientes ou estabelecer tarifas diferenciadas pode levar √† discrimina√ß√£o. Alguns grupos demogr√°ficos podem ser penalizados ou exclu√≠dos, aumentando as desigualdades.\nRisco de monop√≥lio: Empresas de distribui√ß√£o de energia com acesso a recursos computacionais avan√ßados para an√°lise de dados t√™m uma vantagem competitiva significativa. Isso pode resultar em um desequil√≠brio de mercado, com grandes empresas dominando e marginalizando empresas menores.\n\nEssas consequ√™ncias ressaltam a import√¢ncia n√£o apenas da aplica√ß√£o eficaz de algoritmos de agrupamento de s√©ries temporais, como o Z-groupings, mas tamb√©m da considera√ß√£o cuidadosa dos impactos sociais e √©ticos das decis√µes baseadas em dados no setor de energia el√©trica.\n\n\n\nA an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia, por meio do agrupamento de s√©ries temporais, destaca-se como uma aplica√ß√£o vital dessa t√©cnica anal√≠tica. Ao examinar as mudan√ßas no √≠ndice de cobertura vegetal ao longo do tempo, √© poss√≠vel identificar padr√µes e tend√™ncias cruciais para o monitoramento e preven√ß√£o do desmatamento, bem como para o planejamento estrat√©gico de pol√≠ticas de conserva√ß√£o.\nAs consequ√™ncias potenciais desse enfoque s√£o variadas:\n\nMonitoramento e preven√ß√£o eficazes do desmatamento: O uso do agrupamento de s√©ries temporais pode melhorar substancialmente as estrat√©gias de preven√ß√£o do desmatamento, identificando √°reas em risco e facilitando interven√ß√µes preventivas.\nPlanejamento de pol√≠ticas de conserva√ß√£o: A identifica√ß√£o de √°reas com alto risco de desmatamento possibilita o direcionamento eficiente de recursos e esfor√ßos para medidas preventivas, como programas de educa√ß√£o ambiental e refor√ßo da fiscaliza√ß√£o.\nRiscos √† privacidade: O monitoramento detalhado pode levantar preocupa√ß√µes de privacidade, revelando informa√ß√µes sens√≠veis sobre padr√µes de vida e comportamentos das comunidades locais.\nDesigualdade e discrimina√ß√£o: Restri√ß√µes ao uso da terra e acesso limitado √†s ferramentas de an√°lise podem resultar em desigualdades na distribui√ß√£o de recursos para a conserva√ß√£o.\nImpacto nos meios de subsist√™ncia locais: As pol√≠ticas de conserva√ß√£o devem considerar os impactos nas comunidades locais, garantindo que sejam justas e equitativas.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem √©tica e abrangente no uso do agrupamento de s√©ries temporais para a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia.\n\n\n\nA aplica√ß√£o do m√©todo Z-Grouping na an√°lise do consumo e distribui√ß√£o de medicamentos apresenta uma oportunidade significativa para aprimorar a gest√£o de recursos farmac√™uticos, especialmente sob a perspectiva da sa√∫de p√∫blica, com foco na atua√ß√£o da Ag√™ncia Nacional de Vigil√¢ncia Sanit√°ria (ANVISA). Ao identificar padr√µes temporais e regionais no uso de medicamentos, essa abordagem oferece insights valiosos para interven√ß√µes estrat√©gicas na log√≠stica de distribui√ß√£o.\nAs aplica√ß√µes pr√°ticas dessa an√°lise s√£o amplas:\n\nRefinamento da Log√≠stica de Distribui√ß√£o: A identifica√ß√£o de agrupamentos locais de consumo permite ajustes precisos na cadeia de suprimentos, garantindo a disponibilidade adequada de medicamentos essenciais nas regi√µes com maior demanda, o que √© crucial para garantir a continuidade dos tratamentos, especialmente em contextos de doen√ßas cr√¥nicas ou surtos de doen√ßas infecciosas.\nProje√ß√£o de Demandas Futuras: O Z-Grouping possibilita a proje√ß√£o de demandas com base em tend√™ncias hist√≥ricas, permitindo a antecipa√ß√£o de necessidades, como vacinas ou medicamentos antivirais. Essa capacidade preditiva √© fundamental para evitar escassez ou excesso de estoques, possibilitando uma resposta eficiente √†s flutua√ß√µes do mercado e demandas emergentes.\nDiagn√≥stico de Desperd√≠cios e Inefici√™ncias: Al√©m disso, essa abordagem revela padr√µes de subutiliza√ß√£o ou desperd√≠cio de medicamentos, indicando √°reas potenciais para otimiza√ß√£o das pol√≠ticas de distribui√ß√£o e uso racional de recursos farmac√™uticos.\n\nEntretanto, a implementa√ß√£o dessas an√°lises n√£o est√° isenta de desafios e consequ√™ncias, como:\n\nIntegridade e Seguran√ßa dos Dados: A gest√£o cuidadosa da integridade e seguran√ßa dos dados √© essencial para prevenir riscos de comprometimento das an√°lises, garantindo o cumprimento das normativas de prote√ß√£o de dados, como a LGPD.\nJusti√ßa na Distribui√ß√£o de Medicamentos: H√° o risco de que an√°lises baseadas em dados n√£o reflitam com precis√£o a distribui√ß√£o demogr√°fica, resultando em aloca√ß√µes de recursos que perpetuam desequil√≠brios existentes. Portanto, √© crucial que as decis√µes de pol√≠tica farmac√™utica considerem profundamente as necessidades locais.\nRiscos da Depend√™ncia de Modelos Quantitativos: Apesar da robustez do Z-Grouping, sua aplica√ß√£o deve ser complementada por an√°lises qualitativas e conhecimento especializado em sa√∫de p√∫blica para evitar decis√µes que n√£o considerem a complexidade dos padr√µes de sa√∫de espec√≠ficos.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem hol√≠stica e cuidadosa na utiliza√ß√£o do Z-Grouping para an√°lise de consumo de medicamentos e sua distribui√ß√£o, visando garantir benef√≠cios significativos sem comprometer a integridade dos dados ou perpetuar desigualdades existentes."
  },
  {
    "objectID": "seminario1/artigo2.html#contextualiza√ß√£o-do-problema",
    "href": "seminario1/artigo2.html#contextualiza√ß√£o-do-problema",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "A motiva√ß√£o por tr√°s dessa abordagem √© multifacetada. No setor de varejo, por exemplo, a identifica√ß√£o de tend√™ncias locais de compra, como picos de vendas durante per√≠odos festivos, pode ser crucial para otimizar estrat√©gias de marketing e estoque. Da mesma forma, em an√°lises financeiras, compreender as tend√™ncias de mercado pode orientar decis√µes de investimento. Em setores como sa√∫de e biomedicina, a an√°lise de varia√ß√µes sazonais e padr√µes de sono pode contribuir para o desenvolvimento de tratamentos mais eficazes. Al√©m disso, o planejamento de recursos, a detec√ß√£o de anomalias de seguran√ßa e a an√°lise de dados ambientais e clim√°ticos tamb√©m se beneficiam significativamente da capacidade de identificar e compreender padr√µes em s√©ries temporais.\nNeste contexto, este artigo aborda a import√¢ncia da abordagem de agrupamento de s√©ries temporais, com foco no algoritmo Z-groupings. Exploraremos como esse m√©todo oferece uma perspectiva √∫nica para a identifica√ß√£o de grupos locais em s√©ries temporais, destacando sua relev√¢ncia e aplicabilidade em diversas √°reas de estudo e pr√°tica. Ao compreendermos melhor as nuances e potenciais aplica√ß√µes do Z-groupings, podemos abrir novas oportunidades para an√°lises mais precisas e insights mais profundos em uma variedade de dom√≠nios."
  },
  {
    "objectID": "seminario1/artigo2.html#relacionamento-com-m√©todos-cl√°ssicos",
    "href": "seminario1/artigo2.html#relacionamento-com-m√©todos-cl√°ssicos",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "O algoritmo Z-groupings n√£o possui comparativos diretos. No entanto, existem alguns m√©todos cl√°ssicos que realizam tarefas compar√°veis:\n\nK-means: Este m√©todo particiona s√©ries temporais em k clusters, onde os clusters representam grupos locais an√°logos aos encontrados pelo Z-groupings.\nAgrupamento Hier√°rquico: Neste m√©todo, as s√©ries temporais s√£o hierarquicamente divididas com base em uma m√©trica de similaridade. Os grupos resultantes s√£o compar√°veis aos grupos locais identificados pelo Z-groupings.\n\nContudo, √© importante ressaltar que esses algoritmos n√£o s√£o diretamente compar√°veis, pois se limitam a encontrar similaridades dentro de uma √∫nica s√©rie temporal, n√£o considerando rela√ß√µes entre diferentes s√©ries.\nJ√° em rela√ß√£o aos algoritmos de minera√ß√£o de sequ√™ncias, fica evidente que ambos compartilham diversas caracter√≠sticas fundamentais. Ambos os m√©todos t√™m a capacidade de identificar padr√µes sequenciais em conjuntos de dados, baseando-se na frequ√™ncia de ocorr√™ncia desses padr√µes. Al√©m disso, ambos utilizam o conceito de suporte para filtrar padr√µes menos frequentes, priorizando aqueles que s√£o mais relevantes para a an√°lise.\nEntretanto, ao analisar as diferen√ßas entre o Z-groupings e seus equivalentes na minera√ß√£o de sequ√™ncia, destacam-se aspectos distintivos que delineiam a aplica√ß√£o espec√≠fica do Z-groupings em contextos de s√©ries temporais. Enquanto muitos algoritmos de minera√ß√£o de sequ√™ncia s√£o aplic√°veis a diversos tipos de dados, o Z-groupings √© especialmente projetado para lidar com s√©ries temporais. Sua funcionalidade principal reside na capacidade de agrupar sequ√™ncias temporais em grupos locais, visando identificar associa√ß√µes significativas entre os padr√µes temporais presentes nos dados. Essa abordagem mais focalizada confere ao Z-groupings uma vantagem significativa em cen√°rios onde a compreens√£o das rela√ß√µes temporais √© crucial para a an√°lise e interpreta√ß√£o dos dados.\nEssas nuances ressaltam a import√¢ncia do Z-groupings como uma ferramenta especializada e eficaz para a an√°lise de s√©ries temporais, oferecendo insights valiosos e facilitando a descoberta de padr√µes e associa√ß√µes relevantes nos dados."
  },
  {
    "objectID": "seminario1/artigo2.html#impacto-social-e-potenciais-aplica√ß√µes",
    "href": "seminario1/artigo2.html#impacto-social-e-potenciais-aplica√ß√µes",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "Ser√£o examinados tr√™s casos espec√≠ficos que destacam a versatilidade e utilidade do Z-groupings: o agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias, a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento usando agrupamento de s√©ries temporais, e a an√°lise de consumo de medicamentos para otimiza√ß√£o da log√≠stica de distribui√ß√£o. Cada uma dessas aplica√ß√µes oferece uma perspectiva √∫nica sobre como o Z-groupings pode ser empregado para abordar desafios complexos e promover impactos significativos em diversos setores.\n\n\nO agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias √© uma aplica√ß√£o-chave das redes inteligentes, impulsionadas pela converg√™ncia de sistemas computacionais, de medi√ß√£o e de comunica√ß√£o. Os medidores inteligentes, respons√°veis por capturar e transmitir dados de consumo em intervalos regulares, geram uma quantidade substancial de informa√ß√µes. A an√°lise desses dados, conhecida como agrupamento de curvas de carga, √© essencial para extrair insights relevantes. Neste contexto, o Z-groupings e outros algoritmos semelhantes emergem como ferramentas valiosas.\nAs implica√ß√µes dessa aplica√ß√£o s√£o diversas:\n\nPrevis√£o de demanda de energia: Identificar padr√µes de consumo semelhantes entre diferentes regi√µes possibilita prever com mais precis√£o a demanda futura de energia. Isso facilita o planejamento da produ√ß√£o e distribui√ß√£o de eletricidade pelas empresas de energia.\nDetec√ß√£o de anomalias: Ao conhecer os padr√µes de consumo t√≠picos, torna-se mais f√°cil detectar anomalias que possam indicar falhas nos equipamentos, problemas de efici√™ncia energ√©tica ou atividades suspeitas, como roubo de energia.\nPotencial para discrimina√ß√£o: O uso das informa√ß√µes sobre padr√µes de consumo para segmentar clientes ou estabelecer tarifas diferenciadas pode levar √† discrimina√ß√£o. Alguns grupos demogr√°ficos podem ser penalizados ou exclu√≠dos, aumentando as desigualdades.\nRisco de monop√≥lio: Empresas de distribui√ß√£o de energia com acesso a recursos computacionais avan√ßados para an√°lise de dados t√™m uma vantagem competitiva significativa. Isso pode resultar em um desequil√≠brio de mercado, com grandes empresas dominando e marginalizando empresas menores.\n\nEssas consequ√™ncias ressaltam a import√¢ncia n√£o apenas da aplica√ß√£o eficaz de algoritmos de agrupamento de s√©ries temporais, como o Z-groupings, mas tamb√©m da considera√ß√£o cuidadosa dos impactos sociais e √©ticos das decis√µes baseadas em dados no setor de energia el√©trica.\n\n\n\nA an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia, por meio do agrupamento de s√©ries temporais, destaca-se como uma aplica√ß√£o vital dessa t√©cnica anal√≠tica. Ao examinar as mudan√ßas no √≠ndice de cobertura vegetal ao longo do tempo, √© poss√≠vel identificar padr√µes e tend√™ncias cruciais para o monitoramento e preven√ß√£o do desmatamento, bem como para o planejamento estrat√©gico de pol√≠ticas de conserva√ß√£o.\nAs consequ√™ncias potenciais desse enfoque s√£o variadas:\n\nMonitoramento e preven√ß√£o eficazes do desmatamento: O uso do agrupamento de s√©ries temporais pode melhorar substancialmente as estrat√©gias de preven√ß√£o do desmatamento, identificando √°reas em risco e facilitando interven√ß√µes preventivas.\nPlanejamento de pol√≠ticas de conserva√ß√£o: A identifica√ß√£o de √°reas com alto risco de desmatamento possibilita o direcionamento eficiente de recursos e esfor√ßos para medidas preventivas, como programas de educa√ß√£o ambiental e refor√ßo da fiscaliza√ß√£o.\nRiscos √† privacidade: O monitoramento detalhado pode levantar preocupa√ß√µes de privacidade, revelando informa√ß√µes sens√≠veis sobre padr√µes de vida e comportamentos das comunidades locais.\nDesigualdade e discrimina√ß√£o: Restri√ß√µes ao uso da terra e acesso limitado √†s ferramentas de an√°lise podem resultar em desigualdades na distribui√ß√£o de recursos para a conserva√ß√£o.\nImpacto nos meios de subsist√™ncia locais: As pol√≠ticas de conserva√ß√£o devem considerar os impactos nas comunidades locais, garantindo que sejam justas e equitativas.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem √©tica e abrangente no uso do agrupamento de s√©ries temporais para a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia.\n\n\n\nA aplica√ß√£o do m√©todo Z-Grouping na an√°lise do consumo e distribui√ß√£o de medicamentos apresenta uma oportunidade significativa para aprimorar a gest√£o de recursos farmac√™uticos, especialmente sob a perspectiva da sa√∫de p√∫blica, com foco na atua√ß√£o da Ag√™ncia Nacional de Vigil√¢ncia Sanit√°ria (ANVISA). Ao identificar padr√µes temporais e regionais no uso de medicamentos, essa abordagem oferece insights valiosos para interven√ß√µes estrat√©gicas na log√≠stica de distribui√ß√£o.\nAs aplica√ß√µes pr√°ticas dessa an√°lise s√£o amplas:\n\nRefinamento da Log√≠stica de Distribui√ß√£o: A identifica√ß√£o de agrupamentos locais de consumo permite ajustes precisos na cadeia de suprimentos, garantindo a disponibilidade adequada de medicamentos essenciais nas regi√µes com maior demanda, o que √© crucial para garantir a continuidade dos tratamentos, especialmente em contextos de doen√ßas cr√¥nicas ou surtos de doen√ßas infecciosas.\nProje√ß√£o de Demandas Futuras: O Z-Grouping possibilita a proje√ß√£o de demandas com base em tend√™ncias hist√≥ricas, permitindo a antecipa√ß√£o de necessidades, como vacinas ou medicamentos antivirais. Essa capacidade preditiva √© fundamental para evitar escassez ou excesso de estoques, possibilitando uma resposta eficiente √†s flutua√ß√µes do mercado e demandas emergentes.\nDiagn√≥stico de Desperd√≠cios e Inefici√™ncias: Al√©m disso, essa abordagem revela padr√µes de subutiliza√ß√£o ou desperd√≠cio de medicamentos, indicando √°reas potenciais para otimiza√ß√£o das pol√≠ticas de distribui√ß√£o e uso racional de recursos farmac√™uticos.\n\nEntretanto, a implementa√ß√£o dessas an√°lises n√£o est√° isenta de desafios e consequ√™ncias, como:\n\nIntegridade e Seguran√ßa dos Dados: A gest√£o cuidadosa da integridade e seguran√ßa dos dados √© essencial para prevenir riscos de comprometimento das an√°lises, garantindo o cumprimento das normativas de prote√ß√£o de dados, como a LGPD.\nJusti√ßa na Distribui√ß√£o de Medicamentos: H√° o risco de que an√°lises baseadas em dados n√£o reflitam com precis√£o a distribui√ß√£o demogr√°fica, resultando em aloca√ß√µes de recursos que perpetuam desequil√≠brios existentes. Portanto, √© crucial que as decis√µes de pol√≠tica farmac√™utica considerem profundamente as necessidades locais.\nRiscos da Depend√™ncia de Modelos Quantitativos: Apesar da robustez do Z-Grouping, sua aplica√ß√£o deve ser complementada por an√°lises qualitativas e conhecimento especializado em sa√∫de p√∫blica para evitar decis√µes que n√£o considerem a complexidade dos padr√µes de sa√∫de espec√≠ficos.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem hol√≠stica e cuidadosa na utiliza√ß√£o do Z-Grouping para an√°lise de consumo de medicamentos e sua distribui√ß√£o, visando garantir benef√≠cios significativos sem comprometer a integridade dos dados ou perpetuar desigualdades existentes."
  },
  {
    "objectID": "seminario1/artigo2.html#conceitos-chave",
    "href": "seminario1/artigo2.html#conceitos-chave",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.1 Conceitos Chave",
    "text": "2.1 Conceitos Chave\nPara compreender o algoritmo Z-Grouping, √© fundamental dominar alguns conceitos fundamentais.\n\n\nCode\nfrom zgrouping.zgrouping import grouping, syntheticGenerator, utils\nimport matplotlib.pyplot as plt\n\n\n\nS√©ries Temporais: Uma s√©rie temporal consiste em observa√ß√µes coletadas sequencialmente ao longo do tempo. Cada observa√ß√£o est√° vinculada a um instante espec√≠fico, sendo a ordem das observa√ß√µes de crucial import√¢ncia. Exemplo: Uma s√©rie temporal pode registrar as vendas di√°rias de um produto ao longo de um per√≠odo, como as vendas di√°rias de um modelo de smartphone em uma loja.\n\n\n\nCode\ntc = 50\ntl = 365\nc = 20\nno_outliers = 10\noutlier_size = 10\n\n# GROUPING GENERATION\nn_bins = 5\nalpha = 0.9\neta = 1.5\n\nX_raw, y = syntheticGenerator.createSyntheticData(tc = tc, tl=tl, c = c, no_outliers = no_outliers, outlier_size=outlier_size)\nplt.plot(X_raw[0])\n\n\n\n\n\n\n\n\n\n\nAbstra√ß√£o Temporal: A abstra√ß√£o temporal √© o processo de simplificar ou extrair caracter√≠sticas mais significativas de uma s√©rie temporal, facilitando sua an√°lise. Exemplo: A aplica√ß√£o do Symbolic Aggregate Approximation (SAX) para converter uma s√©rie temporal de vendas di√°rias em uma sequ√™ncia de s√≠mbolos que representam padr√µes de vendas ao longo do tempo.\nEventos em S√©ries Temporais: Um evento em uma s√©rie temporal √© uma ocorr√™ncia distinta ou uma caracter√≠stica identific√°vel nos dados ao longo do tempo, como picos, vales, transi√ß√µes ou padr√µes recorrentes.\nR√≥tulos de Eventos: Os r√≥tulos de eventos s√£o atributos simb√≥licos ou categoriza√ß√µes aplicadas aos eventos em uma s√©rie temporal para represent√°-los de maneira simplificada e compreens√≠vel. Exemplo: Os r√≥tulos podem ser escolhidos de um conjunto discreto de s√≠mbolos ou categorias, como letras, n√∫meros ou outros identificadores simb√≥licos.\nMatriz de Sequ√™ncia de Eventos: Uma matriz que representa a sequ√™ncia de r√≥tulos de eventos derivados das s√©ries temporais ap√≥s a abstra√ß√£o temporal. Cada entrada na matriz representa um evento em uma s√©rie temporal espec√≠fica.\nAgrupamento Local: O agrupamento local refere-se √† identifica√ß√£o de subconjuntos de s√©ries temporais que exibem padr√µes semelhantes em intervalos espec√≠ficos de tempo. No contexto do Z-Grouping, os agrupamentos locais s√£o identificados em cada canal de r√≥tulo de evento.\nAssocia√ß√£o de Agrupamentos Locais: Associa√ß√µes s√£o identificadas entre agrupamentos locais consecutivos ou sobrepostos que compartilham inst√¢ncias de s√©ries temporais semelhantes. O objetivo √© descobrir padr√µes mais amplos e complexos que n√£o seriam detectados apenas nos agrupamentos locais individuais.\nSemigeometric Tiling: Um algoritmo utilizado para identificar padr√µes ou agrupamentos em matrizes bin√°rias, considerando combina√ß√µes de intervalos de tempo e contagens de eventos.\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)\n\n\n\nMatriz de Associa√ß√£o e Valida√ß√£o: Uma representa√ß√£o matricial usada para identificar e validar associa√ß√µes entre agrupamentos locais. Essa matriz registra as rela√ß√µes entre os agrupamentos locais e os agrupamentos globais pr√©-definidos.\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)"
  },
  {
    "objectID": "seminario1/artigo2.html#apresenta√ß√£o-do-algoritmo",
    "href": "seminario1/artigo2.html#apresenta√ß√£o-do-algoritmo",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.2 Apresenta√ß√£o do Algoritmo",
    "text": "2.2 Apresenta√ß√£o do Algoritmo\nO algoritmo Z-Grouping √© composto por quatro passos distintos, cada um focado em uma etapa espec√≠fica do processo de an√°lise de s√©ries temporais. S√£o eles:\n\nGera√ß√£o da Matriz de Sequ√™ncia de Eventos\nNeste passo, uma cole√ß√£o de s√©ries temporais √© convertida em uma matriz de eventos, utilizando t√©cnicas de abstra√ß√£o temporal como o m√©todo SAX. Isso permite uma representa√ß√£o mais simplificada dos dados, facilitando a an√°lise subsequente.\n\n\n\nCode\nX = utils.znorm(X_raw)\nX_sax = utils.SAXify(X, n_bins = 5)\nX_sax[0]\n\n\narray([2, 2, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\n\nCode\nplt.plot(X_raw[0])\nplt.plot(X_sax[0])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCria√ß√£o de canais de r√≥tulos\nA matriz de eventos em seguida √© subdividida em uma matriz bin√°ria de mesmo tamanho para cada r√≥tulo\n\n\n\nCode\nmatrices = utils.createChannels(X_sax)\nmatrices[0]\n\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)\n\n\n\nGera√ß√£o de Agrupamentos Locais\nO pr√≥ximo passo envolve a identifica√ß√£o de agrupamentos locais em cada canal de r√≥tulo de evento da matriz de eventos. Esse processo √© conduzido pelo algoritmo de semigeometric tiling, que busca candidatos a agrupamentos locais com base na contagem de eventos em intervalos de tempo espec√≠ficos. Al√©m disso, o algoritmo utiliza um par√¢metro ùù∞, variando de 0 a 1, para determinar a pureza de um agrupamento local. Por exemplo, ao definir ùù∞ como 0.75, estamos estabelecendo que pelo menos 75% dos elementos do agrupamento devem conter o evento analisado.\nIdentifica√ß√£o de Associa√ß√µes entre Agrupamentos Locais\nNesta etapa, o algoritmo procura associa√ß√µes entre os agrupamentos locais identificados. Isso √© feito atrav√©s da an√°lise de candidatos a associa√ß√µes consecutivas, verificando a proximidade entre elas e identificando inst√¢ncias de s√©ries temporais compartilhadas.\nValida√ß√£o dos Agrupamentos Locais\nPor fim, os agrupamentos locais s√£o validados em rela√ß√£o aos agrupamentos globais pr√©-definidos. Isso √© feito calculando uma pontua√ß√£o de validade com base na propor√ß√£o de inst√¢ncias de s√©ries temporais em comum e utilizando um par√¢metro de densidade para controlar a validade dos agrupamentos locais.\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)\n\n\n\n\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)\n\n\n\n\nFigure¬†1: Um exemplo dos quatro passos do Z-grouping"
  },
  {
    "objectID": "seminario1/artigo2.html#metodologia-experimental",
    "href": "seminario1/artigo2.html#metodologia-experimental",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.3 Metodologia Experimental",
    "text": "2.3 Metodologia Experimental\nA metodologia experimental da pesquisa visa avaliar o desempenho do m√©todo Z-Grouping na identifica√ß√£o de agrupamentos locais em s√©ries temporais. Para isso, foi utilizada uma abordagem abrangente que inclui a an√°lise de conjuntos de dados reais de diferentes setores, bem como um conjunto de dados sint√©tico para investiga√ß√£o detalhada dos par√¢metros do m√©todo. Al√©m disso, alguns m√©todos foram adaptados para efeitos de compara√ß√£o. Abaixo, √© fornecida uma descri√ß√£o mais detalhada da metodologia utilizada.\n\nDatasets: Os conjuntos de dados reais utilizados abrangem tr√™s setores diferentes: ind√∫stria de varejo, mercado de a√ß√µes e epidemias de COVID-19. Al√©m disso, um conjunto de dados sint√©tico foi gerado para investiga√ß√£o detalhada dos par√¢metros do m√©todo. Este conjunto de dados sint√©tico simula a presen√ßa de similaridade local em meio a padr√µes sinusoidais com diferentes frequ√™ncias e amplitudes, al√©m de incorporar ru√≠do e outliers para refletir cen√°rios do mundo real.\nConcorrentes: Como n√£o existe um concorrente direto para o problema, foram feitas adapta√ß√µes nos m√©todos semigeometric tiling, kmeans, kmeans-FLEX e kNN para identificar agrupamentos locais em s√©ries temporais.\nProtocolo do Experimento: Para avaliar o desempenho do m√©todo Z-Grouping, foi desenvolvido um protocolo de experimento que envolve a divis√£o dos dados em conjuntos de treinamento e teste. Durante a fase de treinamento, os agrupamentos locais s√£o identificados nos dados de treinamento. Na fase de teste, o objetivo √© determinar se os agrupamentos identificados podem identificar padr√µes de similaridade local em novas inst√¢ncias n√£o vistas. Para cada amostra de teste, o agrupamento global correspondente √© usado como refer√™ncia. Isso simula situa√ß√µes do mundo real, como identificar padr√µes de vendas de um novo produto com base em produtos existentes.\nM√©tricas de Avalia√ß√£o: Os resultados s√£o avaliados em termos de erros de predi√ß√£o, como erro quadr√°tico m√©dio (MSE) e erro absoluto m√©dio (MAE), bem como a cobertura dos agrupamentos, ou seja, a fra√ß√£o de s√©ries temporais cobertas pelos agrupamentos identificados."
  },
  {
    "objectID": "seminario1/artigo2.html#an√°lise-cr√≠tica-dos-resultados",
    "href": "seminario1/artigo2.html#an√°lise-cr√≠tica-dos-resultados",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.4 An√°lise Cr√≠tica dos Resultados",
    "text": "2.4 An√°lise Cr√≠tica dos Resultados\nEm rela√ß√£o aos resultados alcan√ßados, todos foram validados 10 vezes, e os seguintes par√¢metros foram utilizados:\nŒ±: Este √© um par√¢metro que controla o n√≠vel de ‚Äúpureza‚Äù dos agrupamentos.\nŒª: Este par√¢metro controla o n√∫mero de r√≥tulos de abstra√ß√£o que o algoritmo pode usar.\nŒ∑: Este par√¢metro define o n√∫mero m√≠nimo de amostras necess√°rias para que um agrupamento seja considerado v√°lido.\nw: Este √© o intervalo de tempo (em n√∫mero de amostras) que esses algoritmos usam para identificar os agrupamentos locais.\nk: Este √© o n√∫mero de agrupamentos (clusters) que esses algoritmos tentam formar.\nCorte de silhueta: Este √© um par√¢metro que define um valor de corte para a m√©trica de silhueta.\nOs algoritmos testados utilizaram os seguintes par√¢metros:\nZ-Grouping: Œ± = {0.8, 0.9, 1}, Œª = {3, 5, 10}, e Œ∑ = {1, 1.5, 2}.\nSemigeometric: Œ± = {0.8, 0.9, 1}, e Œ∑ = {1, 1.5, 2}.\nkmeans: intervalo de tempo w = {30, 60, 180} e k = {3, 5, 10}.\nkNN: intervalo de tempo w = {30, 60, 180} e k = {3, 5, 10}.\nkmeans-FLEX: corte de silhueta de 0,1 at√© falha em detectar quaisquer agrupamentos v√°lidos.\nEm rela√ß√£o aos resultados no conjunto de dados sint√©ticos, pode-se analisar atrav√©s da tabela 2 os erros de teste m√©dios do Z-Grouping e seus quatro competidores. Atrav√©s dela podemos chegar a algumas conclus√µes em rela√ß√£o ao Z-Grouping e seus concorrentes:\n\nO Z-Grouping sempre consegue encontrar agrupamentos locais v√°lidos de baixos erros considerando MSE e MAE;\nSemigeometric sofre com sua falta de poder de representa√ß√£o com uma forte suposi√ß√£o bin√°ria superado pelo Z-Grouping em rela√ß√£o aos agrupamentos locais;\nkNN atinge seu melhor escore com {w: 180, k: 3};\nkmeans n√£o mostra diferen√ßas not√°veis com v√°rias configura√ß√µes de par√¢metros, e √© geralmente pior do que seus concorrentes;\nKmeans-FLEX tem seu menor MSE sendo apenas 3,4% menor que o menor erro do kmeans;\nO Semigeometric, kmeans, kNN e kmeans-FLEX s√£o piores do que o Z-Grouping em todas as situa√ß√µes.\n\nAl√©m disso, utilizando os dados de UCR o Z-Grouping apresentou dificuldade para encontrar padr√µes para o agrupamento, performando de forma semelhante aos competidores devido a perda de informa√ß√£o pelo SAX em conjuntos mais uniformes.\nJ√° em rela√ß√£o aos resultados no conjunto de dados reais, com os dados de GARMENT e STOCK o Z-Grouping apresentou resultados com diferen√ßa de 44.3% (MSE) e 25.2% (MAE) com cobertura de 88% dos dados, sendo superior aos competidores. E com os dados da COVID pode-se perceber que o trade-off de minimiza√ß√£o do erro por perda de cobertura acabou levando o algoritmo a desempenhar com pouca melhora, sacrificando bastante da cobertura, cobrindo apenas 40% dos dados.\nPor fim, ao analisarmos o efeito dos par√¢metros, um Œª maior pode levar a uma menor cobertura, um Œ± maior leva a agrupamentos mais puros o que permite um n√∫mero menor de r√≥tulos de evento diferentes, e um Œ∑ maior exige mais amostras no agrupamento local para validade resultando em menos agrupamentos. Os par√¢metros mais altos fazem com que o algoritmo perca sua capacidade de crescer mostrando aproximadamente s√≥ 10% de cobertura, al√©m de gerar erros mais altos devido √† aus√™ncia de pontos de dados para compara√ß√£o. Por isso as associa√ß√µes dos agrupamentos s√£o utilizadas para aumentar a cobertura preenchendo as lacunas criadas pelos altos valores dos par√¢metros.\n\n\n\nTable¬†1: Erros m√©dios de teste dos algoritmos no banco de dados Sint√©tico (CV: Covarege(%))\n\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)"
  },
  {
    "objectID": "seminario1/artigo2.html#sum√°rio-dos-resultados",
    "href": "seminario1/artigo2.html#sum√°rio-dos-resultados",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "3.1 Sum√°rio dos Resultados",
    "text": "3.1 Sum√°rio dos Resultados\nO Z-Grouping foi testado contra quatro solu√ß√µes alternativas para o problema de agrupamentos locais, baseadas em adapta√ß√µes para o problema espec√≠fico proposto no artigo de abordagens utilizadas de maneira geral em agrupamentos de s√©ries temporais. Os cinco foram avaliados em tr√™s datasets com dados do mundo real, um dataset gerado sinteticamente e os 128 datasets cl√°ssicos de s√©ries temporais da UCR (University of California, Riverside). O resultado dos experimentos constatou que o Z-Grouping atingiu taxas de erro menores do que seus competidores, e ao mesmo tempo gerou agrupamentos locais sem limita√ß√µes no tamanho dos intervalos de tempo, o que n√£o pode ser feito utilizando as demais abordagens."
  },
  {
    "objectID": "seminario1/artigo2.html#considera√ß√µes-finais-e-sugest√µes-para-futuras-pesquisas",
    "href": "seminario1/artigo2.html#considera√ß√µes-finais-e-sugest√µes-para-futuras-pesquisas",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "3.2 Considera√ß√µes Finais e Sugest√µes para Futuras Pesquisas",
    "text": "3.2 Considera√ß√µes Finais e Sugest√µes para Futuras Pesquisas\nPoss√≠veis abordagens de pesquisas futuras podem incluir o uso de outras fun√ß√µes de abstra√ß√£o temporal (al√©m da SAX, utilizada no artigo), a aplica√ß√£o de t√©cnicas e heur√≠sticas de otimiza√ß√£o global na cria√ß√£o dos agrupamentos locais e o estudo de adapta√ß√µes do algoritmo para s√©ries temporais multivariadas, isto √©, para a gera√ß√£o de agrupamentos multidimensionais."
  },
  {
    "objectID": "seminario1/artigo2.html#instala√ß√£o",
    "href": "seminario1/artigo2.html#instala√ß√£o",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.1 Instala√ß√£o",
    "text": "5.1 Instala√ß√£o\nPara utilizar o Z-Grouping, √© necess√°rio ter instaladas as extens√µes numba, numpy, pyts e o Python em sua vers√£o 3.7 ou superior. Devido √†s depend√™ncias utilizadas, recomenda-se a utiliza√ß√£o do Python 3.8 ou superior para evitar conflitos de vers√£o.\nPara instalar o Python 3.8, siga os passos abaixo:\n\nInstale as depend√™ncias necess√°rias:\n\nsudo apt-get install libsqlite3-dev ## (ou sqlite-devel dependendo do SO). \ncd /opt/ \nsudo wget https://www.python.org/ftp/python/3.8.3/Python-3.8.3.tgz \nsudo tar -xzf Python-3.8.3.tgz \ncd Python-3.8.3 \nsudo ./configure --enable-optimizations --enable-loadable-sqlite-extensions \nsudo make altinstall \n\nAtive o ambiente com Python 3.8:\n\npython3.8 -m venv ./.venv \nsource .venv/bin/activate \npip install --upgrade pip \npip install numba numpy==1.19.5 pyts matplotlib==3.3.1 \n\nPor fim, para instalar o Z-Grouping, siga estas instru√ß√µes:\n\ngit clone https://github.com/zedshape/zgrouping.git \ncd zgrouping \nCertifique-se de seguir esses passos com aten√ß√£o para garantir uma instala√ß√£o bem-sucedida do Z-Grouping em seu ambiente de desenvolvimento."
  },
  {
    "objectID": "seminario1/artigo2.html#utiliza√ß√£o-do-algoritmo-z-grouping",
    "href": "seminario1/artigo2.html#utiliza√ß√£o-do-algoritmo-z-grouping",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.2 Utiliza√ß√£o do Algoritmo Z-Grouping",
    "text": "5.2 Utiliza√ß√£o do Algoritmo Z-Grouping\nO algoritmo pode ser facilmente executado importando o m√©todo createGroupings do reposit√≥rio fornecido:\nfrom zgrouping.syntheticGenerator import createSyntheticData \nEle recebe os seguintes par√¢metros: * matrices: matriz de labels de evento. Essa matriz pode ser gerada utilizando o m√©todo utils.createChannel sobre as s√©ries temporais de entrada. * alpha: o limiar de pureza. * debug: op√ß√µes de print e debug. * accept: habilita a fun√ß√£o de valida√ß√£o da qualidade dos agrupamentos."
  },
  {
    "objectID": "seminario1/artigo2.html#datasets",
    "href": "seminario1/artigo2.html#datasets",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.3 Datasets",
    "text": "5.3 Datasets\nO reposit√≥rio do Z-Grouping j√° cont√©m bases de dados para teste e avalia√ß√£o do algoritmo, localizadas na pasta datasets. Algumas das bases de dados incluem: * Covid-19: Base de dados referente ao continente do pa√≠s, pa√≠s e contagem de casos de covid no pa√≠s de 22/01/2020 at√© 30/09/2021. * Stocks: Base de dados de a√ß√µes contendo informa√ß√µes como data do registro, valor de abertura do dia, maior valor no dia, menor valor no dia, volume e TAG (nome) da a√ß√£o.\nAl√©m disso, o reposit√≥rio inclui um gerador de bases de dados sint√©ticas, que cria padr√µes entre s√©ries temporais. Este gerador pode ser utilizado importando o m√©todo createSyntheticData do reposit√≥rio:\nfrom zgrouping.syntheticGenerator import createSyntheticData\nO m√©todo syntheticGenerator.createSyntheticData requer os seguintes argumentos: * c: N√∫mero de agrupamentos globais. * tc: N√∫mero de membros da inst√¢ncia por agrupamento. * tl: Tamanho de cada s√©rie temporal. * no_outliers: N√∫mero de outliers. * outlier_size: Tamanho do outlier. * amp: Amplitude. * lineranges: Comprimento de linhas retas. * lineheights: Altura das linhas retas.\nEsses datasets sint√©ticos podem ser utilizados como substitutos para os datasets reais mencionados anteriormente. No entanto, ainda √© necess√°rio passar essas bases pelo m√©todo de cria√ß√£o de canais, que √© o dado de entrada para o algoritmo de agrupamento."
  },
  {
    "objectID": "seminario1/artigo2.html#exemplo-de-uso",
    "href": "seminario1/artigo2.html#exemplo-de-uso",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.4 Exemplo de Uso",
    "text": "5.4 Exemplo de Uso\nPara ilustrar o uso do Z-Grouping, apresentamos a seguir um exemplo pr√°tico de execu√ß√£o do algoritmo. Os passos a seguir demonstram como gerar dados sint√©ticos, aplicar transforma√ß√µes e finalmente executar o Z-Grouping para obter os agrupamentos desejados.\nAp√≥s a gera√ß√£o e transforma√ß√£o dos dados, ser√° obtida uma matriz com padr√µes simb√≥licos, representando s√©ries temporais. A seguir, √© apresentado um exemplo dos dados antes e depois da transforma√ß√£o.\n\n\nCode\nfrom zgrouping.zgrouping import grouping, syntheticGenerator, utils \nimport matplotlib.pyplot as plt \n\n# Synthetic generator \ntc = 50 \ntl = 365 \nc = 20 \nno_outliers = 10 \noutlier_size = 10 \n\n# Grouping generation \nn_bins = 5 \nalpha = 0.9 \neta = 1.5 \n\nX_raw, y = syntheticGenerator.createSyntheticData(tc=tc, tl=tl, c=c, no_outliers=no_outliers, outlier_size=outlier_size) \n\n# Normaliza√ß√£o e Transforma√ß√£o \nX = utils.znorm(X_raw)  \nX_sax = utils.SAXify(X, n_bins=5) \n\n# Visualiza√ß√£o dos dados \nplt.plot(X_raw[150], label='antes') \nplt.plot(X_sax[150], label='depois')\nplt.title('Dados sint√©ticos antes e depois da transforma√ß√£o')\nplt.legend()\nplt.show()\nprint(X_sax[150]) \n\n\n\n\n\n\n\n\n\n[2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4\n 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3\n 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2\n 2 2 2 2 2 2 3 3 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 4 3 3\n 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 4 1 1 1 1 1 1 1 1 1 2 1 2 2 2]\n\n\nAp√≥s a prepara√ß√£o dos dados, eles ser√£o utilizados como entrada para a cria√ß√£o dos canais do Z-Grouping. A matriz resultante deve ter dimens√µes \\(S \\times T\\), onde \\(S\\) √© o n√∫mero de s√©ries temporais e \\(T\\) √© o tamanho de cada s√©rie temporal. Isso significa que cada linha da matriz representa uma s√©rie temporal e cada coluna representa o valor daquela s√©rie temporal em um determinado tempo.\n\n\nCode\nmatrices = utils.createChannels(X_sax)\n\n\nCom os canais devidamente criados, ser√° utilizado o Z-Grouping para obter os agrupamentos desejados. O c√≥digo a seguir demonstra como executar o algoritmo e obter os agrupamentos:\n\n\nCode\ngroupings, associations = grouping.createGroupings(matrices, alpha=alpha, accept=False, debug=True) \n\n\n[DEBUG] BEGIN Local grouping generation\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 44.951890109000004\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 36.923591759\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 26.490854166999995\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 36.19687330400001\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 29.767859024000018\n[DEBUG] BEGIN Association generation\n\n\nA vari√°vel groupings resultante √© uma lista de objetos, onde cada objeto representa um agrupamento detectado. Cada agrupamento cont√©m dois campos importantes: * members: um vetor de booleanos indicando se uma s√©rie temporal pertence ou n√£o a esse agrupamento, funcionando como uma m√°scara. * range: o intervalo de tempo no qual o padr√£o se repete entre as s√©ries temporais.\nAgora, para melhor visualiza√ß√£o dos resultados, foi feita uma fun√ß√£o que desenha os gr√°ficos de algumas das s√©ries temporais pertencentes a um determinado agrupamento e destaca o padr√£o detectado.\n::: {#409c2256 .cell execution_count=9} ``` {.python .cell-code} import random\ndef print_3_examples(data, grouping, number_prints): mask = [(index, value) for (index, value) in enumerate(grouping[‚Äòmembers‚Äô])] members = list(filter(lambda tuple : tuple[1], mask))\nrandIndexList = [random.randint(0, len(members) -1) for i in range(number_prints)] \nchoosedMembers = [members[index][0] for index in randIndexList] \n\ninterval = grouping['range'][0:number_prints] \n\nfig, axs = plt.subplots(nrows=number_prints, ncols=1) \nfig.set_figheight(15) \ni = 0 \nfor ax, i in zip(axs, choosedMembers): \n    thisData = data[i] \n    patternData = list(filter(lambda tuple: interval[0] &lt;= tuple[0] &lt;= interval[1], enumerate(thisData))) \n    patternX = [pattern[0] for pattern in patternData] \n    patternY = [pattern[1] for pattern in patternData] \n    ax.plot(thisData) \n    ax.plot(patternX, patternY, 'r') \n    i += 1 \n\nplt.subplots_adjust(hspace=0.0) \nplt.show() \n\nprint(choosedMembers) \nprint_3_examples(X_raw,groupings[13], 6) ```\n::: {.cell-output .cell-output-display}  :::\n::: {.cell-output .cell-output-stdout} [602, 801, 702, 230, 437, 916] ::: :::"
  },
  {
    "objectID": "seminario2/artigo6.html",
    "href": "seminario2/artigo6.html",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "",
    "text": "Minera√ß√£o de modelos excepcionais (Exceptional Model Mining - EMM) √© um framework que tem como objetivo encontrar padr√µes locais, assim como a descoberta de subgrupos (Sbugroup Discovery - SD), por√©m EMM busca encontrar correla√ß√µes entre vari√°veis alvo que podem ser consideradas interessantes/exepcionais. J√° SD busca encontrar padr√µes, criando seletores nos atributos dispon√≠veis, para encontrar individuos que atendam um padr√£o de qualidade em rela√ß√£o a distribui√ß√£o de uma √∫nica vari√°vel alvo.\nO artigo aborda uma t√©cnica chamada minera√ß√£o de prefer√™ncias exepcionais (Excepional Preference Mining - EPM), onde procura-se achar prefer√™ncia sobre r√≥tulos, ou seja, encontrar prefer√™ncias excepcionais de diversas op√ß√µes poss√≠veis sobre uma vari√°vel."
  },
  {
    "objectID": "seminario2/artigo6.html#contextualiza√ß√£o-do-problema",
    "href": "seminario2/artigo6.html#contextualiza√ß√£o-do-problema",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Contextualiza√ß√£o do problema",
    "text": "Contextualiza√ß√£o do problema\nDiversas linhas de pesquisa buscam construir modelos preditivos capazes de realizarem um ajuste global a um conjunto de dados, de forma fornecer resultados generalizados para todo o conjunto de dados que foi treinado, al√©m de prever com acur√°cia novos conjuntos de dados. Esses modelos podem fornecer grande ajuda em tomadas de decis√£o, pois s√£o capazes de preverem uma vari√°vel alvo. Contudo, pode-se extrair informa√ß√µes valiosas procurando padr√µes locais. Em casos como: elei√ß√µes, market-places, restaurantes, sistemas de recomenda√ß√£o em redes sociais. O objetivo √© tentar encontrar padr√µes de prefer√™ncia, onde seria poss√≠vel encontrar atributos de amostras que caracterizam essas prefer√™ncias.\nBusca-se portanto encontrar correla√ß√µes entre os r√≥tulos, objetivando encontrar uma prefer√™ncia entre eles em grupos locais, considerados excepcionais.\n\n\n\nDescoberta de Modelos Excepcionais\n\n\nEntre os m√©todos que realizam fun√ß√µes semelhantes a EPM, pode-se destacar o uso de regras de associa√ß√£o, proposto por Henzgen e Hullermeier, que faz uma busca por padr√µes de subranking."
  },
  {
    "objectID": "seminario2/artigo6.html#conceitos-importantes",
    "href": "seminario2/artigo6.html#conceitos-importantes",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Conceitos importantes",
    "text": "Conceitos importantes\n\nLabel Ranking\nDada uma inst√¢ncia a \\(x = \\{a_1, a_2, \\ldots, a_m, \\pi\\}\\) do espa√ßo de inst√¢ncias \\(\\mathbb{X}\\), o objetivo √© prever o rank dos r√≥tulos \\(\\mathbb{L} = \\{\\lambda_1, \\ldots, \\lambda_n\\}\\) associados com \\(x\\). O ranking pode ser representado como uma strict total order sob \\(\\mathbb{L}\\), definido no espa√ßo de permuta√ß√£o \\(\\Omega\\).\nO Label Ranking se assemelha √†s tarefas de classifica√ß√£o, mas ao inv√©s de prever uma classe, deseja-se ranquear os r√≥tulos. Na classifica√ß√£o, cada inst√¢ncia √© associada a uma distribui√ß√£o probabil√≠stica sob \\(\\Omega\\). Isso significa que, para cada \\(x \\in \\mathbb{X}\\), existe uma distribui√ß√£o de probabilidade \\(\\mathbb{P}(.|x)\\), de forma que para cada \\(\\pi \\in \\Omega\\), \\(\\mathbb{P}(\\pi|x)\\) √© a probabilidade de que \\(\\pi\\) est√° associado ao ranking de \\(x\\). O objetivo de Label Ranking √© mapear \\(\\mathbb{X} \\rightarrow \\Omega\\).\n\n\nDescoberta de Subgrupos e Exceptional Model Mining\nA linguagem usada para retornar um subgrupo √© a seguinte:\n\\(ùê¥ùëîùëí ‚â• 30 ‚ãÄ ùêøùëñùëòùëíùë† = ùëÜùëéùëôùëöùëúùëõ ùëÖùëúùëí ‚Üí ùëàùëõùë¢ùë†ùë¢ùëéùëô\\)\n\nM√©trica de Qualidade\nNa minera√ß√£o de padr√µes, o qu√£o interessante um padr√£o pode ser √© medido pela sua frequ√™ncia; j√° em Subgroup Discovery (SD) essa m√©trica √© estimada de forma supervisionada. Dada uma vari√°vel alvo \\(t_1\\) identificada no dataset, o qu√£o interessante um subgrupo nela for, √© medido pelo qu√£o n√£o-usual a distribui√ß√£o dele neste alvo.\nSe em uma popula√ß√£o o comum √© as pessoas gostarem de sushi chutoro, um subgrupo interessante seria de pessoas que gostam de Makizushi:\n\\(Age ‚â• 30 ‚ãÄ Lives in Region = Hokkaido ‚Üí Makizushi\\)\nSe ao inv√©s de usar um √∫nico atributo alvo, m√∫ltiplos alvos \\(t_1, \\ldots, t_l\\) est√£o dispon√≠veis, e se n√£o estiver interessado em descobrir distribui√ß√µes n√£o usuais em um alvo, mas na intera√ß√£o entre alvos, pode-se ent√£o empregar o Exceptional Model Mining (EMM) no lugar do SD. Essa tarefa consiste em dois fatores: Model Class e M√©trica de Qualidade.\nModel Class √© definido para representar uma intera√ß√£o n√£o comum entre m√∫ltiplos alvos que se esteja interessado. J√° a m√©trica de qualidade √© usada para definir o que n√£o √© usual e, portanto, interessante.\nUm exemplo seria tentar encontrar uma correla√ß√£o entre a altura de uma pessoa \\(( t_1 )\\) e a altura m√©dia dos av√≥s \\(( t_2 )\\). Para isso, √© necess√°rio achar um coeficiente de correla√ß√£o entre $t_1 $ e \\(t_2\\). Nesse caso aplica-se EMM com um correlation model class. No caso de subgrupos muito pequenos, o modelo pode acabar favorecendo-os por serem pouco usuais. Para favorecer subgrupos maiores, deve-se definir uma m√©trica de qualidade que balanceie o qu√£o excepcional um subgrupo √©, e o tamanho dele.\n\n\n\nEstrat√©gia de Busca\nEm EMM √© explorado um amplo espa√ßo de busca, guiado por uma m√©trica de qualidade para expressar a excepcionalidade buscada. Tipicamente, os subgrupos s√£o buscados em uma busca por n√≠vel, combinando atributos da mesma forma que √© feita uma combina√ß√£o de itemsets para minera√ß√£o de padr√µes frequentes.\nA maioria dos algoritmos de busca, fazem de forma generalista-para-espec√≠fico, tratando o espa√ßo de busca como um lattice cuja estrutura √© definida por um refinement operator \\(\\eta: \\mathbb{D} \\rightarrow 2^\\mathbb{D}\\). Esse operador consegue determinar como descri√ß√µes podem ser estendidas para descri√ß√µes mais complexas por adi√ß√µes at√¥micas. A aplica√ß√£o proposta no artigo assume que \\(\\eta\\) √© um specialization operator: toda descri√ß√£o $q $ √© um elemento do conjunto \\(\\eta(p)\\), o qual √© mais especializada que a descri√ß√£o \\(p\\) em si. O algoritmo, portanto, retorna uma lista ranqueada de descri√ß√µes que satisfazem as especifica√ß√µes do usu√°rio.\nA estrat√©gia de busca empregada foi um best first search, em cada n√≠vel as descri√ß√µes s√£o ordenadas pela m√©trica de qualidade \\(\\varphi\\). O limite superior √© o grau de complexidade, geralmente limitado por especialistas, para obter descri√ß√µes com quantidades ideais de atributos para interpreta√ß√£o (profundidade da busca); e o limite inferior √© o suporte dos subgrupos.\n\n\nRegras de Distribui√ß√µes\nRegras de Distribui√ß√µes (Distribution Rules, DR) √© um m√©todo de SD para analisar uma √∫nica vari√°vel alvo. Ao inv√©s de valores representativos (m√©dia, desvio-padr√£o etc.), DR identifica distribui√ß√µes usuais do alvo, encontrando subgrupos expressados pelas regras de associa√ß√£o com a distribui√ß√£o consequente:\n\\(S ‚Üí t = Dist_t|S\\)\n\n\\(S\\): √© um conjunto de condi√ß√µes correspondentes √† parte antecedente do DR (um subgrupo).\n\\(t\\): √© a propriedade de interesse (ou o alvo).\n\\(Dist_t|S\\): √© uma distribui√ß√£o emp√≠rica de \\(t\\) quando \\(S\\) √© observado. Ela √© representada por um conjunto de pares $t_i, freq(t_i) $, onde \\(t_i\\) √© um valor particular de \\(t\\) encontrado quando \\(S\\) √© observado; \\(freq(t_i)\\) √© a frequ√™ncia de \\(t_i\\) quando os itens de \\(S\\) s√£o observados."
  },
  {
    "objectID": "seminario2/artigo6.html#matriz-de-prefer√™ncia",
    "href": "seminario2/artigo6.html#matriz-de-prefer√™ncia",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Matriz de Prefer√™ncia",
    "text": "Matriz de Prefer√™ncia\nEm EMP o conceito alvo consiste em um √∫nico alvo, o que faz sentido em SD. Contudo, o objeto alvo √© um ranqueamento de r√≥tulos, que pode ser representando como compara√ß√µes em pares. Portanto, representa intera√ß√µes entre m√∫ltiplos r√≥tulos individuais, o que √© mais consistente no cen√°rio do EMM.\nRanqueamento de r√≥tulos pode ser dif√≠cil de analisar e visualizar, quando h√° uma quantidade grande de r√≥tulos. O apresentado Sushi dataset, que cont√©m 5000 amostras de opini√µes de pessoas e 10 tipos de sushi mostra um exemplo real. At√© essa quantidade modesta de tipos de sushi diferentes pode ser ranqueado em diversas combina√ß√µes. Isso pode ter um impacto significativo, onde mais de 98% dos 5000 rankings presentes no dataset s√£o √∫nicos.\nPor conta disso, os autores apresentaram uma alternativa para ranquear os r√≥tulos, introduzindo as Matrizes de Prefer√™ncia. A matriz de prefer√™ncia (PM, preference matrix) √© uma representa√ß√£o alternativa dos rankings em um conjunto de dados que facilita a an√°lise de comportamentos de prefer√™ncia excepcionais. Em vez de representar diretamente a ordena√ß√£o dos r√≥tulos, a matriz de prefer√™ncia captura as compara√ß√µes par a par entre r√≥tulos, permitindo uma vis√£o mais detalhada das rela√ß√µes de prefer√™ncia.\nRepresentar um conjunto de rankings por PM tem certas vantagens sob as tradicionais representa√ß√µes por permuta√ß√µes. PM podem, naturalmente, derivar uma variedade de conjunto m√©tricas para busca de padr√µes de prefer√™ncia. Contudo, h√° certas limita√ß√µes tamb√©m, a escolha de agrega√ß√£o de m√©tricas pode esconder informa√ß√µes relevantes nas PMs, por exemplo, escolhendo a m√©dia se metade dos rankings minerados forem opostos, o resultando em entradas na PM s√£o iguais a zero. Por isso subgrupos com PM contendo apenas zeros nas entradas s√£o ignorados."
  },
  {
    "objectID": "seminario2/artigo6.html#entendendo-os-algoritmos-usados",
    "href": "seminario2/artigo6.html#entendendo-os-algoritmos-usados",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Entendendo os algoritmos usados",
    "text": "Entendendo os algoritmos usados\nO algoritmo EPM (Exceptional Preference Mining) tem como objetivo identificar subgrupos significativos em um dataset, utilizando uma medida de qualidade para avaliar a diferen√ßa entre as prefer√™ncias do subgrupo e do dataset original.\nfunction EPM(dataset, quality_measure):\n    dataset_pm = compute_preference_matrix(dataset)\n    candidate_subgroups = generate_candidate_subgroups(dataset)\n\n    for subgroup in candidate_subgroups:\n        subgroup_pm = compute_preference_matrix(subgroup)\n        distance = calculate_distance(dataset_pm, subgroup_pm, quality_measure)\n        subgroup.score = calculate_score(distance, subgroup.size)\n\n    ranked_subgroups = rank_subgroups(dataset_pm, candidate_subgroups)\n    significant_subgroups = validate_subgroups(ranked_subgroups)\n\n    return significant_subgroups\n\nPasso a Passo do Algoritmo\nVamos apresentar o algoritmo EPM (Exceptional Preference Mining): 1. Fun√ß√£o Principal\n   function EPM(dataset, quality_measure):\nA fun√ß√£o principal EPM recebe dois par√¢metros:\ndataset: o conjunto de dados a ser analisado. quality_measure: a medida de qualidade utilizada para avaliar as prefer√™ncias.\n\nComputa√ß√£o da Matriz de Prefer√™ncia do Dataset\n\ndataset_pm = compute_preference_matrix(dataset)\ncompute_preference_matrix(dataset): Calcula a matriz de prefer√™ncia para o dataset completo, que ser√° utilizada como refer√™ncia para comparar os subgrupos.\n\nGera√ß√£o de Subgrupos Candidatos\n\ncandidate_subgroups = generate_candidate_subgroups(dataset)\ngenerate_candidate_subgroups(dataset): Gera uma lista de subgrupos candidatos a partir do dataset original. Esses subgrupos ser√£o avaliados posteriormente.\n\nAvalia√ß√£o dos Subgrupos Candidatos Para cada subgrupo na lista de candidatos, realiza-se os seguintes passos:\n\nfor subgroup in candidate_subgroups:\n    subgroup_pm = compute_preference_matrix(subgroup)\n    distance = calculate_distance(dataset_pm, subgroup_pm, quality_measure)\n    subgroup.score = calculate_score(distance, subgroup.size)\ncompute_preference_matrix(subgroup): Calcula a matriz de prefer√™ncia para o subgrupo espec√≠fico. calculate_distance(dataset_pm, subgroup_pm, quality_measure): Calcula a dist√¢ncia entre a matriz de prefer√™ncia do dataset completo e a do subgrupo, utilizando a medida de qualidade fornecida.\n\nF√≥rmula Geral\nA dist√¢ncia geral \\(L_S\\) entre a matriz de prefer√™ncia do dataset completo \\(M_D\\) e a matriz de prefer√™ncia do subgrupo \\(M_S\\) √© calculada como:\n\\(L_S = \\frac{1}{2} (M_D - M_S)\\)\n\n\nMedidas de Qualidade\n\nNorm\nA medida de qualidade Norm √© definida como a norma de Frobenius da matriz \\(L_S\\). A f√≥rmula √©:\n\\(\\text{Norm}(S) = \\| L_S \\|_F = \\sqrt{s/n} \\cdot \\sqrt{ \\sum_{i=1}^{k} \\sum_{j=1}^{k} L(i,j)^2 }\\)\n\n\nLabelwise\nA medida de qualidade Labelwise √© calculada como o valor m√°ximo entre todas as somas das linhas da matriz \\(L_S\\):\n\\(\\text{Labelwise}(S) = \\max_{i=1,\\ldots,k} \\frac{1}{k(k-1)} \\sum_{j=1}^{k} L(i,j)\\)\n\n\nPairwise\nA medida de qualidade Pairwise √© calculada como o valor m√°ximo entre todos os elementos da matriz \\(L_S\\):\n\\(\\text{Pairwise}(S) = \\max_{i,j=1,\\ldots,k} L(i,j)\\)\nEssas medidas s√£o utilizadas para avaliar a diferen√ßa entre as prefer√™ncias do dataset original e dos subgrupos, ajudando a identificar subgrupos excepcionais.\ncalculate_score(distance, subgroup.size): Calcula a pontua√ß√£o do subgrupo com base na dist√¢ncia calculada e no tamanho do subgrupo.\n\n\n\nPassos para Calcular a Pontua√ß√£o\nCalcular a Cobertura Normalizada do Grupo\nA Cobertura Normalizada do Grupo √© dada por:\n\\(\\sqrt{\\frac{s}{n}}\\)\nonde: - \\(s\\) √© o tamanho do subgrupo. - \\(n\\) √© o tamanho do dataset completo.\nMultiplicar pela Dist√¢ncia\nA pontua√ß√£o final do subgrupo √© obtida multiplicando a Cobertura Normalizada do Grupo pela Dist√¢ncia calculada na fun√ß√£o calculate_distance.\n\nRanqueamento dos Subgrupos\n\nranked_subgroups = rank_subgroups(dataset_pm, candidate_subgroups)\nrank_subgroups(dataset_pm, candidate_subgroups): Ordena os subgrupos candidatos com base na pontua√ß√£o calculada, gerando uma lista de subgrupos ranqueados.\n\n\nF√≥rmula da Covari√¢ncia Ponderada\nA f√≥rmula utilizada para calcular a covari√¢ncia ponderada entre o vetor da matriz de prefer√™ncia do dataset completo \\(\\text{vec}(M_D)\\) e o vetor da matriz de prefer√™ncia do subgrupo \\(\\text{vec}(M_S)\\) √©:\n\\(\\text{RWCov}(S) = -\\sqrt{\\frac{s}{n}} \\cdot \\text{cov}(\\text{vec}(M_D), \\text{vec}(M_S))\\)\nonde: - \\(\\text{vec}(M_D)\\) √© o vetor da matriz de prefer√™ncia do dataset completo. - \\(\\text{vec}(M_S)\\) √© o vetor da matriz de prefer√™ncia do subgrupo. - \\(\\text{cov}\\) representa a covari√¢ncia entre os dois vetores. - \\(s\\) √© o tamanho do subgrupo. - \\(n\\) √© o tamanho do dataset completo.\nEsta medida ajuda a identificar subgrupos que possuem prefer√™ncias excepcionalmente diferentes em rela√ß√£o ao dataset original.\n\nValida√ß√£o dos Subgrupos Significativos\n\nsignificant_subgroups = validate_subgroups(ranked_subgroups)\nvalidate_subgroups(ranked_subgroups): Valida os subgrupos ranqueados para identificar aqueles que s√£o estatisticamente significativos.\n\nRetorno dos Subgrupos Significativos Retorno dos Subgrupos Significativos\n\nreturn significant_subgroups"
  },
  {
    "objectID": "seminario2/artigo6.html#metodologia",
    "href": "seminario2/artigo6.html#metodologia",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Metodologia",
    "text": "Metodologia\nPara fazer os experimentos, os autores incorporaram EPM no Cortana, que oferece uma estrutura gen√©rica para descoberta de subgrupos e possui ferramentas para que diferentes abordagens de SD sejam aplicadas. Al√©m disso, eles definiram uma linguagem de descri√ß√£o para os subgrupos, que √© composta por conjun√ß√µes l√≥gicas de restri√ß√µes para atributos individuais.\nA estrat√©gia adotada para percorrer o espa√ßo de busca foi uma best-first search gulosa. Sendo que os atributos num√©ricos foram discretizados com on fly greedy best-first search contendo 8 bins de mesma largura. Os resultados encontrados passaram pela valida√ß√£o DFD, que serve para evitar que subgrupos sejam selecionados por fatores aleat√≥rios. A valida√ß√£o DFD consiste na cria√ß√£o de c√≥pias do dataset, com algumas altera√ß√µes aleat√≥rias dos atributos-alvo. Subgrupos encontrados nessas c√≥pias podem ser considerados aleat√≥rios. Dessa forma, o m√©todo EPM foi aplicado sobre alguns datasets reais. O procedimento DFD permite controlar o problema das m√∫ltiplas compara√ß√µes em SD e EMM, fornecendo uma forma robusta de identificar padr√µes realmente excepcionais enquanto minimiza a probabilidade de falsas descobertas.\nO procedimento DFD tem apenas um par√¢metro: o n√∫mero de c√≥pias do conjunto de dados. Este n√∫mero deve ser suficientemente grande para satisfazer certas condi√ß√µes decorrentes da modelagem global envolvida na cria√ß√£o da DFD. Tipicamente, 100 c√≥pias s√£o suficientes, com um n√≠vel de signific√¢ncia estat√≠stica de 1%.\nSeis bases de dados reais de diferentes dom√≠nios foram utilizadas nos experimentos. O dataset Algae apresenta os n√≠veis de frequ√™ncia de alguns tipos de alga em diferentes rios europeus. O dataset Sushi cont√©m os dados demogr√°ficos de um conjunto de pessoas, bem como suas prefer√™ncias em rela√ß√£o a diferentes tipos de sushi. O dataset Top7movies √© um subconjunto de outra base de dados, que apresenta os rankings dos usu√°rios para os 7 filmes mais avaliados. Os datasets GermanElections2005 e GermanElections2009 cont√©m dados socioecon√¥micos dos distritos administrativos da Alemanha e o ranking de vota√ß√£o dos partidos mais populares nessas regi√µes. O dataset Cpu-small apresenta dados extra√≠dos de medi√ß√µes relacionadas a servidores.\n\n\n\n\nFonte: sushi\n\n\n\n\n\nFonte: movies\n\n\n\n\n\n\nBases de Dados\n\n\n√â usado um m√©todo chamado Regra de Distribui√ß√£o para procurar distribui√ß√µes alvo, ele foi comparado com o RWNorm aplicado no Cortana\n\n\n\nMetodologia t√©cnica DR\n\n\nPara comparar a distribui√ß√£o dos subgrupos com a popul√ß√£o (o conjunto de dados inteiro) foi realizado o teste estat√≠stico de Komolgorov-Smirgov"
  },
  {
    "objectID": "seminario2/artigo6.html#resultados-obtidos",
    "href": "seminario2/artigo6.html#resultados-obtidos",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Resultados obtidos",
    "text": "Resultados obtidos\nA excepcionalidade informada pelas m√©tricas de qualidade podem se apresentar de diferentes formas em diferentes m√©tricas de qualidade, ou seja, depende o que a m√©tricas de qualidade est√° procurando. As m√©tricas podem at√© estar correlacionadas, mas n√£o perfeitamente, os autores forneceram no estudo uma forma do usu√°rio utilizar essas m√©tricas para tomar escolhas mais bem informadas.\n\n\n\nRela√ß√£o Entre M√©tricas de Qualidade\n\n\nA figura acima mostra gera√ß√£o de 10.000 subgrupos aleat√≥rios, os quais a pontua√ß√£o foi avaliada pelas m√©tricas de qualidade apresentadas. A gera√ß√£o aleat√≥ria combina descri√ß√µes at√© uma profundidade m√°xima ser alcan√ßada. A profundidade da busca √© fixada em 3, permitindo uma boa diversidade de combina√ß√µes de atributos. Para cada par de m√©trica de qualidade na figura, h√° um scatter plot mostrando a rela√ß√£o das pontua√ß√µes. A primeira linha mostra os subgrupos avaliados por RWNorm e o eixo vertical representa a pontua√ß√£o dela; o eixo horizontal representa a pontua√ß√£o de cada m√©trica de qualidade na seguinte ordem: RWNorm; RWNorm-mode; RWCov; LWNorm; PWMax\nPode-se notar que RWNorm-mode mostra um comportamento distinto, ela √© baseada na matriz de dist√¢ncia diferencial L_S, obtida pela diferen√ßa entre as modas da popula√ß√£o (M_D) e a moda dos subgrupos (M_S). Para essa m√©trica, se houver uma invers√£o de prefer√™ncia no ranking dos r√≥tulos em algum subgrupo de tamanho significativo, ele √© considerado interessante, mesmo que seja pouco, como 2%. Para as m√©tricas RWMNorm, LWNorm e PWMax, subgrupos desse tipo j√° n√£o ir√£o ser interessantes, a n√£o ser que a diferen√ßa seja maior, isso fica evidente observando a segunda linha da Figura.\nObservando o RWConv, parece que tem o maior vi√©s, isso se d√° pelo fato dessa m√©trica n√£o se basear na matriz de dist√¢ncia L_S; ao inv√©s disso ela √© baseada na correla√ß√£o negativa entre as matrizes de popula√ß√£o (M_D) e subgrupos (M_S). Portanto, essa m√©trica de qualidade n√£o necessariamente ir√° encontrar subgrupos que maximizem a preference distance, mas ir√° mostrar features n√£o usuais de comportamento de forma abstrata.\n\n1. Elei√ß√µes Alem√£s (2005 e 2009) GermanElections2005:\n\nUtilizando a m√©trica de qualidade PWMax com profundidade de busca 1, foram encontrados 62 subgrupos significativos.\nO subgrupo mais relevante foi ‚ÄúRegi√£o = Leste‚Äù, onde o partido Esquerda teve mais votos que o partido FDP em todos os 87 distritos da Alemanha Oriental, contrastando com a maioria dos distritos na Alemanha.\nOutro subgrupo significativo mostrou que em regi√µes de baixa renda (renda ‚â§ 16.979), o partido Esquerda recebeu mais votos que o partido Verde. GermanElections2009:\nCom as mesmas configura√ß√µes, foram identificados 57 subgrupos significativos. Novamente, ‚ÄúRegi√£o = Leste‚Äù mostrou uma forte prefer√™ncia pelo partido Esquerda em compara√ß√£o ao partido Verde.\nHouve um aumento no n√∫mero de distritos de baixa renda favorecendo o partido Esquerda em rela√ß√£o ao partido Verde comparado a 2005. An√°lise com LWNorm:\nUsando a m√©trica LWNorm com profundidade de busca 2, foram encontrados 2965 subgrupos significativos.\nO subgrupo ‚ÄúRegi√£o = Leste‚Äù continuou mostrando forte prefer√™ncia pelo partido Esquerda.\nOutros subgrupos com caracter√≠sticas como menor popula√ß√£o infantil e maior desemprego tamb√©m favoreceram o partido Esquerda, enquanto regi√µes de maior renda mostraram o partido Esquerda como o menos votado.\n\n\n\n2. Top7Movies\n\nUtilizando a m√©trica LWNorm, foram encontrados 2 subgrupos significativos com profundidade de busca 2.\nO primeiro subgrupo inclu√≠a pessoas com mais de 34 anos vivendo abaixo de uma latitude de 32.9, que n√£o gostaram do filme ‚ÄúBeleza Americana‚Äù e preferiram ‚ÄúStar Wars: Epis√≥dio IV‚Äù e ‚ÄúO Resgate do Soldado Ryan‚Äù.\nA m√©dia de classifica√ß√£o deste subgrupo foi b (Star Wars: Epis√≥dio IV) &gt; f (O Resgate do Soldado Ryan) &gt; c (Star Wars: Epis√≥dio V) &gt; d (Star Wars: Epis√≥dio VI) &gt; g (O Exterminador do Futuro 2) &gt; a (Beleza Americana) &gt; e (Jurassic Park).\n\n\n\n\nResultados Filmes Matriz de Prefixos\n\n\n\n\n3. Algae\n\nUtilizando a m√©trica RWNorm, os resultados indicam que durante a primavera, as esp√©cies de algas a, b e c s√£o mais comuns em rios.\nA m√©trica LWNorm revelou mais de 400 subgrupos com profundidade m√°xima de 2.\nO melhor subgrupo mostrou que a esp√©cie de alga a √© fortemente preferida no subgrupo em compara√ß√£o com o conjunto de dados geral.\nUtilizando profundidade de 3, foram encontrados cerca de 5400 subgrupos, mostrando um comportamento oposto em rela√ß√£o √† esp√©cie de alga a.\n\n\n\n4. Sushi\n\nDevido ao alto percentual de rankings √∫nicos, focou-se em padr√µes de ranking labelwise.\nA m√©trica LWNorm identificou 149 subgrupos.\nO melhor subgrupo revelou que homens com mais de 30 anos mostraram uma forte prefer√™ncia por ouri√ßo-do-mar (r√≥tulo e), contrastando com a popula√ß√£o geral.\n\n\n\n\nCompara√ß√£o de Subgrupod de Prefer√™ncia de Sushi com a Popula√ß√£o\n\n\n\n\n5. Cpu-small\n\nUtilizando a m√©trica RWCov, foram encontrados 275 subgrupos significativos com profundidade m√°xima de 4.\nO subgrupo mais relevante exibiu grandes desvios em todas as entradas da matriz de prefer√™ncia, indicando comportamento de prefer√™ncia incomum.\n\n\n\n6. Compara√ß√£o de M√©tricas de Qualidade\n\nObservou-se uma varia√ß√£o na quantidade de subgrupos obtidos por diferentes m√©tricas.\nA RWNorm apresentou mais subgrupos em compara√ß√£o a RWNorm-Mode e RWCov. Cada m√©trica mostrou diferentes vieses, destacando subgrupos espec√≠ficos com comportamentos de prefer√™ncia √∫nicos.\nEsses resultados demonstram a efic√°cia do EPM na identifica√ß√£o de padr√µes de prefer√™ncia excepcionais em diversos contextos, proporcionando insights valiosos sobre comportamentos n√£o usuais em rankings.\n\nTamb√©m foi feita uma compara√ß√£o entre o CORTANA e o CAREN que usava a t√©cnica DR:\n\n\n\nCompara√ß√£o Resultados CAREN vs CORTANA"
  },
  {
    "objectID": "seminario2/artigo6.html#aplica√ß√µes-e-desafios",
    "href": "seminario2/artigo6.html#aplica√ß√µes-e-desafios",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Aplica√ß√µes e desafios",
    "text": "Aplica√ß√µes e desafios\nA minera√ß√£o de prefer√™ncias excepcionais pode ser aplicada em diversos contextos e trazer benef√≠cios. Vamos apresentar abaixo algumas aplica√ß√µes onde o uso de EPM teria grande valor.\nNa √°rea de neg√≥cios, seria poss√≠vel encontrar subpopula√ß√µes que possuem prefer√™ncias divergentes da maioria, o que permitiria a constru√ß√£o de estrat√©gias de marketing direcionado a esses nichos. Al√©m disso, torna-se mais f√°cil a identifica√ß√£o de varia√ß√µes em tend√™ncias de mercado.\nA medicina pode ser positivamente afetada pelo uso de EPM na segmenta√ß√£o de grupos de pacientes com caracter√≠sticas semelhantes. Isso faz com que cada grupo possa receber um tratamento mais especializado.\nOutro exemplo de aplica√ß√£o √© o setor p√∫blico. Nesse caso, o conceito de prefer√™ncia poderia ser usado de forma an√°loga para identificar subgrupos que possuem necessidades espec√≠ficas, possibilitando a cria√ß√£o de pol√≠ticas p√∫blicas direcionadas para atender essas pessoas.\nNa √°rea de gest√£o de recursos humanos, seria interessante utilizar EPM para detectar nichos de funcion√°rios que possuem alguns fatores de motiva√ß√£o e necessidades mais espec√≠ficos. Assim, a equipe de RH poderia agir de maneira mais assertiva, tornando o ambiente de trabalho mais agrad√°vel e inclusivo.\nApesar das possibilidades ben√©ficas citadas acima, √© importante ressaltar os impactos negativos que podem surgir com a aplica√ß√£o da t√©cnica de EPM nesses cen√°rios. O principal impacto identificado √© a manipula√ß√£o de informa√ß√µes. A busca por padr√µes de prefer√™ncias que fogem √† regra geral pode ser usada de forma indevida caso esses padr√µes sejam divulgados como se fossem representativos para toda a popula√ß√£o. Como um exemplo, pode-se pensar no caso em que uma empresa usa as informa√ß√µes de grupos espec√≠ficos para promover seus produtos para o p√∫blico geral, o que configura em uma propaganda enganosa."
  },
  {
    "objectID": "seminario2/artigo6.html#execu√ß√£o-dos-algoritmos-usados-no-artigo",
    "href": "seminario2/artigo6.html#execu√ß√£o-dos-algoritmos-usados-no-artigo",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Execu√ß√£o dos algoritmos usados no artigo",
    "text": "Execu√ß√£o dos algoritmos usados no artigo\nO c√≥digo-fonte desenvolvido pelos autores para elabora√ß√£o do artigo n√£o foi disponibilizado. No entanto, foram encontrados dois reposit√≥rios no GitHub que utilizam as mesmas t√©cnicas e citam o artigo estudado.\n\nReposit√≥rio MD2S_MusicProject\nEste reposit√≥rio n√£o foi muito explorado pela equipe respons√°vel, pois a documenta√ß√£o que explica os detalhes de implementa√ß√£o foi escrita em franc√™s, o que dificultou o entendimento.\nLink para o reposit√≥rio\n\n\nReposit√≥rio My-Sushi-Addiction\nA implementa√ß√£o contida nesse reposit√≥rio aplica a EPM em um dataset de prefer√™ncias de tipos de sushi, mas permite tamb√©m que outros datasets possam ser utilizados. Diferentemente do artigo, o algoritmo de busca usado nessa vers√£o de EPM foi o beam search. No reposit√≥rio, a m√©trica de qualidade √© parametriz√°vel, mas apenas a RWNorm est√° dispon√≠vel para experimenta√ß√£o. Para utilizar outras m√©tricas, √© necess√°rio implement√°-las antes de passar como par√¢metro.\n\n\n\nBase de dados Sushi 2016\n\n\nLink para o reposit√≥rio\n\n0 Quick_Start.ipynb: Realiza a execu√ß√£o do projeto em passos simples, bastando apenas seguir o roteiro do pr√≥prio notebook. √â poss√≠vel at√© aplicar a EPM aos pr√≥prios dados do usu√°rio, n√£o apenas ao dataset do sushi; ‚Äã\n1 Exceptional_Preference_Mining.ipynb: Estruturado como um rascunho, este notebook mostra, passo a passo, como foi implementado o algoritmo de Beam Search e sua aplica√ß√£o ao conjunto de dados de sushi;‚Äã\nbeam_search.py: Fun√ß√µes para o algoritmo de Beam Search;‚Äã\npreference_matrix.py: Fun√ß√µes para calcular e visualizar a Matriz de Prefer√™ncia, e calcular uma pontua√ß√£o de excepcionalidade derivada delas.\n\nO grupo respons√°vel realizou testes, aplicando o EPM sobre o dataset disponibilizado no reposit√≥rio. Os principais subgrupos excepcionais descobertos foram os subgrupos de mulheres com menos de 19 anos e homens que responderam a pesquisa muito rapidamente. Tamb√©m foram feitos experimentos com as outras m√©tricas que n√£o haviam sido previamente disponibilizadas. No geral, os resultados foram semelhantes √†queles vistos com a RWNorm. Uma descoberta not√°vel foi o subgrupo de mulheres com menos de 39 anos de idade com a m√©trica LWNorm.\n\n\n\nResultados Hacker"
  },
  {
    "objectID": "seminario2/artigo6.html#conclus√£o",
    "href": "seminario2/artigo6.html#conclus√£o",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Conclus√£o",
    "text": "Conclus√£o\nO artigo analisado apresenta a t√©cnica de Exceptional Preferences Mining (EPM) como uma abordagem inovadora para a descoberta de subgrupos com padr√µes de prefer√™ncia excepcionais. Atrav√©s de uma compara√ß√£o detalhada com outras t√©cnicas, como SD e EMM, o artigo evidencia a especificidade e a utilidade da EPM. Os experimentos realizados com diversos conjuntos de dados demonstram a efic√°cia da t√©cnica e suas poss√≠veis aplica√ß√µes em √°reas como neg√≥cios, medicina, setor p√∫blico e gest√£o de recursos humanos. Apesar dos benef√≠cios apresentados, √© importante considerar os impactos negativos potenciais, como a manipula√ß√£o de informa√ß√µes. A an√°lise dos reposit√≥rios relacionados tamb√©m fornece informa√ß√µes importantes sobre a implementa√ß√£o pr√°tica da EPM, evidenciando a adaptabilidade e flexibilidade da t√©cnica."
  },
  {
    "objectID": "seminario2/artigo6.html#refer√™ncias",
    "href": "seminario2/artigo6.html#refer√™ncias",
    "title": "Discovering a Taste for the Unusual: Exceptionla Models for Preference Mining",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\nde S√°, C. R., Duivesteijn, W., Azevedo, P., Jorge, A. M., Soares, C., & Knobbe, A. (2018). Discovering a taste for the unusual: exceptional models for preference mining. Machine Learning, 107, 1775-1807."
  },
  {
    "objectID": "seminario2/artigo4.html",
    "href": "seminario2/artigo4.html",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "",
    "text": "A Descoberta de Subgrupos (SD) √© uma √°rea dentro da Minera√ß√£o de Dados e do Aprendizado de M√°quina cujo objetivo √© encontrar subgrupos relevantes em conjuntos de dados. Desde o final dos anos 90, muitas estrat√©gias t√™m sido desenvolvidas para melhorar a efici√™ncia e relev√¢ncia dos resultados na SD. No entanto, ainda existem desafios significativos, como a efici√™ncia na explora√ß√£o do espa√ßo de busca.\nO artigo ‚ÄúAnytime discovery of a diverse set of patterns with Monte Carlo tree search‚Äù prop√µe uma solu√ß√£o inovadora: o m√©todo MTCS4SD. Esse m√©todo utiliza a √Årvore de Busca Monte Carlo (Monte Carlo Tree Search - MCTS), uma heur√≠stica popular em jogos de tomada de decis√£o, para descobrir subgrupos de maneira eficiente e diversificada."
  },
  {
    "objectID": "seminario2/artigo4.html#introdu√ß√£o",
    "href": "seminario2/artigo4.html#introdu√ß√£o",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "",
    "text": "A Descoberta de Subgrupos (SD) √© uma √°rea dentro da Minera√ß√£o de Dados e do Aprendizado de M√°quina cujo objetivo √© encontrar subgrupos relevantes em conjuntos de dados. Desde o final dos anos 90, muitas estrat√©gias t√™m sido desenvolvidas para melhorar a efici√™ncia e relev√¢ncia dos resultados na SD. No entanto, ainda existem desafios significativos, como a efici√™ncia na explora√ß√£o do espa√ßo de busca.\nO artigo ‚ÄúAnytime discovery of a diverse set of patterns with Monte Carlo tree search‚Äù prop√µe uma solu√ß√£o inovadora: o m√©todo MTCS4SD. Esse m√©todo utiliza a √Årvore de Busca Monte Carlo (Monte Carlo Tree Search - MCTS), uma heur√≠stica popular em jogos de tomada de decis√£o, para descobrir subgrupos de maneira eficiente e diversificada."
  },
  {
    "objectID": "seminario2/artigo4.html#conceitos-e-adapta√ß√µes",
    "href": "seminario2/artigo4.html#conceitos-e-adapta√ß√µes",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "Conceitos e Adapta√ß√µes",
    "text": "Conceitos e Adapta√ß√µes\n\nFundamentos do M√©todo\nO MTCS4SD adapta a heur√≠stica da √Årvore de Busca de Monte Carlo, que se baseia em quatro etapas principais:\n\nSelect: Seleciona recursivamente um n√≥ filho a partir da raiz at√© encontrar um n√≥ n√£o totalmente expandido, utilizando a m√©trica UCT.\nExpand: Adiciona aleatoriamente uma nova dire√ß√£o a partir do n√≥ selecionado.\nRollout: Simula aleatoriamente as pr√≥ximas a√ß√µes at√© chegar a um terminal, avaliando a recompensa.\nUpdate: Propaga o resultado obtido para os n√≥s superiores, atualizando os valores de recompensa acumulada e o n√∫mero de visitas.\n\n\n\n\nEtapas da √Årvore de Busca de Monte Carlo.\n\n\n\n\nAdapta√ß√£o para Descoberta de Subgrupos\nPara o contexto de SD, o m√©todo sofre algumas adapta√ß√µes:\n\nSelect: Utiliza-se a SP-MCTS para selecionar subgrupos promissores, considerando a vari√¢ncia da recompensa.\nExpand: Refinamento para obter descri√ß√µes mais espec√≠ficas, evitando descritores fechados e duplica√ß√µes.\nRollout: Pode executar at√© que o padr√£o seja infrequente, agregando os resultados da simula√ß√£o.\nUpdate: Utiliza a maior propaganda para priorizar as melhores recompensas.\n\nA execu√ß√£o prolongada do algoritmo permite uma busca exaustiva, embora existam hiperpar√¢metros que limitam o n√∫mero de execu√ß√µes."
  },
  {
    "objectID": "seminario2/artigo4.html#metodologia-e-resultados",
    "href": "seminario2/artigo4.html#metodologia-e-resultados",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "Metodologia e Resultados",
    "text": "Metodologia e Resultados\nO m√©todo foi comparado com outros algoritmos da √°rea, como SD-Map*, Beam Search, SSDP e Misere, usando m√©tricas como qualidade m√©dia, tempo de execu√ß√£o, redund√¢ncia, diversidade e uso de mem√≥ria. Os resultados mostraram que o MCTS4SD encontra conjuntos de padr√µes mais diversos, embora com um custo um pouco maior de redund√¢ncia em alguns casos.\n\n\n\nIlustra√ß√£o de diferentes algoritmos de busca. a) Redundancy problem. b) Beam search. c) Sampling exploration. d) MCTS-based exploration.\n\n\n\nResultados das Compara√ß√µes\n\nBeam Search: MCTS4SD produziu resultados mais diversos.\nSSDP e m√©todos de amostragem: MCTS4SD garantiu a busca por √≥timos locais, algo que esses m√©todos n√£o conseguem.\nM√©todos exaustivos: MCTS4SD obteve resultados onde m√©todos exaustivos falharam devido a limita√ß√µes de recursos.\n\nAs vantagens incluem flexibilidade, alta diversidade e converg√™ncia para uma busca exaustiva, embora consuma muita mem√≥ria e explore intensamente o espa√ßo de busca."
  },
  {
    "objectID": "seminario2/artigo4.html#impacto-social-e-considera√ß√µes-√©ticas",
    "href": "seminario2/artigo4.html#impacto-social-e-considera√ß√µes-√©ticas",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "Impacto Social e Considera√ß√µes √âticas",
    "text": "Impacto Social e Considera√ß√µes √âticas\nA aplica√ß√£o do MTCS4SD em √°reas como sa√∫de, seguran√ßa, agricultura e ecologia traz consigo um potencial incr√≠vel, mas tamb√©m levanta quest√µes √©ticas e sociais importantes. Vamos analisar os benef√≠cios, riscos e responsabilidades de cada √°rea:\n\nSa√∫de\n\nBenef√≠cio: Detectar doen√ßas precocemente, possibilitando tratamentos mais eficazes e personalizados.\nRiscos: Quebra de privacidade dos pacientes, acesso desigual √† tecnologia (aumentando a desigualdade social) e decis√µes automatizadas que desconsideram o lado humano da medicina.\nResponsabilidades: Garantir a seguran√ßa dos dados dos pacientes, promover o acesso igualit√°rio √† tecnologia e garantir que a tomada de decis√£o m√©dica continue considerando o paciente como um todo.\n\nSeguran√ßa\n\nBenef√≠cio: Prevenir crimes de forma mais eficiente, utilizando recursos de forma otimizada.\nRiscos: Refor√ßar discrimina√ß√µes e vieses existentes nos dados, gerar desconfian√ßa na justi√ßa e amea√ßar liberdades individuais.\nResponsabilidades: Assegurar que os dados utilizados sejam neutros e imparciais, operar com transpar√™ncia e garantir que os direitos individuais sejam preservados.\n\nAgricultura\n\nBenef√≠cio: Aumentar a produ√ß√£o de alimentos e otimizar o uso de recursos naturais.\nRiscos: Excluir pequenos agricultores do acesso √† tecnologia, aumentar a depend√™ncia tecnol√≥gica e gerar impactos sociais negativos, como o desemprego.\nResponsabilidades: Promover o acesso √† tecnologia de forma democr√°tica, considerar os impactos sociais de sua implementa√ß√£o e garantir uma produ√ß√£o agr√≠cola mais justa e sustent√°vel.\n\nEcologia\n\nBenef√≠cio: Gerenciar recursos naturais de forma mais eficiente e proteger o meio ambiente.\nRiscos: Dificultar o acesso √† tecnologia devido √† complexidade e custos, centralizar o conhecimento e desconsiderar as comunidades locais na tomada de decis√£o.\nResponsabilidades: Buscar solu√ß√µes acess√≠veis e f√°ceis de usar, democratizar o conhecimento e garantir que as a√ß√µes beneficiem a todos, principalmente as comunidades mais afetadas pelos problemas ambientais."
  },
  {
    "objectID": "seminario2/artigo4.html#c√≥digo-aberto-e-documenta√ß√£o",
    "href": "seminario2/artigo4.html#c√≥digo-aberto-e-documenta√ß√£o",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "C√≥digo Aberto e Documenta√ß√£o",
    "text": "C√≥digo Aberto e Documenta√ß√£o\nOs autores disponibilizaram o c√≥digo do MTCS4DM como software de c√≥digo aberto no GitHub. O reposit√≥rio inclui datasets, arquivos execut√°veis, scripts para experimentos e visualiza√ß√£o de resultados.\n\n1. Instala√ß√£o do Java\nPara executar o programa MCTS4DM, √© necess√°rio instalar o Java Development Kit (JDK) e o Java Runtime Environment (JRE) na vers√£o 22. Siga os passos abaixo para realizar a instala√ß√£o:\n\n1.1. Baixar e instalar o JDK\n\nAcesse o site oficial da Oracle: Oracle JDK 22.\nEscolha a vers√£o adequada, indicamos o JDK 22.0.1, para o seu sistema operacional (Windows, macOS ou Linux) e fa√ßa o download do instalador.\nExecute o instalador baixado e siga as instru√ß√µes na tela para concluir a instala√ß√£o.\n\n\n\n1.2. Configurar a vari√°vel de ambiente JAVA_HOME\n\nNo Windows, abra o Painel de Controle e v√° em ‚ÄúSistema e Seguran√ßa‚Äù &gt; ‚ÄúSistema‚Äù &gt; ‚ÄúConfigura√ß√µes avan√ßadas do sistema‚Äù &gt; ‚ÄúVari√°veis de ambiente‚Äù.\nCrie uma nova vari√°vel de sistema chamada JAVA_HOME e defina seu valor para o caminho onde o JDK foi instalado, por exemplo, C:\\Program Files\\Java\\jdk-20.\nAdicione %JAVA_HOME%\\bin ao PATH nas vari√°veis de sistema.\n\n\n\n1.3. Verificar a instala√ß√£o\n\nAbra o terminal (Prompt de Comando no Windows, Terminal no macOS ou Linux) e digite java -version e javac -version para verificar se o Java foi instalado corretamente.\n\n\n\n\n2. Clonar o Reposit√≥rio\nPara obter o c√≥digo fonte do MCTS4DM, voc√™ precisa clonar o reposit√≥rio do GitHub. Siga os passos abaixo para clonar o reposit√≥rio em diferentes sistemas operacionais:\n\n2.1. Windows\n\nBaixe e instale o Git a partir do site oficial: Git para Windows.\nAp√≥s a instala√ß√£o, abra o Git Bash.\nNo Git Bash, execute o seguinte comando para clonar o reposit√≥rio:\ngit clone https://github.com/guillaume-bosc/MCTS4DM.git\n\n\n\n2.2. macOS\n\nAbra o Terminal.\nInstale o Git usando o Homebrew com o comando:\nbrew install git\nNo Terminal, execute o comando para clonar o reposit√≥rio:\ngit clone https://github.com/guillaume-bosc/MCTS4DM.git\n\n\n\n2.3. Linux\n\nAbra o Terminal.\nInstale o Git usando o gerenciador de pacotes da sua distribui√ß√£o Linux, por exemplo, no Ubuntu:\n\nsudo apt - get install git\n\nNo Terminal, execute o comando para clonar o reposit√≥rio:\ngit clone https://github.com/guillaume-bosc/MCTS4DM.git\n\n\n\n\n3. Executar o MCTS4DM\nDepois de configurar o ambiente Java, √© hora de executar o MCTS4DM. Primeiro, certifique-se de que os arquivos de dataset e o arquivo de configura√ß√£o de par√¢metros estejam preparados. Em seguida, siga os passos abaixo:\n\n3.1. Preparar os arquivos de dataset e configura√ß√£o\n\nNavegue at√© a pasta datasets no diret√≥rio onde o programa MCTS4DM est√° localizado.\nDentro da pasta datasets, crie uma pasta exclusiva para o dataset, por exemplo, BreastCancer.\nColoque os arquivos properties.csv e qualities.csv dentro da pasta BreastCancer, por exemplo.\nCertifique-se de que o arquivo parameters.conf esteja configurado corretamente, apontando para os caminhos relativos dos arquivos de dataset. O arquivo padr√£o do reposit√≥rio parameters.conf explica cada par√¢metro e como configurar.\n\n\n\n3.2. Formato dos arquivos de dataset\n\nproperties.csv: Cont√©m a tabela de atributos, onde cada linha √© um objeto e cada coluna √© um atributo. O separador entre colunas deve ser \\t.\nqualities.csv: Cont√©m a tabela de r√≥tulos, onde cada linha √© um objeto (na mesma ordem do properties.csv) e cada coluna √© um r√≥tulo de alvo.\n\n\n\n3.3. Executar o MCTS4DM\n\nNo terminal, navegue at√© a pasta onde est√° o arquivo MCTS4DM.jar.\nExecute o comando:\njava -jar MCTS4DM.jar &lt;caminho para o arquivo de configura√ß√£o&gt;\nPor exemplo:\njava -jar MCTS4DM.jar parameters.conf\n\n\n\n\n4. Resultados da Execu√ß√£o\nAp√≥s a execu√ß√£o do programa, os resultados estar√£o dispon√≠veis na pasta especificada no par√¢metro resultFolderName dentro da pasta results. Quatro arquivos ser√£o gerados:\n\ninfo.log: Cont√©m os valores dos par√¢metros utilizados, o tempo de execu√ß√£o e a data da execu√ß√£o.\nresults.log: Cada linha cont√©m um subgrupo no formato &lt;Descri√ß√£o&gt;\\t&lt;Alvos&gt;\\t&lt;Medida&gt;\\t&lt;E11&gt;\\t&lt;E10&gt;\\t&lt;E01&gt;. Onde E11 √© o n√∫mero de objetos que respeitam a descri√ß√£o e est√£o associados aos alvos, E10 √© o n√∫mero de objetos que respeitam a descri√ß√£o mas n√£o est√£o associados aos alvos, e E01 √© o n√∫mero de objetos que n√£o respeitam a descri√ß√£o mas est√£o associados aos alvos.\nsupport.log: Cont√©m o suporte de cada subgrupo, onde cada linha corresponde ao suporte do subgrupo correspondente no arquivo results.log.\nsupportE11.log: Cont√©m apenas os IDs dos objetos em E11.\n\n\n\n5. Gera√ß√£o de Plots com Base nos Resultados\nPara gerar plots dos resultados obtidos, siga os passos abaixo:\n\n5.1. Acessar a pasta GenerateDataPlot\n\nNavegue at√© a pasta GenerateDataPlot no terminal.\n\n\n\n5.2. Executar o comando para gerar plots\n\nExecute o comando:\njava -jar GenerateDataPlot.jar\n\n\n\n5.3. Executar os scripts de bash\n\nNo terminal, v√° at√© a pasta RunExperiments/results.\nExecute os seguintes scripts para gerar os gr√°ficos:\n./launchLength.sh\n./launchQuality.sh\n./launchRuntime.sh\n\n\n\n5.4. Verificar os resultados\n\nOs resultados dos gr√°ficos estar√£o dispon√≠veis na pasta RunExperiments/results/NbInterations/ com o nome do dataset correspondente.\nOs gr√°ficos gerados estar√£o em formato .pdf e prontos para an√°lise.\n\n\n\n\n6. Executar Experimentos em Lotes\nA pasta RunExperiments cont√©m o programa que pode executar automaticamente o algoritmo para todos os datasets. Nesta pasta, a pasta results cont√©m os resultados dos lotes, a pasta src cont√©m os c√≥digos-fonte deste programa, o arquivo RunExperiments.jar, e o arquivo paramGen.conf para configura√ß√£o, assim como √© o arquivo parameters.conf. Para executar, use o comando:\njava -jar RunExperiments.jar [options]\nAs op√ß√µes dispon√≠veis s√£o escolhidas entre {ucb, expand, rollout, memory, update, iter}, que permitem executar o experimento de uma estrat√©gia definida de MCTS.\n\nucb: Executa experimentos usando a estrat√©gia Upper Confidence Bound (UCB).\nexpand: Executa experimentos focando na expans√£o da √°rvore.\nrollout: Executa experimentos utilizando a estrat√©gia de rollout.\nmemory: Executa experimentos com foco em otimiza√ß√µes de mem√≥ria.\nupdate: Executa experimentos aplicando estrat√©gias de atualiza√ß√£o.\niter: Executa experimentos atrav√©s de itera√ß√µes espec√≠ficas.\n\nPara iniciar o programa com uma op√ß√£o espec√≠fica, use o comando no terminal, por exemplo:\njava -jar RunExperiments.jar ucb\nOs resultados dos experimentos ser√£o armazenados na pasta results dentro de uma hierarquia definida, facilitando a an√°lise dos diferentes experimentos realizados."
  },
  {
    "objectID": "seminario2/artigo4.html#discuss√µes-e-pontos-relevantes",
    "href": "seminario2/artigo4.html#discuss√µes-e-pontos-relevantes",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "Discuss√µes e Pontos Relevantes",
    "text": "Discuss√µes e Pontos Relevantes\nDurante a discuss√£o do semin√°rio, v√°rios pontos foram levantados:\n\nVi√©s: A aplica√ß√£o em seguran√ßa p√∫blica gerou preocupa√ß√µes sobre o potencial de refor√ßar vieses existentes. √â crucial garantir a justi√ßa e a equidade na aplica√ß√£o do m√©todo.\nAvalia√ß√£o da Qualidade dos Grupos: A forma como a qualidade dos grupos √© avaliada no artigo gerou debate, levantando a necessidade de m√©tricas mais robustas e transparentes.\nCompara√ß√£o com Abordagens Num√©ricas: A falta de compara√ß√£o com m√©todos num√©ricos foi apontada como uma limita√ß√£o do estudo.\nImport√¢ncia da Diversidade: A capacidade do MCTS4DM em encontrar subgrupos diversos foi destacada como um diferencial importante em rela√ß√£o a outros m√©todos."
  },
  {
    "objectID": "seminario2/artigo4.html#conclus√µes",
    "href": "seminario2/artigo4.html#conclus√µes",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "Conclus√µes",
    "text": "Conclus√µes\nO artigo apresenta o MTCS4SD como uma abordagem promissora para a descoberta de subgrupos, demonstrando vantagens em rela√ß√£o a m√©todos tradicionais em termos de qualidade, diversidade e flexibilidade.\nNo entanto, √© importante destacar que a implementa√ß√£o deste m√©todo traz consigo quest√µes √©ticas e sociais importantes, especialmente quando aplicado em √°reas sens√≠veis como sa√∫de, seguran√ßa, agricultura e ecologia. Portanto, ao utilizar o MTCS4DM, √© crucial considerar esses aspectos e garantir que o m√©todo seja usado de maneira respons√°vel e √©tica.\nPor fim, a disponibiliza√ß√£o do c√≥digo-fonte e a descri√ß√£o detalhada do processo de execu√ß√£o fornecem uma base s√≥lida para futuras pesquisas e desenvolvimentos na √°rea de Descoberta de Subgrupos. Isso abre caminho para novas possibilidades de explora√ß√£o e aprimoramento do MCTS, contribuindo para o avan√ßo cont√≠nuo do campo de Aprendizado de M√°quina."
  },
  {
    "objectID": "seminario2/artigo4.html#refer√™ncias",
    "href": "seminario2/artigo4.html#refer√™ncias",
    "title": "Artigo 4: Anytime discovery of a diverse set of patterns with Monte Carlo tree search",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\n\nBosc, G., Boulicaut, JF., Ra√Øssi, C. et al.¬†Anytime discovery of a diverse set of patterns with Monte Carlo tree search. Data Min Knowl Disc 32, 604‚Äì650 (2018). Link para o artigo"
  },
  {
    "objectID": "seminario1/artigo3.html",
    "href": "seminario1/artigo3.html",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "",
    "text": "A minera√ß√£o de dados √© uma √°rea de estudo e pesquisa cada vez mais frequente devido ao seu impacto e capacidade de extra√ß√£o de informa√ß√µes relevantes em grandes conjuntos de dados. Nesse sentido, uma das principais sub√°reas de minera√ß√£o de dados √© a de minera√ß√£o de subgrafos frequentes.\nEm termos gerais, dado um grafo, essa √°rea de pesquisa se concentra em descobrir algoritmos e heur√≠sticas que permitem analisar quais s√£o os subgrafos de maior import√¢ncia (motif) e que ocorrem com maior frequ√™ncia dentro desse mesmo grafo. Sabe-se que esse √© um problema de natureza dif√≠cil, devido √† alta explos√£o combinat√≥ria do espa√ßo de solu√ß√£o. Por isso, muitos estudos s√£o feitos para desenvolver uma abordagem eficiente de solu√ß√£o do problema."
  },
  {
    "objectID": "seminario1/artigo3.html#contextualiza√ß√£o-do-problema",
    "href": "seminario1/artigo3.html#contextualiza√ß√£o-do-problema",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Contextualiza√ß√£o do Problema",
    "text": "Contextualiza√ß√£o do Problema\nA motiva√ß√£o para desenvolver solu√ß√µes nesse tipo de an√°lise de dados √© diversa. Dentre as √°reas em que √© poss√≠vel aplicar essa t√©cnica, podemos destacar: a biologia e a qu√≠mica, no estudo e pesquisa de f√°rmacos e das rela√ß√µes entre √°tomos e liga√ß√µes qu√≠micas; o setor de transporte, na an√°lise de rotas mais eficientes e baratas para deslocamento; assim como redes de computadores, no estudo das conex√µes entre diferentes computadores e servidores de modo a encontrar redistribui√ß√µes mais r√°pidas e eficientes de pacotes, entre outras."
  },
  {
    "objectID": "seminario1/artigo3.html#algoritmos-cl√°ssicos",
    "href": "seminario1/artigo3.html#algoritmos-cl√°ssicos",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Algoritmos Cl√°ssicos",
    "text": "Algoritmos Cl√°ssicos\nOs algoritmos cl√°ssicos de minera√ß√£o de subgrafos frequentes baseiam-se em abordagens similares √†quelas usadas na minera√ß√£o de conjuntos de itens frequentes. Em resumo, consistem na gera√ß√£o de candidatos e no crescimento de padr√µes para encontrar os subgrafos recorrentes na base de dados.\nTais abordagens apresentam tanto vantagens como desvantagens, dentre as quais vale destacar:\n\n\n\n\n\n\n\n\n\nGera√ß√£o de Candidatos\nCrescimento de Padr√µes\n\n\n\n\nVantagens\n- Simples\n- Redu√ß√£o do espa√ßo de busca por meio de podas\n\n\n\n- Natural\n- Elimina√ß√£o de redund√¢ncias\n\n\n\n\n\n\n\nDesvantagens\n- Explos√£o combinat√≥ria do n√∫mero de candidatos\n- Alto custo na verifica√ß√£o dos subgrafos\n\n\n\n- Extremamente ineficiente em grandes grafos\n- Ineficiente em grandes grafos\n\n\n\n- Consome grande quantidade de recursos como mem√≥ria"
  },
  {
    "objectID": "seminario1/artigo3.html#spminer-uma-abordagem-inovadora",
    "href": "seminario1/artigo3.html#spminer-uma-abordagem-inovadora",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "SPMiner: Uma abordagem inovadora",
    "text": "SPMiner: Uma abordagem inovadora\nCom o problema contextualizado, fica evidente a import√¢ncia da pesquisa conduzida pelos autores do artigo. A abordagem proposta por eles consiste no uso de aprendizado profundo para tornar a computa√ß√£o dos subgrafos frequentes eficiente. A ideia principal √© utilizar uma Rede Neural em Grafos (GNN) para mapear subgrafos para um espa√ßo ordenado de embeddings multidimensional de modo que a busca por subgrafos frequentes nesse espa√ßo seja mais r√°pida.\nA constru√ß√£o da rede neural foi feita justamente com esse objetivo, de modo que a arquitetura e a fun√ß√£o de perda utilizada garantam que a rela√ß√£o de ordem parcial entre subgrafos seja mantida. Em termos gerais, se um subgrafo A √© subgrafo de B, ent√£o A se encontra abaixo e √† esquerda de B no espa√ßo de embeddings citado."
  },
  {
    "objectID": "seminario1/artigo3.html#o-algoritmo-do-spminer",
    "href": "seminario1/artigo3.html#o-algoritmo-do-spminer",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "O Algoritmo do SPMiner",
    "text": "O Algoritmo do SPMiner\nIdentificar subgrafos frequentes de import√¢ncia, tamb√©m chamados de Redes Funcionais (Network Motif) √© crucial para analisar e prever propriedades de redes do mundo real. Contudo, encontrar grandes redes funcionais comuns √© um problema desafiador n√£o apenas devido √† sua sub-rotina NP Dif√≠cil de contagem de subgrafos, mas tamb√©m ao crescimento exponencial do n√∫mero de poss√≠veis padr√µes de subgrafos.\nO algoritmo SPMiner alia o poder das seguintes √°reas: redes neurais de grafos, espa√ßos latentes ordenados (order embedding space) e uma estrat√©gia de busca eficiente no espa√ßo de possibilidades. Isso possibilita a identifica√ß√£o de padr√µes de subgrafos de rede que aparecem com mais frequ√™ncia no grafo de destino.\nPara tal, de forma simplificada e ordenada, ele segue os seguintes passos:\n\nDecomp√µe o grafo de destino em subgrafos sobrepostos ancorados;\nMapeia cada subgrafo do passo anterior em um espa√ßo multidimensional latente ordenado;\nUtiliza um caminhamento monot√¥nico no espa√ßo resultante do passo anterior;\nIdentifica as Redes Funcionais frequentes.\n\nO algoritmo n√£o √© exato, por√©m o tempo de execu√ß√£o √© mais de 100 vezes menor do que os algoritmos exatos e √© preciso para subgrafos pequenos. Como limita√ß√£o ele n√£o √© capaz de retornar a frequ√™ncia dos elementos. De uma maneira geral ele representa uma inova√ß√£o na √°rea e sua estrutura b√°sica pode inspirar na busca de solu√ß√µes para outros problemas de mesma magnitude, a exemplo dos combinatoriais.\n\n\n\nDiagrama representativo do encoder e decoder do SPMiner\n\n\nAbaixo segue a descri√ß√£o detalhada de cada passo.\nA decomposi√ß√£o do grafo inicial √© baseada na defini√ß√£o de redes funcionais ancoradas. Define-se \\(G_T\\) o grafo inicial, decomposto em seus v√©rtices \\(V_T\\) e arestas \\(E_T\\) da seguinte forma \\(G_T=(V_T,E_T)\\). Analogamente, define-se \\(G_Q=(V_Q,E_Q)\\) como sendo a busca de uma rede funcional. O problema √© determinar se uma c√≥pia isom√≥rfica de \\(G_Q\\) aparece em \\(G_T\\), ou seja, se existe uma fun√ß√£o injetora entre os v√©rtices e arestas de ambos.\nA defini√ß√£o de um subgrafo ancorado √© dada da seguinte forma: Seja \\((G_Q, v)\\) um padr√£o de subgrafo ancorado no v√©rtice \\(v\\). A frequ√™ncia do motivo \\(G_Q\\) no conjunto de dados do grafo \\(G_T\\), em rela√ß√£o √† √¢ncora \\(v\\), √© o n√∫mero de v√©rtices \\(u\\), em \\(G_T\\) para o qual existe um isomorfismo de subgrafo \\(f: V_Q‚Üí V_T\\) tal que \\(f(v) = u\\).\nDefine-se a frequ√™ncia como o n√∫mero de subconjuntos exclusivos de v√©rtices \\(S ‚äÇ V_T\\) para onde existe um isomorfismo de subgrafo \\(f : V_Q ‚Üí V_T\\) cuja imagem √© \\(S\\). Comparado com estado da arte, esta medida √© mais robusta a outliers, prov√™ uma vis√£o hol√≠stica e satisfaz a propriedade de Downward Closure Property (DCP).\n\n\n\nDiferen√ßa entre a frequ√™ncia de subgrafos ancorados em n√≥s e em n√≠vel de grafo.\n\n\nNa imagem acima, encontram-se no grafo √† esquerda uma frequ√™ncia de \\(\\binom{100}{6}\\) subgrafos isom√≥rficos ao grafo da direita e uma medida ancorada de 1.\nPortanto, dado um grafo \\(G_T\\), um par√¢metro de tamanho de subgrafo \\(K\\) e o n√∫mero desejado de resultados \\(R\\), o objetivo do SPMiner √© identificar, dentre todos os poss√≠veis grafos de \\(K\\) v√©rtices, os \\(R\\) subgrafos com a maior frequ√™ncia em \\(G_T\\).\nDadas as defini√ß√µes, a decomposi√ß√£o de \\(G_T\\) √© feita extraindo os k-hop vizinhos \\(G_V\\) ancorada em cada v√©rtice \\(v\\), ou seja, os que cont√©m todos os v√©rtices que t√™m o caminho mais curto de no m√°ximo \\(k\\) para o v√©rtice \\(v\\).\nO processo de mapeamento para o espa√ßo latente ordenado √© feito por uma rede neural utilizando o n√≥ √¢ncora como uma feature categ√≥rica. O SPMiner usa essa Rede Neural de Grafo (GNN) para aprender uma fun√ß√£o de incorpora√ß√£o œÜ, que mapeia os vizinhos ancorados em n√≥s em pontos no espa√ßo latente tal que a propriedade do subgrafo √© preservada. √â importante ressaltar que o SPMiner GNN √© treinado apenas uma vez e depois pode ser aplicado a qualquer grafo de destino em qualquer dom√≠nio.\nPara caminhar no espa√ßo latente, o trabalho sugere tr√™s estrat√©gias: a heur√≠stica gulosa, a busca em feixes e o algoritmo Monte Carlo Tree Search (MTCS). Para a estrat√©gia gulosa, o trabalho apresenta a fun√ß√£o de perda que ser√° avaliada. No algoritmo de busca em feixe, concilia-se a busca em profundidade com a estrat√©gia gulosa. J√° para o algoritmo MTCS, o trabalho apresenta uma fun√ß√£o objetivo com base no crit√©rio superior de confian√ßa para √°rvores (UCT).\nDessa forma, dado o resultado da explora√ß√£o do espa√ßo, o algoritmo informa os subgrafos mais frequentes."
  },
  {
    "objectID": "seminario1/artigo3.html#metodologia-experimental",
    "href": "seminario1/artigo3.html#metodologia-experimental",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Metodologia Experimental",
    "text": "Metodologia Experimental\nO SPMiner foi comparado com outros m√©todos aproximativos e, quando vi√°vel, com m√©todos de enumera√ß√£o exata. As compara√ß√µes podem ser divididas em 3 grupos: subgrafos pequenos, subgrafos grandes plantados e subgrafos grandes reais.\nPara os subgrafos pequenos, a compara√ß√£o com m√©todos de enumera√ß√£o exata √© poss√≠vel, o que torna a compara√ß√£o de desempenho mais s√≥lida. Os subgrafos grandes plantados s√£o subgrafos gerados artificialmente. A ideia √© ter um par√¢metro mais realista do desempenho na pr√°tica. A abordagem √© vantajosa, pois combina grafos maiores, que s√£o o conjunto de interesse para a aplica√ß√£o, e permite avaliar o desempenho de forma mais objetiva. A √∫ltima abordagem, a de compara√ß√£o com grafos grandes reais, contrasta com os m√©todos aproximativos, mas √© a que melhor aproxima o uso pr√°tico. Os datasets utilizados nessa fase incluem aplica√ß√µes em diversos dom√≠nios: biologia (ENZYMES), qu√≠mica (COX2) e imagens (MSRC).\nTamb√©m foi feita uma compara√ß√£o do tempo de execu√ß√£o. Foram usados dois algoritmos como baseline: o MFInder (Kashtan et al., 2004) e o RAND-ESU (Wernicke, 2006). Os par√¢metros foram adequados para se obter um n√∫mero compar√°vel de subgrafos e tempo de execu√ß√£o."
  },
  {
    "objectID": "seminario1/artigo3.html#resultados",
    "href": "seminario1/artigo3.html#resultados",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Resultados",
    "text": "Resultados\nO SPMiner tem uma acur√°cia significativa na identifica√ß√£o de motifs nos subgrafos pequenos. O SPMiner encontra motifs de tamanho 5 e 6 em at√© 90% das vezes. A compara√ß√£o de tempo de execu√ß√£o √© dr√°stica: o m√©todo de enumera√ß√£o ESU (Wernicke, 2006) demora cerca de 10 horas, enquanto o SPMiner executa em apenas 5 minutos. Similarmente, para os subgrafos plantados, o desempenho tamb√©m foi satisfat√≥rio.\n\n\n\nCompara√ß√£o entre SPMiner e principais algoritmos aproximados de minera√ß√£o de subgrafos. Os 10 principais motifs identificados pelo SPMiner t√™m frequ√™ncia mais alta do que aqueles encontrados pelas baselines, para motifs de tamanho 5 e tamanho 6\n\n\n\n\n\nCompara√ß√£o das frequ√™ncias medianas de motifs identificados por diferentes estrat√©gias de busca e baselines.O SPMiner encontra padr√µes com uma frequ√™ncia ancorada em n√≥s mais alta do que as baselines MLP neural ou as baseadas em amostragem Rand-ESU e MFinder, nos conjuntos de dados COX2 (A), ENZYMES (B) e ENZYMES (C)\n\n\n\n\n\nFrequ√™ncia de motifs identificados por Gaston, gSpan, Motivo e SPMiner. O SPMiner √© capaz de identificar motifs de alta frequ√™ncia de grande tamanho\n\n\n\n\n\nCompara√ß√£o de tempo de execu√ß√£o entre m√©todos n√£o neurais e o SPMiner\n\n\nPara os subgrafos grandes reais, a identifica√ß√£o dos motifs foi de 10 a 100 vezes mais frequente. Al√©m disso, o SPMiner consegue identificar motifs grandes, com 10 v√©rtices ou mais, enquanto a mediana dos baselines √© 3. Uma das vantagens do SPMiner √© o pr√©-treinamento, que √© executado apenas uma vez e √© generaliz√°vel para qualquer grafo. Isso reduz drasticamente o tempo de execu√ß√£o, em particular se comparado aos m√©todos exatos.\nApesar das vantagens, o algoritmo tamb√©m possui suas limita√ß√µes. O treino com grafos aleat√≥rios pode limitar sua aplicabilidade em an√°lise de bancos de dados reais. Al√©m disso, o algoritmo retorna apenas os k motifs mais frequentes, sem considerar a ordena√ß√£o."
  },
  {
    "objectID": "seminario1/artigo3.html#aplica√ß√µes-e-desafios",
    "href": "seminario1/artigo3.html#aplica√ß√µes-e-desafios",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Aplica√ß√µes e Desafios",
    "text": "Aplica√ß√µes e Desafios\nO uso de algoritmos de recupera√ß√£o de informa√ß√£o relacionados a subgrafos √© amplamente difundido no meio industrial, acad√™mico e social, tais como: 1. no meio industrial, destacam-se a ind√∫stria qu√≠mica e farmac√™utica na produ√ß√£o de elementos qu√≠micos espec√≠ficos e f√°rmacos; 2. na engenharia de software, destaca-se a sua utiliza√ß√£o no desenvolvimento de fluxos de controle de aplica√ß√µes; 3. no com√©rcio eletr√¥nico, t√™m-se os sistemas de recomenda√ß√£o; 4. no setor banc√°rio, atua na detec√ß√£o de fraudes, 5. na cadeia de suprimentos, detecta rotas e identifica padr√µes log√≠sticos; 6. no meio acad√™mico, a √°rea da bioinform√°tica destaca-se em quest√µes ligadas a redes de prote√≠nas e conjuntos de prote√≠nas; 7. na ci√™ncia ambiental, auxilia na identifica√ß√£o de habitats cr√≠ticos para a conserva√ß√£o; 8. no meio social, destaca-se detec√ß√£o de rotas frequentes para planejamento urbano, novos neg√≥cios e defini√ß√£o de rotas de fuga.\nO algoritmo tamb√©m possui tais desvantagens: 1. pela an√°lise de redes sociais √© poss√≠vel propagar informa√ß√µes maliciosas, perda de privacidade e perda da autonomia individual; 2. na √°rea comercial √© poss√≠vel induzir o consumo desnecess√°rio.\nDentre os usos espec√≠ficos do algoritmo, incluem-se artigos de aplica√ß√£o para a detec√ß√£o de rumores ou not√≠cias falsas em redes sociais (Detecting rumours with latency guarantees using massive streaming data). E um novo algoritmo chamado Multi-SPMiner j√° foi proposto (Multi-SPMiner: A Deep Learning Framework for Multi-Graph Frequent Pattern Mining with Application to spatiotemporal Graphs)."
  },
  {
    "objectID": "seminario1/artigo3.html#como-usar-o-spminer",
    "href": "seminario1/artigo3.html#como-usar-o-spminer",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Como Usar o SPMiner",
    "text": "Como Usar o SPMiner\nJure Leskovec, professor da Universidade Stanford e um dos autores do artigo que apresenta o SPMiner, comanda um projeto denominado Stanford Network Analysis Platform (SNAP). O projeto consiste no desenvolvimento e manuten√ß√£o de um sistema de c√≥digo aberto para a an√°lise de redes complexas. Um dos m√≥dulos do SNAP, √© o Neural Subgraph Learning (NSL), que consiste em uma biblioteca com v√°rias rotinas dedicadas ao aprendizado de rela√ß√µes de subgrafos, e um dos algoritmos implementados √© o SPMiner.\nA fim de solucionar problemas de compatibilidade de bibliotecas, conflitos de instala√ß√£o e facilitar a execu√ß√£o em ambientes diferentes, foram feitas modifica√ß√µes na implementa√ß√£o disponibilizada pelo SNAP e gerado um arquivo para a cria√ß√£o de um ambiente Docker. O reposit√≥rio completo, que inclui um pequeno tutorial para a execu√ß√£o do SPMiner via Docker, pode ser acessado neste link.\nAl√©m da implementa√ß√£o do SPMiner, os desenvolvedores do projeto SNAP tamb√©m disponibilizaram datasets que podem ser utilizados para testar o funcionamento do algoritmo, al√©m de scripts para diferentes an√°lises dos resultados. Experimentos locais utilizando o dataset COX2, executando o SPMiner, sem GPU, obtiveram tempo de execu√ß√£o pr√≥ximo de 40 minutos.\n\n\n\nSubgrafos frequentes de tamanho 5, 12 e 20, respectivamente, resultantes da minera√ß√£o de padr√µes no dataset COX2, composto por 467 grafos. A minera√ß√£o foi realizada utilizando a estrat√©gia de pesquisa Greedy, com padr√µes identificados tendo tamanho m√≠nimo de 5 e m√°ximo de 20. O processo de minera√ß√£o levou 40 minutos e 17 segundos\n\n\n\nDados de entrada\nH√° alguns datasets no reposit√≥rio, mas para uma aplica√ß√£o real, o usu√°rio pode alterar o arquivo de entrada, bem como outros par√¢metros: tamanho m√≠nimo e/ou m√°ximo dos subgrafos frequentes, estrat√©gia de pesquisa, dentre outros.\nOs dados de entrada est√£o no formato txt:\n\nA representa√ß√£o de cada grafo √© inicializada por uma linha do tipo:\nt # {id do grafo}\nEm seguida, n linhas, cada uma representa um v√©rtice:\nv {id do v√©rtice} {r√≥tulo do v√©rtice}\nE por fim, m arestas, novamente, uma por linha:\ne {id do v√©rtice de origem} {id do v√©rtice de destino} {r√≥tulo da aresta}\n\nContudo, o c√≥digo aceita outras estrutura√ß√µes dos grafos (por exemplo, os dados do TUDataset tem um .txt com uma lista de adjac√™ncia, entre outros adicionais).‚Äã"
  },
  {
    "objectID": "seminario1/artigo3.html#conclus√£o",
    "href": "seminario1/artigo3.html#conclus√£o",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Conclus√£o",
    "text": "Conclus√£o\nO SPMiner representa um avan√ßo significativo para a minera√ß√£o de subgrafos frequentes, oferecendo uma abordagem inovadora e eficiente para a identifica√ß√£o de padr√µes em dados complexos. Com seu potencial de aplica√ß√£o em uma variedade de dom√≠nios, o SPMiner promete abrir novas oportunidades de pesquisa e inova√ß√£o. Ao aproveitar o poder do aprendizado profundo, o SPMiner por auxiliar na revela√ß√£o de padr√µes ocultos e oferecer insights valiosos."
  },
  {
    "objectID": "seminario1/artigo3.html#refer√™ncias",
    "href": "seminario1/artigo3.html#refer√™ncias",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\n\nYing, R., Fu, T., Wang, A., You, J., Wang, Y., & Leskovec, J. (2024). Representation Learning for Frequent Subgraph Mining. arXiv preprint arXiv:2402.14367. https://doi.org/10.48550/arXiv.2402.14367‚Äã\nSIMPLEDATAMINING. Graph Pattern Mining (gSpan) - Introduction. Dispon√≠vel em: https://simpledatamining.blogspot.com/2015/03/graph-pattern-mining-gspan-introduction.html. Acesso em: 19 abr. 2024.‚Äã\nJ, Vamsi. GRAPH MINING. Dispon√≠vel em: https://www.youtube.com/watch?v=KoG5lEAJmgI&t=1694s. Acesso em: 18 abr. 2024.‚Äã\nRex Ying et al.¬†Frequent Subgraph Mining by Walking in Order Embedding Space. In: INTERNATIONAL CONFERENCE ON MACHINE LEARNING, 37., 2020, Virtual. Workshop details. Dispon√≠vel em: https://icml.cc/virtual/2020/7061. Acesso em: 22 abr. 2024.‚Äã\nFrequent Subgraph Mining by Walking in Order Embedding Space. R. Ying, A. Wang, J. You, J. Leskovec, 2020. Dispon√≠vel em:https://snap.stanford.edu/frequent-subgraph-mining/‚Äã\nNguyen, T.T., Huynh, T.T., Yin, H. et al.¬†Detecting rumours with latency guarantees using massive streaming data. The VLDB Journal 32, 369‚Äì387 (2023). https://doi.org/10.1007/s00778-022-00750-4‚Äã\nZEGHINA, Assaad et al.¬†Multi-SPMiner: A Deep Learning Framework for Multi-Graph Frequent Pattern Mining with Application to spatiotemporal Graphs. Procedia Computer Science, v. 225, p.¬†1094-1103, 2023. ISSN 1877-0509. Dispon√≠vel em: https://doi.org/10.1016/j.procs.2023.10.097. Acesso em: 22 abr. 2024."
  },
  {
    "objectID": "seminario1.html",
    "href": "seminario1.html",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Os semin√°rios da disciplina consistem em uma apresenta√ß√£o coletiva (da turma) de um artigo mais recente sobre t√≥picos diretamente relacionados ao conte√∫do visto em sala. A ideia √© que a turma como um todo estude os artigos mais recentes da √°rea e discuta esses trabalhos em sala. Em cada sess√£o, discutimos tr√™s artigos recentes relacionados aos t√≥picos abordados nas aulas te√≥ricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canad√°) ‚Äì veja a proposta original em https://colinraffel.com/blog/role-playing-seminar.html. A proposta consiste em fazer uma encena√ß√£o de pap√©is (role play) cient√≠ficos para a apresenta√ß√£o do semin√°rio. Nessa proposta, cada grupo cumprir√° um papel na apresenta√ß√£o. Ao final, uma apresenta√ß√£o em formato de slides e um documento textual s√£o produzidos. A apresenta√ß√£o √© usada em sala de aula para fomentar as discuss√µes, enquanto o documento fornece uma descri√ß√£o textual das impress√µes da turma com a inten√ß√£o de descrever o tema do artigo para um p√∫blico amplo interessado em aprendizado de m√°quina e minera√ß√£o de dados.\nS√£o apresentados a seguir os artigos discutidos no semestre 2024/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\nA Survey of High Utility Itemset Mining\nby Fournier-Viger, Philippe, Jerry Chun-Wei Lin, Tin Truong-Chi, and Roger Nkambou. 2019\nhttps://doi.org/10.1007/978-3-030-04921-8_1\n\n\n\nFinding Local Groupings of Time Series\nby Lee, Zed, Marco Trincavelli, and Panagiotis Papapetrou. 2023\nhttps://doi.org/10.1007/978-3-031-26422-1_5\n\n\n\nRepresentation Learning for Frequent Subgraph Mining\nby Ying, Rex, Tianyu Fu, Andrew Wang, Jiaxuan You, Yu Wang, and Jure Leskovec. 2024\nhttps://arxiv.org/abs/2402.14367"
  },
  {
    "objectID": "seminario1.html#artigo-1",
    "href": "seminario1.html#artigo-1",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "A Survey of High Utility Itemset Mining\nby Fournier-Viger, Philippe, Jerry Chun-Wei Lin, Tin Truong-Chi, and Roger Nkambou. 2019\nhttps://doi.org/10.1007/978-3-030-04921-8_1"
  },
  {
    "objectID": "seminario1.html#artigo-2",
    "href": "seminario1.html#artigo-2",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Finding Local Groupings of Time Series\nby Lee, Zed, Marco Trincavelli, and Panagiotis Papapetrou. 2023\nhttps://doi.org/10.1007/978-3-031-26422-1_5"
  },
  {
    "objectID": "seminario1.html#artigo-3",
    "href": "seminario1.html#artigo-3",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Representation Learning for Frequent Subgraph Mining\nby Ying, Rex, Tianyu Fu, Andrew Wang, Jiaxuan You, Yu Wang, and Jure Leskovec. 2024\nhttps://arxiv.org/abs/2402.14367"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizado Descritivo",
    "section": "",
    "text": "Aprendizado Descritivo ‚Äî DCC/UFMG   Prof.¬†Renato Vimieiro \n\nEssa disciplina √© ofertada no Programa de P√≥s-Gradua√ß√£o em Ci√™ncia da Computa√ß√£o da Universidade Federal de Minas Gerais. Ela tem como objetivo apresentar t√©cnicas avan√ßadas para identifica√ß√£o de padr√µes descritivos em bases de dados. A(o) aluna(o) ter√° contato com t√©cnicas para aprendizado de padr√µes n√£o-supervisionados e supervisionados. Ser√£o discutidas as dificuldades computacionais da busca por tais padr√µes, bem como sua utilidade para an√°lise explorat√≥ria de dados.\nOs t√≥picos abordados na disciplina s√£o:\n\nDiferen√ßas entre aprendizado descritivo e preditivo.\nAprendizado descritivo n√£o-supervisionado.\nAprendizado descritivo supervisionado.\nRepresenta√ß√µes condensadas.\nM√©tricas de qualidade de padr√µes descritivos.\nAlgoritmos de aprendizado de padr√µes descritivos supervisionados e n√£o-supervisionados.\nEstudos de casos e aplica√ß√µes em problemas reais.\n\nOs t√≥picos s√£o apresentados atrav√©s de aulas expositivas sobre o assunto, leitura e apresenta√ß√£o de semin√°rios sobre artigos recentes na literatura, e projetos de aplica√ß√£o dos m√©todos estudados para extra√ß√£o de conhecimento de bases de dados.\nUtilize o menu acima ou o link a seguir para visualizar o conte√∫do produzido nos semin√°rios e projetos desenvolvidos pelos alunos.\n\nSemin√°rios: Padr√µes frequentes; Descoberta de subgrupos; Aplica√ß√µes"
  },
  {
    "objectID": "seminario1/artigo1.html",
    "href": "seminario1/artigo1.html",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "",
    "text": "No campo da minera√ß√£o e an√°lise de dados, a minera√ß√£o de padr√µes frequentes possui uma relev√¢ncia bastante significativa, sendo importante para encontrar associa√ß√µes e correla√ß√µes entre diferentes vari√°veis. Essa √°rea de estudo surgiu juntamente com o crescimento exponencial da quantidade de dados dispon√≠veis em diversos setores da vida cotidiana, em especial o com√©rcio, tendo sido batizada com o nome de ‚ÄúAnalise da cesta de compras‚Äù.\nPara dar seguimento a este artigo, √© necess√°rio definir (ou relembrar) alguns conceitos:\nA an√°lise final dos padr√µes identificados como frequentes atrav√©s da minera√ß√£o executada pode muitas vezes ser complicada, por se tratar de uma t√©cnica de aprendizado n√£o supervisionado. Mas al√©m da complexidade inata da an√°lise de resultados, existe tamb√©m a possibilidade dos padr√µes obtidos n√£o significarem nada, ou simplesmente serem pouco √∫teis para os objetivos do neg√≥cio.\nPor exemplo, considere que na an√°lise de uma papelaria os itens ‚Äúl√°pis‚Äù e ‚Äúborracha‚Äù s√£o frequentemente inclu√≠dos em uma mesma transa√ß√£o, o pre√ßo final pago pelo consumidor por apenas esse conjunto de itens ser√° muito baixo, n√£o trazendo os benef√≠cios esperados da an√°lise. Por√©m, na mesma papelaria, pode ser que os itens impressora e cartucho de tinta tamb√©m s√£o frequentemente comprados juntos, o que leva a um pre√ßo final maior pago pelo consumidor.\nO exemplo anterior √© b√°sico, mas ilustra a ideia de que os itens serem apenas frequentes pode n√£o ser o suficiente, sendo necess√°rio que as combina√ß√µes analisadas sejam tamb√©m √∫teis para o analista. √â nesse contexto que surge a minera√ß√£o de padr√µes frequentes de alta utilidade, tratada no artigo ‚ÄúA Survey of High Utility Itemset Mining‚Äù, que aborda diferentes algoritmos para resolver esse problema.\nPara entender esses algoritmos, √© primeiro necess√°rio fazer uma segunda leva de defini√ß√µes sobre o assunto, dessa vez mais espec√≠ficas ao escopo de minera√ß√£o de padr√µes de alta utilidade:\nPerceba que, de acordo com essas defini√ß√µes, todos os algoritmos que s√£o utilizados para minera√ß√£o de padr√µes frequentes de alta utilidade podem tamb√©m ser utilizados para minerar padr√µes frequentes, basta que a utilidade interna e externa de todos os itens seja definida com o mesmo valor, preferencialmente ‚Äú1‚Äù. Para entender melhor as semelhan√ßas e diferen√ßas entre as duas t√©cnicas de minera√ß√£o de dados, verifique a tabela a seguir:"
  },
  {
    "objectID": "seminario1/artigo1.html#t√©cnicas-e-algoritmos-usados",
    "href": "seminario1/artigo1.html#t√©cnicas-e-algoritmos-usados",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "T√©cnicas e Algoritmos usados",
    "text": "T√©cnicas e Algoritmos usados\nO artigo estudado tem por objetivo apresentar a √°rea de minera√ß√£o de padr√µes frequentes de alta utilidade, al√©m de mostrar ao leitor diferentes algoritmos para realizar essa minera√ß√£o. As principais t√©cnicas para a confec√ß√£o dos algoritmos s√£o a de ‚ÄúDuas fases‚Äù e de ‚ÄúUma fase‚Äù, essas t√©cnicas ser√£o explicadas nas pr√≥ximas subse√ß√µes, juntamente com um algoritmo representante de cada classe.\n\nAlgoritmos de duas fases\nAlgoritmos que seguem essa t√©cnica usam o conceito de ‚ÄúUtilidade da transa√ß√£o‚Äù, ou Transaction Utility (TU), que pode ser definido como a soma da utilidade de todos os itens que est√£o presentes em uma transa√ß√£o, para definir limites superiores do qu√£o alta a utilidade de um subconjunto dessa transa√ß√£o pode ser. Esse limite superior √© calculado para cada um dos padr√µes (itemsets) candidatos atrav√©s de uma ‚ÄúUtilidade com peso em transa√ß√µes‚Äù, ou Transaction Weighted Utility (TWU), que √© definida como a soma da utilidade de todas as transa√ß√µes que cont√™m o padr√£o em evid√™ncia.\nO valor obtido de TWU para um itemset, √© o limite superior para todos os superconjuntos que possam ser formados a partir dele. Por exemplo, suponha a exist√™ncia de um itemset base {a, b} que possui TWU igual a 10, isso significa que qualquer itemset da forma {a, b, _}, onde o terceiro e √∫ltimo item pode ser qualquer um do universo de itens dispon√≠vei, ter√° necessariamente uma utilidade menor que 10. A aplica√ß√£o dessa propriedade nos algoritmos traz um importante avan√ßo, que √© o estabelecimento de um decrescimento monot√¥nico do TWU de acordo com o aumento dos itens em um itemset.\nA partir dessas propriedades, √© definido um suporte de utilidade m√≠nimo que elimina todos os itemsets que tenham TWU abaixo desse limiar assim que s√£o identificados, evitando a gera√ß√£o de superconjuntos que n√£o t√™m chances de serem de alta utilidade.\n\n\n\nExemplo de c√°lculo do TWU.\n\n\nA primeira fase dos algoritmos consiste em gerar o TWU de todos os itens dispon√≠veis, j√° que eles s√£o o menor itemset poss√≠vel (excluindo o conjunto vazio). Ap√≥s o c√°lculo, todos os itemsets unit√°rios que tenham um TWU que estejam abaixo do suporte de utilidade m√≠nimo definido s√£o eliminados do espa√ßo de busca, evitando que candidatos infrut√≠feros sejam gerados. Em seguida, a gera√ß√£o de candidatos continua para os itemsets de dois elementos gerados a partir dos remanescentes do filtro anterior, sendo que esses novos candidatos ser√£o tamb√©m removidos no caso de terem TWU menor que o suporte m√≠nimo. Essa sequ√™ncia de a√ß√µes continua em repeti√ß√£o at√© que j√° n√£o seja mais poss√≠vel gerar novos candidatos.\n\nNote que nessa primeira fase est√° sendo calculado o TWU, que √© o limite superior de utilidade, e n√£o a utilidade dos itemsets em si\n\nA segunda fase do algoritmo consiste em calcular a utilidade de todos os candidatos que sobraram da fase anterior, eliminando aqueles que tenham utilidade menor que o limite inferior estabelecido.\nO primeiro algoritmo desenvolvido para essa t√©cnica se chama Two-Phase Algorithm, tendo sido baseado no algoritmo Apriori para minera√ß√£o de padr√µes frequentes. √â poss√≠vel ver uma imagem do pseudoc√≥digo desse algoritmo a seguir:\n\n\n\nPseudoc√≥digo do algoritmo Two-Phase.\n\n\nPerceba que a fun√ß√£o ITEMSETGENERATION() recebe apenas o conjunto de candidatos da itera√ß√£o anterior como par√¢metro, n√£o verificando a base de dados de transa√ß√£o para gerar os candidatos, o que pode levar a itemsets que n√£o ocorrem em nenhuma transa√ß√£o, resultando em um desperd√≠cio de tempo consider√°vel para os c√°lculos deles.\nOutra limita√ß√£o do algoritmo √© que ele itera pelo conjunto de dados v√°rias vezes para calcular o TWU dos itemsets, elevando o custo do algoritmo. Note que a explora√ß√£o do espa√ßo de busca desse algoritmo segue a t√©cnica de Breadth First Search (BFS), o que leva a uma maior demora para elimina√ß√£o de candidatos infrut√≠feros, principalmente pelo fato de que o TWU √© uma m√©trica de limite extrapolada.\n\n\nAlgoritmos de uma fase\nEsses algoritmos s√£o mais diretos, fazendo o c√°lculo da utilidade de cada padr√£o considerado no espa√ßo de busca, o que permite identificar imediatamente se um itemset √© de alta ou baixa utilidade sem a necessidade de guard√°-lo em mem√≥ria principal (RAM).\nOutra novidade desses algoritmos √© que eles trazem uma nova forma de calcular os limites superiores de utilidade, sendo mais pr√≥xima √† utilidade real dos itemsets do que o TWU usado nos algoritmos de duas fases. Como exemplo de algoritmo dessa t√©cnica, ser√° utilizado o Fast High-Utility Miner (FHM), que introduz o conceito de Listas de Utilidade, ou Utility List (UL), para representar o banco de dados das transa√ß√µes.\nConsiderando um itemset X, a lista de utilidade UL(X) ser√° uma lista de tuplas para todas as ocorr√™ncias de X nas transa√ß√µes do banco, sendo que cada tupla armazenar√° o ID da transa√ß√£o em que o itemset est√° presente, a utilidade do itemset naquela transa√ß√£o e a soma da utilidade de todos os itens com ordem lexicogr√°fica superior aos itens de X. O algoritmo se inicia calculando as listas de utilidade de todos os itemsets de um √∫nico elemento, sendo que as listas de utilidades dos superconjuntos desses itemsets ser√° calculada a partir dos componentes delas.\nPor exemplo, suponha as listas de utilidade dos conjuntos unit√°rios UL({a}) e UL({d}), para gerar a lista de utilidade e calcular a utilidade do itemset {a, d}, ser√° calculada a interse√ß√£o das transa√ß√µes que est√£o em UL({a}) e UL({d}). A utilidade do novo itemset ser√° simplesmente a soma das utilidades dos itemsets geradores, enquanto a utilidade dos itens com ordem lexicogr√°fica superior ser√° igual a presente no itemset gerador de maior ordem lexicogr√°fica, no caso do exemplo, ser√° o mesmo de {b}.\n\n\n\nExemplo de c√°lculo das listas de utilidade.\n\n\nO c√°lculo do limite superior para esse algoritmo √© chamado de ‚ÄúLimite Superior por Utilidade Residual‚Äù, ou Remaining Utility Upper-Bound, √© feito somando a utilidade de um item (iutil) com a utilidade dos itens residuais de ordem lexicogr√°fica maior (rutil) para todas as transa√ß√µes presentes na lista de utilidade. Caso esse resultado final seja menor que a utilidade m√≠nima definida, aquele itemset √© eliminado do espa√ßo de busca, evitando que novos candidatos sejam gerados. A figura a seguir mostra o pseudoc√≥digo para o algoritmo FHM:\n\n\n\nPseudoc√≥digo do algoritmo FHM.\n\n\nAlgoritmos baseados em listas de utilidade, como o FHM, s√£o at√© duas ordens de magnitude mais r√°pidos que os algoritmos de duas fases. Por√©m, a gera√ß√£o de candidatos ainda √© baseada em itemsets anteriores, sem verificar o banco de dados de transa√ß√µes, o que pode levar a candidatos inexistentes e aumento no custo total do algoritmo por gastar recursos verificando possibilidades desnecess√°rias.\nAl√©m disso, o custo de mem√≥ria para o armazenamento das listas de utilidade de cada itemset verificado pode vir a ser preocupante. Outro ponto de aten√ß√£o de algoritmos que seguem essa estrat√©gia √© o fato de que s√£o feitas muitas compara√ß√µes com listas de utilidade anteriores no processo de gera√ß√£o de candidatos, j√° que um candidato com k itens dever√° fazer compara√ß√µes com k-1 listas de utilidade anteriores."
  },
  {
    "objectID": "seminario1/artigo1.html#metodologia-do-artigo",
    "href": "seminario1/artigo1.html#metodologia-do-artigo",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Metodologia do artigo",
    "text": "Metodologia do artigo\nO artigo adota uma abordagem metodol√≥gica baseada em Survey, delineando inicialmente o problema em quest√£o e, em seguida, apresentando algoritmos destinados √† sua resolu√ß√£o. Uma filtragem criteriosa de artigos relevantes no dom√≠nio da minera√ß√£o de itemsets de alta utilidade foi realizada, seguida pela compila√ß√£o e s√≠ntese dos algoritmos destacados, abordando suas estruturas e conceitos fundamentais.\nOs primeiros algoritmos abrangentes para identificar conjuntos de itens de alta utilidade operam em duas fases distintas: primeiro, geram-se candidatos que s√£o subsequentemente avaliados quanto √† sua utilidade efetiva. Esses algoritmos introduziram uma inova√ß√£o crucial ao estabelecer uma medida mon√≥tona que serviria como limite superior para a utilidade dos conjuntos de itens. Uma dessas medidas pioneiras foi a TWU (Transaction-Weighted Utilization), a qual permitiu uma poda eficiente do espa√ßo de busca. Em est√°gios posteriores, surgiram algoritmos de uma √∫nica fase, cujo prop√≥sito √© economizar tempo ao integrar a gera√ß√£o e avalia√ß√£o de candidatos em um √∫nico passo. Vale ressaltar que muitos desses algoritmos propostos representam generaliza√ß√µes de t√©cnicas de minera√ß√£o de conjuntos de itens frequentes estabelecidas, como o Two Phase (uma extens√£o do Apriori) e o UP-Growth (uma extens√£o do FP-Growth).\nDentre os algoritmos apresentados para a minera√ß√£o de padr√µes frequentes de alta utilidade s√£o destacados os seguintes:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTipo de Busca\nFases\nRepresenta√ß√£o dos Dados\nExtende\n\n\n\n\nTwo-Phase\nBusca em Largura\nDuas\nHorizontal\nApriori\n\n\nHUP-Growth\nBusca em Profundidade\nDuas\nHorizontal (√Årvore de Prefixos)\nFP-Growth\n\n\nD2HUP\nBusca em Profundidade\nUma\nVertical (Hiperestrutura)\nH-Mine\n\n\nFHM\nBusca em Profundidade\nUma\nVertical (Listas de Utilidade)\nEclat\n\n\nEFIM\nBusca em Profundidade\nUma\nVertical (com fus√µes)\nLCM\n\n\n\nO artigo por√©m n√£o se cont√©m somente em discutir os algoritmos completos de minera√ß√£o de padr√µes, mas tamb√©m, reconhecendo a import√¢ncia de representa√ß√µes com um n√≠vel maior de significado. √â nesse ponto em que s√£o apresentados os algoritmos que mineram representa√ß√µes concisas dos subconjuntos de alta utilidade:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nPadr√µes\nFases\nRepresenta√ß√£o dos Dados\nExtende\n\n\n\n\nMinFHM\nMinUIs\nUma\nVertical (Listas de Utilidade)\nFHM\n\n\nCHUD\nCHUIs\nDuas\nVertical (Listas de Utilidade)\nDCI Closed\n\n\nEFIM-CLOSED‚Äã\nCHUIs\nUma\nHorizontal (com fus√µes)\nEFM\n\n\nGUIDE\nMHUIs One\nUma\nStream\nUpGrowth\n\n\n\nPor fim, s√£o apresentados algoritmos que retornam apenas os K subconjuntos de alta utilidade mais frequentes no conjunto de transa√ß√µes:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTipo de Busca\nFases\nRepresenta√ß√£o dos Dados\nExtende\n\n\n\n\nTKU‚Äã\nBusca em Profundidade‚Äã\nDuas\nHorizontal (√Årvore de Prefixos)\n‚Äã UP-Growth‚Äã\n\n\nTKO‚Äã\nBusca em Profundidade‚Äã\nUma\nVertical (Listas de Utilidade)\nHUI-Miner‚Äã\n\n\nREPT‚Äã\nBusca em Profundidade‚Äã\nUma\nHorizontal (√Årvore de Prefixos)‚Äã\nMU-Growth‚Äã\n\n\nkHMC‚Äã\nBusca em Profundidade‚Äã\nUma\nVertical (Listas de Utilidade)‚Äã\nFHM‚Äã"
  },
  {
    "objectID": "seminario1/artigo1.html#aplica√ß√µes-e-desafios-√©ticos-e-sociais",
    "href": "seminario1/artigo1.html#aplica√ß√µes-e-desafios-√©ticos-e-sociais",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Aplica√ß√µes e Desafios √âticos e Sociais",
    "text": "Aplica√ß√µes e Desafios √âticos e Sociais\nH√° uma vasta gama de problemas do mundo real que podem se beneficiar significativamente do uso de algoritmos de minera√ß√£o de subconjuntos frequentes de alta utilidade. Entre eles:\n\nMercado de Varejo: Potencial para aumentar os lucros ao impulsionar as vendas de produtos mais rent√°veis.\nMercado de Compra Conjunta: Oportunidade de melhorar a lucratividade ao associar produtos visando redu√ß√£o de impostos.\nSistema de Recomenda√ß√£o: Aprimoramento da capacidade de gerar lucro ao focar em produtos mais rent√°veis.\nCross-Selling e Up-Selling: Est√≠mulo para compras de produtos complementares e promo√ß√£o de vendas casadas.\nTratamento de Sa√∫de: Desenvolvimento de conjuntos de tratamentos visando maior efici√™ncia.\nDetec√ß√£o de Fraudes: Identifica√ß√£o de padr√µes pouco frequentes, por√©m altamente √∫teis, na detec√ß√£o de fraudes. Uso da Internet:__ An√°lise do comportamento dos usu√°rios para aprimorar a import√¢ncia do site.\nTelecomunica√ß√µes: Utiliza√ß√£o na identifica√ß√£o de padr√µes de comunica√ß√£o que resultam em maior lucratividade.\nMinera√ß√£o de Texto: Identifica√ß√£o de textos com elevado valor agregado.\n\nNo entanto, a implementa√ß√£o de algoritmos de minera√ß√£o de alta utilidade suscita preocupa√ß√µes sociais e √©ticas que demandam uma aten√ß√£o cuidadosa. Um ponto crucial √© a amea√ßa √† privacidade, uma vez que a identifica√ß√£o de indiv√≠duos a partir de dados aparentemente an√¥nimos pode comprometer a seguran√ßa dos mesmos. Ademais, h√° o risco de manipula√ß√£o do mercado e do comportamento do consumidor, onde o conhecimento de padr√µes de consumo pode ser utilizado de maneira indevida para influenciar escolhas.\nOutra quest√£o relevante √© a elis√£o fiscal, na qual empresas utilizam o conhecimento de padr√µes de alta utilidade para minimizar suas obriga√ß√µes fiscais de forma legal, mas question√°vel do ponto de vista √©tico. Esses desafios destacam a import√¢ncia de regulamenta√ß√µes s√≥lidas e transpar√™ncia no uso de algoritmos de minera√ß√£o de dados, garantindo que o impacto social e √©tico seja considerado em todas as etapas, desde a implementa√ß√£o at√© a opera√ß√£o dessas ferramentas avan√ßadas."
  },
  {
    "objectID": "seminario1/artigo1.html#como-usar",
    "href": "seminario1/artigo1.html#como-usar",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Como usar",
    "text": "Como usar\nNeste guia iremos ensinar o passo a passo para poder executar o SPMF, um software livre que tem implementado v√°rios algoritmos de minera√ß√£o de itemsets de alta qualidade.\nA execu√ß√£o do SPMF exige o JAVA vers√£o m√≠nima 1.8, aqui iremos mostrar a instala√ß√£o tanto do JAVA quanto do SPMF para o Windows, o processo de instala√ß√£o do programa deve ser o mesmo no Linux, j√° que o programa √© baseado em JAVA, a diferen√ßa se dar√° na instala√ß√£o do JAVA.\n\nInstala√ß√£o\nInicialmente segui o guia de instala√ß√£o do JAVA deste link, mas na hora de execu√ß√£o do SPMF o programa n√£o funcionou e a solu√ß√£o foi reinstalar o JAVA de outra forma. Apenas a fim de documentar um poss√≠vel erro que voc√™ encontre ao tentar executar o SPMF, fica aqui o v√≠deo do processo de instala√ß√£o que n√£o funcionou.\n\n\n\n\n\nInstala√ß√£o da vers√£o errada do JAVA\n\n\nA instala√ß√£o do SPMF √© simples e se encontra neste link. O v√≠deo a seguir mostra o processo inteiro:\n\n\n\n\n\nInstala√ß√£o do software SPMF\n\n\nComo dito anteriormente, no final obtemos um erro do JAVA que √© concertado pela re-instala√ß√£o de uma vers√£o atual neste link, tal processo √© mostrado no v√≠deo a seguir:\n\n\n\n\n\nInstala√ß√£o da vers√£o mais recente do JAVA\n\n\n\n\nExecu√ß√£o\n\nArquivo de Entrada\nO SPMF suporta arquivos de entrada no formato .txt.\nA primeira parte do arquivo de entrada √© opcional e √© usada para nomear os itens presentes no banco de dados.\n\nLinhas come√ßando com @‚Äã.\nPrimeira linha com ‚Äú@CONVERTED_FROM_TEXT‚Äù‚Äã\nDemais linhas fazem a liga√ß√£o do item com sua descri√ß√£o no formato @ITEM={ID}={DESCRICAO}\n\n{ID} √© o n√∫mero do item\n{DESCRICAO} √© o nome do item\n\n\n\n\n\nPrimira parte do arquivo de entrada (opcional)\n\n\nA segunda parte cont√©m os dados das transa√ß√µes, com cada linha representando uma transa√ß√£o e cada coluna separada por ‚Äú:‚Äù contendo o itemset, a utilidade total do itemset e a utilidade de cada item do itemset, respectivamente.\n\nLinhas representam as transa√ß√µes‚Äã\nCada linha possui 3 colunas separadas pelo caractere ‚Äò:‚Äô‚Äã\n\nColuna 1: itemset com os ids dos itens separados por espa√ßo simples.\nColuna 2: utilidade total do itemset.\nColuna 3: utilidade respectiva de cada item do itemset separadas por espa√ßo simples.‚Äã\n\n\n\n\n\nSegunda parte do arquivo de entrada\n\n\n\n\nExecu√ß√£o do Software\nV√≠deo tutorial de como se deve executar o programa a partir do dado de entrada, o algoritmo escolhido no tutorial foi o Two-Phase:\n\n\n\n\n\nApesar de no tutorial ser mostrado a execu√ß√£o com o algoritmo Two-Phase, temos v√°rias op√ß√µes de algoritmos para minera√ß√£o de itensets de alta utilidade, como UP-Growth, UP-Growth+, FHM e HUI-Miner.\n\n\nArquivo de Sa√≠da\nA sa√≠da do algoritmo tamb√©m √© um arquivo .txt, contendo os itemsets de alta utilidade encontrados, o suporte do itemset (nem todos os algoritmos geram esse valor) e a utilidade do itemset.\n\nLinhas representam itemsets de alta utilidade encontrados.‚Äã\nCada linha possui 3 se√ß√µes:‚Äã\n\nO itemset, com os ids ou nomes dos itens separados por espa√ßo simples, depende da exist√™ncia da 1¬™ parte do arquivo de entrada.‚Äã\n‚Äú#SUP: {VALOR}‚Äù onde {VALOR} √© o suporte do itemset (nem todos os algoritmos geram esse valor)‚Äã\n‚Äú#UTIL: {VALOR}‚Äù onde {VALOR} √© a utilidade do itemset.\n\n\n\n\n\nArquivo de sa√≠da"
  },
  {
    "objectID": "seminario1/artigo1.html#refer√™ncias",
    "href": "seminario1/artigo1.html#refer√™ncias",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\n\nFournier-Viger, P., Chun-Wei Lin, J., Truong-Chi, T., Nkambou, R. (2019). A Survey of High Utility Itemset Mining. In: Fournier-Viger, P., Lin, JW., Nkambou, R., Vo, B., Tseng, V. (eds) High-Utility Pattern Mining. Studies in Big Data, vol 51. Springer, Cham. https://doi.org/10.1007/978-3-030-04921-8_1\nFOURNIER-VIGER, P. et al.¬†FHM: Faster High-Utility Itemset Mining Using Estimated Utility Co-occurrence Pruning. ReserachGate, Taiwan, jul./2014. Dispon√≠vel em: https://www.researchgate.net/publication/263696687. Acesso em: 23 abr. 2024.\n\nFournier-Viger, Philippe. ‚ÄúSPMF: A Java Open-Source Pattern Mining Library.‚Äù Dispon√≠vel em: https://www.philippe-fournier-viger.com/spmf/index.php. Acesso em: 22 de Abril de 2024.\nLIU, Mengchi; QU, Junfeng. Mining High Utility Itemsets without Candidate Generation. ResearchGate, Wuhan, nov./2020. Dispon√≠vel em: https://www.researchgate.net/publication/262369808. Acesso em: 23 abr. 2024."
  },
  {
    "objectID": "seminario2.html",
    "href": "seminario2.html",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Os semin√°rios da disciplina consistem em uma apresenta√ß√£o coletiva (da turma) de um artigo mais recente sobre t√≥picos diretamente relacionados ao conte√∫do visto em sala. A ideia √© que a turma como um todo estude os artigos mais recentes da √°rea e discuta esses trabalhos em sala. Em cada sess√£o, discutimos tr√™s artigos recentes relacionados aos t√≥picos abordados nas aulas te√≥ricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canad√°) ‚Äì veja a proposta original em https://colinraffel.com/blog/role-playing-seminar.html. A proposta consiste em fazer uma encena√ß√£o de pap√©is (role play) cient√≠ficos para a apresenta√ß√£o do semin√°rio. Nessa proposta, cada grupo cumprir√° um papel na apresenta√ß√£o. Ao final, uma apresenta√ß√£o em formato de slides e um documento textual s√£o produzidos. A apresenta√ß√£o √© usada em sala de aula para fomentar as discuss√µes, enquanto o documento fornece uma descri√ß√£o textual das impress√µes da turma com a inten√ß√£o de descrever o tema do artigo para um p√∫blico amplo interessado em aprendizado de m√°quina e minera√ß√£o de dados.\nS√£o apresentados a seguir os artigos discutidos no semestre 2024/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\nAnytime discovery of a diverse set of patterns with Monte Carlo tree search\nby Guillaume Bosc, Jean-Fran√ßois Boulicaut, Chedy Raissi, Tin Truong-Chi, and Mehdi Kaytoue. 2017\nhttps://doi.org/10.1007/s10618-017-0547-5"
  },
  {
    "objectID": "seminario2.html#artigo-4",
    "href": "seminario2.html#artigo-4",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Anytime discovery of a diverse set of patterns with Monte Carlo tree search\nby Guillaume Bosc, Jean-Fran√ßois Boulicaut, Chedy Raissi, Tin Truong-Chi, and Mehdi Kaytoue. 2017\nhttps://doi.org/10.1007/s10618-017-0547-5"
  },
  {
    "objectID": "seminario2/artigo5.html",
    "href": "seminario2/artigo5.html",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "",
    "text": "A descoberta de subgrupos (SD) √© um m√©todo de minera√ß√£o de dados que visa identificar padr√µes interessantes dentro de grandes conjuntos de dados, destacando segmentos espec√≠ficos que diferem de forma significativa do restante. Este m√©todo √© particularmente √∫til para explorar dados e encontrar subgrupos que apresentam comportamentos ou caracter√≠sticas not√°veis.\nNo contexto da SD, os dados num√©ricos desempenham um papel crucial. Eles podem ser usados tanto como atributos de descri√ß√£o, que ajudam a definir os subgrupos, quanto como alvos, onde se analisa o valor num√©rico em si. A forma como esses dados num√©ricos s√£o tratados pode impactar significativamente a qualidade e a utilidade dos subgrupos descobertos. Com isso, √© importante que a aplica√ß√£o de m√©todos SD sejam adaptadas para lidar com esse tipo de dado da melhor forma poss√≠vel."
  },
  {
    "objectID": "seminario2/artigo5.html#contextualiza√ß√£o-do-problema",
    "href": "seminario2/artigo5.html#contextualiza√ß√£o-do-problema",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Contextualiza√ß√£o do problema",
    "text": "Contextualiza√ß√£o do problema\nHistoricamente, o tratamento de dados num√©ricos em algoritmos de descoberta de subgrupos tem sido predominantemente est√°tico e global. Um exemplo disso √© o mergeSD (2009), que abordou o tratamento de dados num√©ricos, embora com um aumento significativo no custo computacional. No entanto, muitos algoritmos cl√°ssicos ainda n√£o tratam adequadamente os atributos num√©ricos, resultando na perda de informa√ß√µes relevantes e na diminui√ß√£o da efici√™ncia do modelo.\nPara abordar essa quest√£o, o artigo investiga qual abordagem √© mais eficaz para lidar com esses atributos, utilizando um framework que compara diferentes estrat√©gias de discretiza√ß√£o de dados num√©ricos e de busca de subgrupos. A motiva√ß√£o central dos autores √© compreender como a discretiza√ß√£o dos valores num√©ricos pode ser realizada de maneira a preservar a qualidade e a redund√¢ncia m√≠nima nos subgrupos descobertos. Assim, o artigo pode ser visto como uma revis√£o dos principais m√©todos de tratamento de atributos num√©ricos em SD."
  },
  {
    "objectID": "seminario2/artigo5.html#conceitos-importantes",
    "href": "seminario2/artigo5.html#conceitos-importantes",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Conceitos importantes",
    "text": "Conceitos importantes\nA descoberta de subgrupos lida com atributos num√©ricos por meio de condi√ß√µes nos valores, discretizando-os em intervalos para tornar o problema trat√°vel. A discretiza√ß√£o pode ser realizada de forma global, no in√≠cio do processo, com todos os pontos de corte definidos de uma vez, ou de forma local, sendo realizada dinamicamente durante a minera√ß√£o.\nOs intervalos gerados pela discretiza√ß√£o podem ser bin√°rios ou nominais. Intervalos bin√°rios referem-se a divis√µes simples em duas categorias, como ‚Äúbaixo‚Äù e ‚Äúalto‚Äù, enquanto intervalos nominais podem ter m√∫ltiplas categorias como ‚Äúbaixo‚Äù, ‚Äúm√©dio‚Äù e ‚Äúalto‚Äù. No entanto, os autores mencionam que essa simplifica√ß√£o resultante da discretiza√ß√£o pode descaracterizar os dados, pois os valores perdem certas propriedades ao serem agrupados em categorias. Por exemplo, ao comparar valores num√©ricos em um conjunto que varia de 1 a 10, os valores 7 e 8 podem ser categorizados como ‚Äúalto‚Äù, fazendo com que 7 deixe de ser menor que 8, pois ambos s√£o apenas ‚Äúalto‚Äù.\nA tabela abaixo mostra um exemplo pr√°tico de discretiza√ß√£o do atributo ‚Äúheight‚Äù (altura) de um grupo de 13 indiv√≠duos usando a estrat√©gia nominal e bin√°ria. Na estrat√©gia nominal (coluna heightn), os pontos de corte foram definidos para os intervalos a ‚â§ 170 &lt; b ‚â§ 179 &lt; c.¬†J√° na estrat√©gia bin√°ria temos duas categorias: low (coluna heightl) e low/medium (coluna heightlm) que correspondem a uma forma alternativa de discretizar os pontos de corte da estrat√©gia nominal.\n\n\n\nExemplo de estrat√©gias de discretiza√ß√£o para atributos num√©ricos\n\n\nA granularidade para discretiza√ß√£o refere-se ao n√≠vel de detalhe ou ao n√∫mero de candidatos (intervalos) em que os dados num√©ricos s√£o divididos. Granularidade fina envolve a cria√ß√£o de muitos intervalos pequenos, enquanto a granularidade grossa gera poucos intervalos maiores. Uma granularidade mais fina permite uma an√°lise mais detalhada, mas pode aumentar o custo computacional. A sele√ß√£o de candidatos pode incluir todos os poss√≠veis subgrupos (all) ou apenas um subconjunto (best), o que tamb√©m impacta o custo computacional."
  },
  {
    "objectID": "seminario2/artigo5.html#entendendo-os-algoritmos-usados",
    "href": "seminario2/artigo5.html#entendendo-os-algoritmos-usados",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Entendendo os algoritmos usados",
    "text": "Entendendo os algoritmos usados\nPara dar suporte √† investiga√ß√£o, os pesquisadores parametrizaram e executaram dois algoritmos de base: um para a descoberta de subgrupos e outro para a discretiza√ß√£o de atributos num√©ricos.\nO primeiro algoritmo, SDMM, realiza a busca de subgrupos v√°lidos em uma base de dados, utilizando uma fun√ß√£o de qualidade, restri√ß√µes e estrat√©gias de busca pr√©-estabelecidas. O algoritmo explora o dados, criando um primeiro subgrupo de busca e refinando o banco de dados a partir dele, com o objetivo de gerar novos candidatos para valida√ß√£o. Cada candidato √© analisado, uma fun√ß√£o de qualidade √© associada a ele e √© verificado se os candidatos seguem o padr√£o de qualidade estabelecido. Se sim, esses dados s√£o adicionados ao conjunto solu√ß√£o; caso contr√°rio, a busca √© reiniciada.\nO segundo algoritmo, Equal Frequency Discretisation, √© um algoritmo de discretiza√ß√£o que desenvolve intervalos de classe. No in√≠cio do processo, √© definido como os atributos num√©ricos ser√£o discretizados, estabelecendo o n√∫mero de intervalos de classes e, a partir desse n√∫mero, o algoritmo define os pontos de corte das classes para categorizar os atributos."
  },
  {
    "objectID": "seminario2/artigo5.html#estrat√©gias-de-busca",
    "href": "seminario2/artigo5.html#estrat√©gias-de-busca",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Estrat√©gias de busca",
    "text": "Estrat√©gias de busca\nPara gerar os quadros de simula√ß√µes poss√≠veis e comparar as melhores solu√ß√µes de descoberta de subgrupos, s√£o utilizados tr√™s m√©todos principais: busca em feixe tradicional, busca em feixe CBSS e busca completa.\nA busca em feixe tradicional √© uma busca em n√≠vel, que limita o n√∫mero de candidatos e a cada processamento. O m√©todo √© ajustado para buscar subgrupos de acordo com um valor predefinido, restringindo o n√∫mero de candidatos considerados em cada etapa.\nA busca em feixe em CBSS √© uma varia√ß√£o do feixe tradicional, que gera supercandidatos preliminares. Para otimizar a busca dos melhores candidatos, ele incrementa o n√∫mero de candidatos, visando aumentar a diversidade do processo.\nA busca completa realiza uma busca extensa usando todos os candidatos na busca de subgrupos. Embora isso aumente a qualidade da descoberta, h√° um custo operacional elevado e redund√¢ncia. Trabalhar com grandes bancos de dados pode ser dif√≠cil e, apesar de melhorar a qualidade, a performance pode ser prejudicada.\n\n\n\nDiagrama de etapas do processamento de dados para descoberta de subgrupos"
  },
  {
    "objectID": "seminario2/artigo5.html#metodologia",
    "href": "seminario2/artigo5.html#metodologia",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Metodologia",
    "text": "Metodologia\nNo que diz respeito √† metodologia do artigo, os autores realizaram uma s√©rie de testes, com todas as combina√ß√µes de hiperpar√¢metros e estrat√©gias poss√≠veis. Ao todo, forma avaliados 5 aspectos diferentes de SD e como cada um deles impacta os resultados, s√£o estes:\n\nHiperpar√¢metros, que se dividem em 2 tipos:\n\nN√∫mero de bins: quantidade de quebras na discretiza√ß√£o.\nProfundidade: n√∫mero de descritores.\n\nEstrat√©gias para o SD num√©rico que variam em 4 dimens√µes, havendo duas op√ß√µes para cada e, portanto, 2^4 possibilidades:\n\nMomento de discretiza√ß√£o (local ou global).\nTipo de intervalo (bin√°rio ou nominal).\nGranularidade (fina ou grossa).\nM√©todos de sele√ß√£o (‚Äúall‚Äù ou ‚Äúbest‚Äù).\n\nDatasets utilizados, que podem ser para dois tipos de problemas:\n\nDatasets de classifica√ß√£o e regras n√£o supervisionados, ex: covertype, credit-a, outros.\nDatasets de regress√£o, ex: auto-mpg, abalone, outros.\n\nEstrat√©gia de busca:\n\nComplete search: envolve a explora√ß√£o de todo o espa√ßo de busca.\nBeam search: limita o n√∫mero de candidatos a cada n√≠vel da busca.\nBeam search + CBSS: otimiza√ß√£o para tentar reduzir a redund√¢ncia dos subgrupos.\n\nM√©tricas de avalia√ß√£o:\n\nWRAcc: para classifica√ß√£o.\nz-score: para regress√£o.\nEntropia conjunta: para calcular a redund√¢ncia dos top 10 subgrupos.\n\n\nPara avaliar esses aspectos, foram realizados 17.020 experimentos, utilizando o algoritmo SDMM. Os experimentos utilizaram seis datasets de classifica√ß√£o e seis datasets de regress√£o e foram avaliados atrav√©s de WRAcc para classifica√ß√£o e |z-score| para regress√£o."
  },
  {
    "objectID": "seminario2/artigo5.html#resultados-obtidos",
    "href": "seminario2/artigo5.html#resultados-obtidos",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Resultados obtidos",
    "text": "Resultados obtidos\nAs conclus√µes sobre v√°rios aspectos obtidas com os resultados dos experimentos podem ser vistas de forma resumina no quadro a seguir:\n\n\n\n\n\n\n\nAspecto metodol√≥gico\nConclus√£o\n\n\n\n\nDiscretiza√ß√£o\nN√£o existe regra universal para o n√∫mero de bins. Estrat√©gias nominais t√™m melhor desempenho com n√∫meros de bins menores, mas estrat√©gias bin√°rias s√£o prefer√≠veis em todos os contextos e aplica√ß√µes. A discretiza√ß√£o local √© sempre melhor.\n\n\nBusca\nA escolha da heur√≠stica de busca tem pouco impacto. Beam search √© recomendada por ser eficiente e apresentar resultados bons quanto √† complete search. Em datasets pequenos, a busca completa pode ser √∫til. CBSS reduz a redund√¢ncia, mas n√£o melhora a qualidade.\n\n\nM√©tricas de Qualidade\nAs m√©tricas impactam significativamente nos subgrupos gerados, especialmente nos tamanhos, favorecendo subgrupos maiores. Avalia√ß√£o feita com a correla√ß√£o de Pearson.\n\n\nGranularidade\nA granularidade fina √© melhor, mas em grandes profundidades, granularidades fina e grossa s√£o equivalentes.\n\n\nM√©todo de Sele√ß√£o\nO m√©todo ‚Äúall‚Äù √© melhor, mas o ‚Äúbest‚Äù melhora a efici√™ncia sem grandes perdas de qualidade.\n\n\n\nNo artigo, as estrat√©gias utilizadas s√£o denotadas por siglas que combinam v√°rias letras, cada uma representando um hiperpar√¢metro espec√≠fico da metodologia aplicada. Abaixo segue uma explica√ß√£o simplificada do que cada letra nas iniciais das estrat√©gias representa:\n\nL: Refere-se ao uso de discretiza√ß√£o local.\nG: Refere-se ao uso de discretiza√ß√£o global.\nB: Indica o uso de intervalos bin√°rios.\nN: Indica o uso de intervalos nominais.\nF: Representa a abordagem de granulidade fina na discretiza√ß√£o dos dados.\nC: Representa a abordagem de granulidade grossa na discretiza√ß√£o dos dados.\nA: Refere-se √† categoria All no m√©todo de sele√ß√£o.\nB: Refere-se √† categoria Best no m√©todo de sele√ß√£o.\n\nAssim, por exemplo, uma estrat√©gia LBFA aplica discretiza√ß√£o local com intervalos bin√°rios, granularidade fina e m√©todo de sele√ß√£o ‚Äúall‚Äù.\nPor fim, os autores apresentaram uma tabela dos resultados com as melhores escolhas para as 4 dimens√µes de estrat√©gias em forma de ranking. Essa tabela se divide em duas partes, a primeira coluna que √© baseada apenas na avalia√ß√£o do melhor subgrupo gerado e a segunda leva em conta os 10 melhores subgrupos.\n\n\n\nRank final das estrat√©gias utilizadas\n\n\nDe modo geral, os melhores resultados foram obtidos pelas estrat√©gias LBFA e LBFB. Entretanto, esse ranking geral n√£o tem garantia de estat√≠stica, visto que ele foi criado a partir de uma combina√ß√£o de v√°rios testes.\nVale ressaltar que uma estrat√©gia em particular (LXFB) tamb√©m apresentou resultados bons mas se distingue das demais por usar intervalos cartesianos como t√©cnica de discretiza√ß√£o, ao inv√©s dos bin√°rios ou nominais. Devido √†s suas limita√ß√µes de aplicabilidade, ela foi testada separadamente e teve performance melhor que todas as demais, sendo a melhor estrat√©gia quando o objetivo principal √© obter subgrupos de alta qualidade para classifica√ß√£o. No entanto, ela n√£o √© aplic√°vel para regress√£o."
  },
  {
    "objectID": "seminario2/artigo5.html#aplica√ß√µes-e-desafios",
    "href": "seminario2/artigo5.html#aplica√ß√µes-e-desafios",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Aplica√ß√µes e desafios",
    "text": "Aplica√ß√µes e desafios\nA descoberta de subgrupos com atributos num√©ricos tem diversas aplica√ß√µes, como por exemplo nas √°reas da sa√∫de, educa√ß√£o e setor financeiro. No entanto, tamb√©m apresenta desafios espec√≠ficos em cada uma dessas √°reas.\nNa sa√∫de, os modelos podem ser utilizados para predi√ß√£o de riscos, identificando subgrupos de pessoas mais suscet√≠veis a doen√ßas de alto risco. Al√©m disso, s√£o √∫teis na an√°lise de resposta a tratamentos, permitindo encontrar subgrupos que reagem de forma diferenciada a determinadas terapias, e no controle de doen√ßas cr√¥nicas, identificando subgrupos que necessitam de cuidados espec√≠ficos. Outra aplica√ß√£o interessante √© o mapeamento de √°reas de risco em uma cidade, identificando regi√µes negligenciadas pelo sistema de sa√∫de, que necessitem de maior aten√ß√£o e investimento.\nNa educa√ß√£o, os modelos de descoberta de subgrupos podem ser aplicados para melhorar a performance acad√™mica, identificando subgrupos de alunos com caracter√≠sticas similares para personalizar a abordagem pedag√≥gica. Outra aplica√ß√£o potencial √© a predi√ß√£o de desist√™ncia, onde √© poss√≠vel identificar subgrupos de alunos com maiores √≠ndices de evas√£o, e assim, oferecer medidas de apoio adequadas. Adicionalmente, √© poss√≠vel identificar √°reas de risco educacional, destacando regi√µes com baixo investimento em educa√ß√£o para cria√ß√£o de novas pol√≠ticas p√∫blicas que visem melhorar a qualidade do ensino nessas √°reas.\nNo setor financeiro, os modelos podem ser utilizados para otimiza√ß√£o de portf√≥lio, identificando subgrupos de a√ß√µes que melhor se encaixam no perfil de determinados investidores. Al√©m disso, tamb√©m podem ser empregados na detec√ß√£o de fraude, identificando subgrupos de transa√ß√µes que apresentam caracter√≠sticas an√¥malas. Na an√°lise de cr√©dito, √© poss√≠vel identificar subgrupos de pessoas com maior propens√£o a cometer fraudes banc√°rias, a fim de adotar medidas preventivas.\nApesar dos benef√≠cios das diversas aplica√ß√µes, a descoberta de subgrupos com atributos num√©ricos apresenta desafios comuns nas tr√™s √°reas discutidas. A privacidade dos dados √© uma preocupa√ß√£o constante, sendo necess√°rio garantir o controle sobre onde os dados, como ser√£o utilizados e quem pode acess√°-los. A discrimina√ß√£o e a equidade de tratamento tamb√©m s√£o quest√µes importantes, uma vez que a identifica√ß√£o de subgrupos pode gerar prefer√™ncia de tratamento para determinados grupos, prejudicando outros."
  },
  {
    "objectID": "seminario2/artigo5.html#execu√ß√£o-dos-algoritmos-usados-no-artigo",
    "href": "seminario2/artigo5.html#execu√ß√£o-dos-algoritmos-usados-no-artigo",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Execu√ß√£o dos algoritmos usados no artigo",
    "text": "Execu√ß√£o dos algoritmos usados no artigo\nDois reposit√≥rios podem ser destacados para a execu√ß√£o do c√≥digo proposto para an√°lise de algoritmos de descoberta de subgrupos. O primeiro reposit√≥rio √© o da Universidade de Leiden, que disponibiliza o sistema Cortana. Esse sistema possui tanto o c√≥digo-fonte quanto o bin√°rio compilado para execu√ß√£o. A p√°gina oficial do Cortana fornece informa√ß√µes gerais sobre a ferramenta e o bin√°rio pode ser baixado diretamente da p√°gina disponibilizada. Al√©m disso, o c√≥digo-fonte est√° dispon√≠vel para desenvolvedores que desejam explorar ou modificar o sistema.\nO Cortana se destaca pela sua documenta√ß√£o extensa, encontrada no diret√≥rio /javadoc do c√≥digo-fonte. No entanto, apresenta uma limita√ß√£o significativa: a falta de um hist√≥rico de atualiza√ß√µes e uma descri√ß√£o detalhada das fun√ß√µes. Isso pode dificultar a compreens√£o completa do sistema e a rastreabilidade de mudan√ßas ao longo do tempo, o que √© crucial para desenvolvedores e pesquisadores que precisam entender a evolu√ß√£o do software.\nO segundo reposit√≥rio discutido foi o SubDisc, dispon√≠vel no GitHub e atualizado regularmente, com a √∫ltima atualiza√ß√£o registrada em 12 de outubro de 2023. O SubDisc √© escrito em Java e se foca principalmente na usabilidade e interface do usu√°rio. Uma das grandes vantagens desse reposit√≥rio √© a inclus√£o de um guia detalhado em PDF, que fornece instru√ß√µes claras sobre como utilizar a ferramenta, tornando-a acess√≠vel mesmo para aqueles que n√£o s√£o especialistas na √°rea.\nA qualidade dos reposit√≥rios varia, mas ambos t√™m suas particularidades e utilidades. O Cortana, apesar de sua documenta√ß√£o extensa, carece de detalhes hist√≥ricos e descri√ß√µes de fun√ß√µes, o que pode ser um desafio. Por outro lado, o SubDisc se sobressai com sua documenta√ß√£o voltada para o usu√°rio final e um guia de uso detalhado, embora n√£o haja men√ß√£o √† profundidade da documenta√ß√£o t√©cnica. A escolha entre essas ferramentas depender√° das necessidades espec√≠ficas dos usu√°rios, seja para um entendimento profundo do funcionamento interno ou para uma interface de usu√°rio amig√°vel.\nUm teste foi realizado utilizando a ferramenta Cortana. O dataset utilizado, tanto para regress√£o, quanto para classifica√ß√£o, foi o Adult, do reposit√≥rio de Machine Learning da UCI. Na tarefa de classifica√ß√£o, o foco foi buscar subgrupos que apresentam um comportamento diferente da popula√ß√£o em rela√ß√£o √† vari√°vel bin√°ria ‚Äúrenda anual ‚â• 50k‚Äù. Na tarefa de regress√£o, o foco est√° na idade dos indiv√≠duos, verificando se h√° subgrupos com uma distribui√ß√£o de idade at√≠pica em rela√ß√£o √† popula√ß√£o geral.\nPara instalar o Cortana, baixe o arquivo cortana1782.jar e execute-o com o comando java abaixo na linha de comando.\njava -jar cortana1782.jar\nAp√≥s iniciar o programa, selecione o arquivo de dados nos formatos arff ou csv, ajuste os par√¢metros conforme o tipo de objetivo (por exemplo, Single Numeric ou Single Nominal) e as medidas de qualidade desejadas (como Lift ou Z-Score). Verifique se os dados foram identificados corretamente e ajuste os tipos de atributos, desabilitando colunas indesejadas. Configure o m√©todo de descoberta, definindo par√¢metros como profundidade de refinamento e cobertura m√≠nima e m√°xima, e utilize a estrat√©gia de beam search com um tamanho de beam de 100. Clique no bot√£o ‚ÄúSubgroup Discovery‚Äù para iniciar o processo.\n\n\n\nInicializa√ß√£o do programa e carga de dados\n\n\nNo primeiro exemplo, para um problema de classifica√ß√£o onde se deseja identificar pessoas com renda anual ‚â• 50k, foi configurado o m√©todo como Beam Search, com largura do beam de 100, profundidade de refinamento de 2, m√©trica de qualidade Lift (‚â• 1.0) e cobertura entre 10% e 90%. Ap√≥s selecionar o arquivo adult.csv e ajustar os par√¢metros e atributos, a execu√ß√£o do algoritmo resultou em subgrupos como ‚Äúeducation-num &gt; 12.0 AND capital-gain &gt; 5000‚Äù, com uma AUC de 0.85 na curva ROC.\n\n\n\nSubgrupos resultantes classifica√ß√£o\n\n\nNo segundo exemplo do problema de regress√£o, para identificar distribui√ß√µes n√£o usuais de idade, a configura√ß√£o tamb√©m incluiu Beam Search, com largura do beam de 100, profundidade de refinamento de 2 e cobertura entre 10% e 90%. Todavia, a m√©trica de qualidade foi Z-Score (‚â• 2.0). A execu√ß√£o encontrou subgrupos como ‚Äúrelationship = husband AND hours-per-week &gt; 40‚Äù, permitindo a compara√ß√£o da distribui√ß√£o de idade com a popula√ß√£o geral.\n\n\n\nSubgrupos resultantes regress√£o"
  },
  {
    "objectID": "seminario2/artigo5.html#conclus√£o",
    "href": "seminario2/artigo5.html#conclus√£o",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Conclus√£o",
    "text": "Conclus√£o\nO trabalho cumpre um papel importate na realiza√ß√£o de experimentos capazes de confirmar algumas intui√ß√µes n√£o validadas at√© ent√£o e aprimorar o conhecimento em rela√ß√µes a estrat√©gias num√©ricas. Nesse sentido, √© um estudo bastante √∫til tanto em uma perspectiva aplicada, podendo servir como apoio na decis√£o de aspectos em aplica√ß√µes reais, quanto no contexto de pesquisas e desenvolvimento de algoritmos."
  },
  {
    "objectID": "seminario2/artigo5.html#refer√™ncias",
    "href": "seminario2/artigo5.html#refer√™ncias",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\nBoley M, Goldsmith BR, Ghiringhelli LM, Vreeken J (2017) Identifying consistent statements about numerical data with dispersion-corrected subgroup discovery. Data Min Knowl Discov 31(5):1391‚Äì1418. https://doi.org/10.1007/s10618-017-0520-3."
  },
  {
    "objectID": "seminario3/artigo7.html",
    "href": "seminario3/artigo7.html",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "",
    "text": "A an√°lise de desempenho esportivo tem se beneficiado cada vez mais da minera√ß√£o de dados para extrair insights valiosos a partir de grandes volumes de informa√ß√µes. Em esportes de equipe, como o rugby union, entender padr√µes de jogo √© crucial para melhorar estrat√©gias e otimizar o desempenho dos atletas. Este artigo explora a aplica√ß√£o da minera√ß√£o supervisionada de padr√µes sequenciais para identificar sequ√™ncias de eventos que influenciam diretamente os resultados em partidas de rugby."
  },
  {
    "objectID": "seminario3/artigo7.html#sobre-a-import√¢ncia-dos-padr√µes-sequenciais",
    "href": "seminario3/artigo7.html#sobre-a-import√¢ncia-dos-padr√µes-sequenciais",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Sobre a import√¢ncia dos padr√µes sequenciais",
    "text": "Sobre a import√¢ncia dos padr√µes sequenciais\nPadr√µes sequenciais referem-se a sequ√™ncias ordenadas de eventos que ocorrem ao longo do tempo, onde a ordem dos eventos √© crucial para determinar um resultado espec√≠fico. Em contextos esportivos, identificar tais padr√µes pode revelar insights sobre estrat√©gias eficazes, vulnerabilidades advers√°rias e fatores determinantes para o sucesso durante uma partida.\n\n\n\nIlustrando padr√µes sequenciais\n\n\nNo rugby union, como em muitos outros esportes de equipe, os eventos s√£o interdependentes e seu impacto no resultado do jogo depende muito da sequ√™ncia em que ocorrem. Por exemplo, um passe bem-sucedido seguido de uma corrida eficaz pode levar a uma situa√ß√£o de pontua√ß√£o, enquanto um passe mal executado pode resultar em uma perda de posse de bola. Assim, a an√°lise de padr√µes sequenciais oferece uma vis√£o mais aprofundada e contextualizada dos eventos de jogo, permitindo aos analistas esportivos entenderem melhor as din√¢micas de jogo que levam ao sucesso ou ao fracasso.\nAo contr√°rio de abordagens tradicionais que podem se concentrar apenas na contagem de eventos isolados, a minera√ß√£o de padr√µes sequenciais leva em considera√ß√£o a interdepend√™ncia entre eventos e sua influ√™ncia cumulativa no resultado final de uma partida. Por exemplo, um √∫nico passe bem-sucedido pode n√£o ser t√£o significativo quanto a sequ√™ncia de eventos que leva a uma jogada de try."
  },
  {
    "objectID": "seminario3/artigo7.html#motiva√ß√£o-e-objetivos",
    "href": "seminario3/artigo7.html#motiva√ß√£o-e-objetivos",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Motiva√ß√£o e Objetivos",
    "text": "Motiva√ß√£o e Objetivos\nO desenvolvimento de t√©cnicas avan√ßadas de an√°lise de padr√µes sequenciais visa superar limita√ß√µes das abordagens tradicionais, que geralmente se concentram apenas na frequ√™ncia de eventos isolados. Neste estudo, aplicamos o algoritmo de Minera√ß√£o de Padr√µes Sequenciais Supervisionada (Supervised Sequential Pattern Mining - SSPM) ao rugby union, com o objetivo de identificar padr√µes de jogo que discriminam entre situa√ß√µes de pontua√ß√£o e n√£o pontua√ß√£o.\nOs principais objetivos deste estudo s√£o:\n\nIdentificar padr√µes de eventos que precedem situa√ß√µes de pontua√ß√£o no rugby union.\nComparar esses padr√µes com sequ√™ncias que levam a eventos n√£o pontu√°veis.\nAvaliar a efic√°cia desses padr√µes em prever resultados de jogos.\nFornecer recomenda√ß√µes pr√°ticas para treinadores e analistas de desempenho com base nos padr√µes identificados."
  },
  {
    "objectID": "seminario3/artigo7.html#o-que-a-literatura-fala-sobre-isso",
    "href": "seminario3/artigo7.html#o-que-a-literatura-fala-sobre-isso",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "O que a literatura fala sobre isso",
    "text": "O que a literatura fala sobre isso\nA literatura j√° existente destaca v√°rias abordagens para a minera√ß√£o de padr√µes sequenciais em contextos esportivos. M√©todos como Generalized Sequential Patterns (GSP), PrefixSpan e Spade t√™m sido amplamente utilizados para descobrir padr√µes frequentes em dados sequenciais. No entanto, essas t√©cnicas geralmente n√£o consideram explicitamente o impacto de padr√µes espec√≠ficos na determina√ß√£o de resultados positivos ou negativos em esportes de equipe.\nA abordagem de minera√ß√£o de padr√µes sequenciais supervisionada (SSPM) difere das abordagens tradicionais ao incorporar r√≥tulos de classe nos dados de treinamento, permitindo a identifica√ß√£o de padr√µes que s√£o discriminativos para diferentes classes de resultado. Por exemplo, num estudo sobre futebol, [Bertens et al.¬†(2016)] usaram minera√ß√£o supervisionada para identificar padr√µes de passes que precedem situa√ß√µes de gol, enquanto [Sato e Sasaki (2018)] aplicaram t√©cnicas semelhantes ao basquete para analisar sequ√™ncias de jogadas que levam a cestas."
  },
  {
    "objectID": "seminario3/artigo7.html#como-essas-an√°lises-foram-feitas",
    "href": "seminario3/artigo7.html#como-essas-an√°lises-foram-feitas",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Como essas an√°lises foram feitas",
    "text": "Como essas an√°lises foram feitas\n\nColeta de dados\nOs dados foram coletados a partir de partidas de rugby union utilizando sistemas de an√°lise de desempenho que capturam eventos como passes, chutes, tackles e tries. Cada evento foi registrado temporalmente, formando sequ√™ncias de eventos ao longo de cada partida.\nEsses dados foram obtidos atrav√©s de plataformas de an√°lise de desempenho, como Opta Sports e Stats Perform, que fornecem informa√ß√µes detalhadas sobre cada a√ß√£o ocorrida durante as partidas. Al√©m disso, grava√ß√µes de v√≠deo das partidas foram analisadas para garantir a precis√£o dos dados coletados.\nEnt√£o, os eventos foram coletados na seguinte estrutura:\n\n\n\n\n\n\n\n\nID do Evento\nEvento\nDescri√ß√£o do Evento\n\n\n\n\n1\nRestart Received\nTime recebe um rein√≠cio de jogo com um chute feito pela equipe advers√°ria\n\n\n2\nPhase\nPer√≠odo entre quebras (time em posse da bola)\n\n\n3\nBreakdown\nJogador do time √© tackleado, resultando em um ruck\n\n\n4\nKick in Play\nChute dentro do campo de jogo (em vez de para fora) feito pelo time\n\n\n5\nPenalty Conceded\nTime concede uma penalidade, a equipe advers√°ria pode recuperar a posse\n\n\n6\nKick at Goal\nTime tenta um chute ao gol\n\n\n\n\n\nPrepara√ß√£o dos dados\nOs dados brutos foram pr√©-processados para extrair sequ√™ncias de eventos relevantes para a an√°lise. Cada sequ√™ncia foi rotulada com base no resultado final do evento (pontua√ß√£o ou n√£o pontua√ß√£o), preparando assim o conjunto de dados para aplica√ß√£o do SSPM. O pr√©-processamento incluiu a limpeza dos dados para remover inconsist√™ncias, a normaliza√ß√£o temporal dos eventos e a segmenta√ß√£o das partidas em sequ√™ncias de jogadas significativas, por exemplo:\n\n\nAplica√ß√£o do SSPM\nO algoritmo SSPM foi aplicado aos dados preparados para identificar padr√µes sequenciais que s√£o discriminativos em rela√ß√£o aos resultados de pontua√ß√£o e n√£o pontua√ß√£o. O processo envolveu a descoberta de padr√µes que ocorrem com frequ√™ncia significativa em cen√°rios de pontua√ß√£o, mas s√£o menos frequentes em cen√°rios de n√£o pontua√ß√£o, e vice-versa.\n\nAlgoritmo SSPM\nO algoritmo de minera√ß√£o de padr√µes sequenciais supervisionada usado neste estudo baseia-se na extens√£o dos m√©todos tradicionais de minera√ß√£o de padr√µes frequentes para incorporar r√≥tulos de classe. Isso permite a identifica√ß√£o de padr√µes que n√£o s√£o apenas frequentes, mas tamb√©m discriminativos para diferentes resultados de jogo.\nDe forma simplificada, o SSPM segue os seguintes passos:\n\nConstru√ß√£o do Conjunto de Dados: As sequ√™ncias de eventos s√£o extra√≠das dos dados brutos e rotuladas com base no resultado (pontua√ß√£o ou n√£o pontua√ß√£o).\nGera√ß√£o de Padr√µes Candidatos: Sequ√™ncias candidatas s√£o geradas a partir do conjunto de dados, considerando diferentes combina√ß√µes de eventos.\nAvalia√ß√£o de Padr√µes: Os padr√µes candidatos s√£o avaliados com base em m√©tricas como suporte, confian√ßa e lift, para determinar sua relev√¢ncia e capacidade de discrimina√ß√£o entre classes.\nFiltragem de Padr√µes: Padr√µes que n√£o atendem a crit√©rios m√≠nimos de suporte e confian√ßa s√£o descartados, enquanto os padr√µes significativos s√£o retidos para an√°lise posterior.\n\n\n\n\nAn√°lise\nOs padr√µes identificados pelo SSPM foram avaliados quanto √† sua capacidade de discriminar entre diferentes resultados de jogo. M√©tricas como suporte (frequ√™ncia do padr√£o no conjunto de dados), confian√ßa (propor√ß√£o de sequ√™ncias contendo o padr√£o que resultam na classe de interesse) e lift (medida da import√¢ncia relativa do padr√£o) foram utilizadas para medir a relev√¢ncia e a signific√¢ncia estat√≠stica dos padr√µes descobertos.\nOs padr√µes foram ent√£o validados utilizando um conjunto de dados de teste separado, garantindo que os resultados n√£o fossem enviesados pelo overfitting. A an√°lise incluiu a visualiza√ß√£o dos padr√µes identificados em contextos reais de jogo, proporcionando uma compreens√£o pr√°tica de como esses padr√µes influenciam os resultados."
  },
  {
    "objectID": "seminario3/artigo7.html#resultados",
    "href": "seminario3/artigo7.html#resultados",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Resultados",
    "text": "Resultados\nO estudo identificou um conjunto de padr√µes sequenciais que demonstraram forte capacidade de discrimina√ß√£o entre situa√ß√µes de pontua√ß√£o e n√£o pontua√ß√£o no rugby union. Entre os padr√µes mais significativos estavam sequ√™ncias de eventos que precedem tries e convers√µes bem-sucedidas, assim como padr√µes defensivos que antecedem turnovers e penalidades concedidas.\n\nPadr√µes relevantes\nOs padr√µes mais relevantes inclu√≠ram combina√ß√µes espec√≠ficas de eventos como passes r√°pidos seguidos de corridas eficazes, al√©m de forma√ß√µes defensivas que resultaram em turnovers estrat√©gicos. Esses padr√µes n√£o apenas refletiram estrat√©gias eficazes de jogo, mas tamb√©m indicaram √°reas de melhoria potencial para equipes analisarem e treinarem.\nExemplo do formato de resultados:\n\n\n\n\n\n\n\nSequ√™ncia de Eventos\nResultado\n\n\n\n\nRestart Received ‚Üí Phase ‚Üí Breakdown ‚Üí Try Scored\nPontua√ß√£o\n\n\nPhase ‚Üí Breakdown ‚Üí Kick in Play ‚Üí Penalty Conceded\nN√£o Pontua√ß√£o\n\n\nLine-out ‚Üí Phase ‚Üí Breakdown ‚Üí Error\nN√£o Pontua√ß√£o\n\n\nScrum ‚Üí Phase ‚Üí Line Breaks ‚Üí Try Scored\nPontua√ß√£o\n\n\nPenalty Conceded ‚Üí O-Restart Received ‚Üí O-Phase ‚Üí O-Try Scored\nN√£o Pontua√ß√£o\n\n\nError ‚Üí O-Line-out ‚Üí O-Phase ‚Üí O-Kick at Goal\nN√£o Pontua√ß√£o\n\n\n\n\nExemplo de padr√£o ofensivo\nUm dos padr√µes ofensivos mais significativos identificados foi a sequ√™ncia: passe r√°pido ‚Üí corrida curta ‚Üí passe longo ‚Üí try. Este padr√£o foi observado frequentemente em situa√ß√µes de pontua√ß√£o e mostrou uma combina√ß√£o eficaz de movimenta√ß√£o r√°pida e precisa da bola, seguida por uma corrida curta para atrair a defesa advers√°ria, culminando em um passe longo que explorava espa√ßos abertos para finalizar com um try.\n\n\nExemplo de padr√£o defensivo\nUm padr√£o defensivo relevante identificado foi a sequ√™ncia: tackle eficaz ‚Üí turnover ‚Üí chute para fora. Este padr√£o refletiu uma estrat√©gia defensiva eficaz onde um tackle bem executado resultava em perda de posse pelo advers√°rio, seguido por um turnover estrat√©gico e um chute para reposicionar o jogo, ganhando territ√≥rio e aliviando a press√£o defensiva."
  },
  {
    "objectID": "seminario3/artigo7.html#considera√ß√µes",
    "href": "seminario3/artigo7.html#considera√ß√µes",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Considera√ß√µes",
    "text": "Considera√ß√µes\nA aplica√ß√£o bem-sucedida da SSPM ao rugby union destacou a import√¢ncia de considerar a sequencialidade de eventos em an√°lises de desempenho esportivo. Ao contr√°rio de abordagens tradicionais baseadas apenas em estat√≠sticas simples, como posse de bola ou n√∫mero de chutes, a minera√ß√£o de padr√µes sequenciais oferece uma perspectiva mais granular e orientada a eventos que s√£o diretamente relevantes para o resultado final do jogo.\nOs padr√µes identificados t√™m implica√ß√µes diretas para o desenvolvimento de estrat√©gias de jogo. Por exemplo, o reconhecimento de padr√µes ofensivos eficazes pode informar a prepara√ß√£o de jogadas espec√≠ficas em treinos, enquanto a identifica√ß√£o de padr√µes defensivos pode ajudar as equipes a desenvolver estrat√©gias para interceptar e neutralizar ataques advers√°rios.\n\nLimita√ß√µes observadas\nEmbora os resultados sejam promissores, este estudo tamb√©m enfrentou algumas limita√ß√µes. A qualidade e a granularidade dos dados de eventos s√£o cruciais para a precis√£o dos padr√µes identificados. Al√©m disso, foi observado uma generaliza√ß√£o dos padr√µes descobertos para diferentes n√≠veis de competi√ß√£o (amador vs.¬†profissional) e constatado que diferentes contextos de jogo (condi√ß√µes clim√°ticas, local da partida) requerem uma an√°lise mais aprofundada.\nOutro desafio √© o potencial de overfitting, onde os padr√µes identificados podem ser espec√≠ficos do conjunto de dados de treinamento e n√£o se generalizam bem para novos dados. Isso foi mitigado atrav√©s do uso de um conjunto de dados de teste separado, mas permanece uma considera√ß√£o importante para futuras pesquisas.\n\n\nSobre o futuro\nEste estudo abre v√°rias dire√ß√µes para futuras pesquisas em an√°lise de desempenho esportivo. Uma √°rea promissora √© a aplica√ß√£o de t√©cnicas de aprendizado de m√°quina para prever resultados de jogos com base nos padr√µes sequenciais identificados. Al√©m disso, a incorpora√ß√£o de dados biom√©tricos e f√≠sicos dos jogadores pode enriquecer ainda mais a an√°lise, fornecendo insights sobre como o condicionamento f√≠sico e a sa√∫de dos atletas influenciam a execu√ß√£o de padr√µes de jogo.\n\n\nAplica√ß√µes pr√°ticas\nAl√©m do rugby union, a metodologia SSPM pode ser aplicada a outros esportes de equipe, como futebol, basquete e h√≥quei, para melhorar a an√°lise de desempenho, informar estrat√©gias t√°ticas e at√© mesmo otimizar o condicionamento f√≠sico dos atletas. As t√©cnicas desenvolvidas neste estudo t√™m o potencial de transformar a forma como os treinadores e analistas esportivos abordam a prepara√ß√£o e o planejamento de partidas."
  },
  {
    "objectID": "seminario3/artigo7.html#conclus√£o",
    "href": "seminario3/artigo7.html#conclus√£o",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Conclus√£o",
    "text": "Conclus√£o\nEm suma, a minera√ß√£o supervisionada de padr√µes sequenciais aparece como uma ferramenta poderosa para analisar e entender o rugby union, oferecendo insights valiosos que podem influenciar diretamente a estrat√©gia e o desempenho das equipes. Este estudo n√£o apenas demonstra a viabilidade da SSPM em contextos do rugby, mas tamb√©m destaca seu potencial para inova√ß√µes futuras na an√°lise de desempenho esportivo.\nA continuidade desta linha de pesquisa pode levar a avan√ßos significativos na an√°lise de desempenho esportivo, melhorando a tomada de decis√£o estrat√©gica, otimizando o treinamento de atletas e elevando o n√≠vel competitivo em esportes de equipe ao redor do mundo."
  },
  {
    "objectID": "seminario3/artigo7.html#refer√™ncias",
    "href": "seminario3/artigo7.html#refer√™ncias",
    "title": "Artigo 7 - Minera√ß√£o Supervisionada de Padr√µes Sequenciais em Esportes para Identificar Padr√µes de Jogo Importantes: Uma Aplica√ß√£o ao Rugby Union",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\n\nBunker R, Fujii K, Hanada H, Takeuchi I (2021) Supervised sequential pattern mining of event sequences in sport to identify important patterns of play: An application to rugby union. PLOS ONE 16(9): e0256329. https://doi.org/10.1371/journal.pone.0256329\nBertens C, Elzinga D, van der Werf E (2016) Discovering sequential patterns in soccer matches to characterize defensive team strategies. PLOS ONE 11(10): e0165039. https://doi.org/10.1371/journal.pone.0165039\nSato K, Sasaki H (2018) Supervised learning for pattern discovery in basketball: A comparative evaluation of alternative approaches. Expert Systems with Applications 94: 280-290. https://doi.org/10.1016/j.eswa.2017.10.011\nAgrawal R, Srikant R (1995) Mining sequential patterns. In: Proceedings of the Eleventh International Conference on Data Engineering. IEEE, pp 3-14. https://doi.org/10.1109/ICDE.1995.380415\nSrikant R, Agrawal R (1996) Mining sequential patterns: Generalizations and performance improvements. In: Proceedings of the 5th International Conference on Extending Database Technology: Advances in Database Technology. Springer, pp 3-17. https://doi.org/10.1007/BFb0014140"
  }
]