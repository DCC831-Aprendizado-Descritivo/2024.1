[
  {
    "objectID": "seminario1/artigo2.html",
    "href": "seminario1/artigo2.html",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "O estudo e a an√°lise de s√©ries temporais desempenham um papel crucial em uma ampla gama de campos, desde o monitoramento do varejo at√© a detec√ß√£o de anomalias de seguran√ßa. Ao longo do tempo, observa√ß√µes cont√≠nuas capturam nuances e padr√µes que podem revelar insights valiosos sobre o comportamento de sistemas complexos. Neste contexto, a capacidade de agrupar s√©ries temporais com base em padr√µes similares torna-se fundamental para extrair conhecimento significativo.\n\n\nA motiva√ß√£o por tr√°s dessa abordagem √© multifacetada. No setor de varejo, por exemplo, a identifica√ß√£o de tend√™ncias locais de compra, como picos de vendas durante per√≠odos festivos, pode ser crucial para otimizar estrat√©gias de marketing e estoque. Da mesma forma, em an√°lises financeiras, compreender as tend√™ncias de mercado pode orientar decis√µes de investimento. Em setores como sa√∫de e biomedicina, a an√°lise de varia√ß√µes sazonais e padr√µes de sono pode contribuir para o desenvolvimento de tratamentos mais eficazes. Al√©m disso, o planejamento de recursos, a detec√ß√£o de anomalias de seguran√ßa e a an√°lise de dados ambientais e clim√°ticos tamb√©m se beneficiam significativamente da capacidade de identificar e compreender padr√µes em s√©ries temporais.\nNeste contexto, este artigo aborda a import√¢ncia da abordagem de agrupamento de s√©ries temporais, com foco no algoritmo Z-groupings. Exploraremos como esse m√©todo oferece uma perspectiva √∫nica para a identifica√ß√£o de grupos locais em s√©ries temporais, destacando sua relev√¢ncia e aplicabilidade em diversas √°reas de estudo e pr√°tica. Ao compreendermos melhor as nuances e potenciais aplica√ß√µes do Z-groupings, podemos abrir novas oportunidades para an√°lises mais precisas e insights mais profundos em uma variedade de dom√≠nios.\n\n\n\nO algoritmo Z-groupings n√£o possui comparativos diretos. No entanto, existem alguns m√©todos cl√°ssicos que realizam tarefas compar√°veis:\n\nK-means: Este m√©todo particiona s√©ries temporais em k clusters, onde os clusters representam grupos locais an√°logos aos encontrados pelo Z-groupings.\nAgrupamento Hier√°rquico: Neste m√©todo, as s√©ries temporais s√£o hierarquicamente divididas com base em uma m√©trica de similaridade. Os grupos resultantes s√£o compar√°veis aos grupos locais identificados pelo Z-groupings.\n\nContudo, √© importante ressaltar que esses algoritmos n√£o s√£o diretamente compar√°veis, pois se limitam a encontrar similaridades dentro de uma √∫nica s√©rie temporal, n√£o considerando rela√ß√µes entre diferentes s√©ries.\nJ√° em rela√ß√£o aos algoritmos de minera√ß√£o de sequ√™ncias, fica evidente que ambos compartilham diversas caracter√≠sticas fundamentais. Ambos os m√©todos t√™m a capacidade de identificar padr√µes sequenciais em conjuntos de dados, baseando-se na frequ√™ncia de ocorr√™ncia desses padr√µes. Al√©m disso, ambos utilizam o conceito de suporte para filtrar padr√µes menos frequentes, priorizando aqueles que s√£o mais relevantes para a an√°lise.\nEntretanto, ao analisar as diferen√ßas entre o Z-groupings e seus equivalentes na minera√ß√£o de sequ√™ncia, destacam-se aspectos distintivos que delineiam a aplica√ß√£o espec√≠fica do Z-groupings em contextos de s√©ries temporais. Enquanto muitos algoritmos de minera√ß√£o de sequ√™ncia s√£o aplic√°veis a diversos tipos de dados, o Z-groupings √© especialmente projetado para lidar com s√©ries temporais. Sua funcionalidade principal reside na capacidade de agrupar sequ√™ncias temporais em grupos locais, visando identificar associa√ß√µes significativas entre os padr√µes temporais presentes nos dados. Essa abordagem mais focalizada confere ao Z-groupings uma vantagem significativa em cen√°rios onde a compreens√£o das rela√ß√µes temporais √© crucial para a an√°lise e interpreta√ß√£o dos dados.\nEssas nuances ressaltam a import√¢ncia do Z-groupings como uma ferramenta especializada e eficaz para a an√°lise de s√©ries temporais, oferecendo insights valiosos e facilitando a descoberta de padr√µes e associa√ß√µes relevantes nos dados.\n\n\n\nSer√£o examinados tr√™s casos espec√≠ficos que destacam a versatilidade e utilidade do Z-groupings: o agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias, a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento usando agrupamento de s√©ries temporais, e a an√°lise de consumo de medicamentos para otimiza√ß√£o da log√≠stica de distribui√ß√£o. Cada uma dessas aplica√ß√µes oferece uma perspectiva √∫nica sobre como o Z-groupings pode ser empregado para abordar desafios complexos e promover impactos significativos em diversos setores.\n\n\nO agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias √© uma aplica√ß√£o-chave das redes inteligentes, impulsionadas pela converg√™ncia de sistemas computacionais, de medi√ß√£o e de comunica√ß√£o. Os medidores inteligentes, respons√°veis por capturar e transmitir dados de consumo em intervalos regulares, geram uma quantidade substancial de informa√ß√µes. A an√°lise desses dados, conhecida como agrupamento de curvas de carga, √© essencial para extrair insights relevantes. Neste contexto, o Z-groupings e outros algoritmos semelhantes emergem como ferramentas valiosas.\nAs implica√ß√µes dessa aplica√ß√£o s√£o diversas:\n\nPrevis√£o de demanda de energia: Identificar padr√µes de consumo semelhantes entre diferentes regi√µes possibilita prever com mais precis√£o a demanda futura de energia. Isso facilita o planejamento da produ√ß√£o e distribui√ß√£o de eletricidade pelas empresas de energia.\nDetec√ß√£o de anomalias: Ao conhecer os padr√µes de consumo t√≠picos, torna-se mais f√°cil detectar anomalias que possam indicar falhas nos equipamentos, problemas de efici√™ncia energ√©tica ou atividades suspeitas, como roubo de energia.\nPotencial para discrimina√ß√£o: O uso das informa√ß√µes sobre padr√µes de consumo para segmentar clientes ou estabelecer tarifas diferenciadas pode levar √† discrimina√ß√£o. Alguns grupos demogr√°ficos podem ser penalizados ou exclu√≠dos, aumentando as desigualdades.\nRisco de monop√≥lio: Empresas de distribui√ß√£o de energia com acesso a recursos computacionais avan√ßados para an√°lise de dados t√™m uma vantagem competitiva significativa. Isso pode resultar em um desequil√≠brio de mercado, com grandes empresas dominando e marginalizando empresas menores.\n\nEssas consequ√™ncias ressaltam a import√¢ncia n√£o apenas da aplica√ß√£o eficaz de algoritmos de agrupamento de s√©ries temporais, como o Z-groupings, mas tamb√©m da considera√ß√£o cuidadosa dos impactos sociais e √©ticos das decis√µes baseadas em dados no setor de energia el√©trica.\n\n\n\nA an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia, por meio do agrupamento de s√©ries temporais, destaca-se como uma aplica√ß√£o vital dessa t√©cnica anal√≠tica. Ao examinar as mudan√ßas no √≠ndice de cobertura vegetal ao longo do tempo, √© poss√≠vel identificar padr√µes e tend√™ncias cruciais para o monitoramento e preven√ß√£o do desmatamento, bem como para o planejamento estrat√©gico de pol√≠ticas de conserva√ß√£o.\nAs consequ√™ncias potenciais desse enfoque s√£o variadas:\n\nMonitoramento e preven√ß√£o eficazes do desmatamento: O uso do agrupamento de s√©ries temporais pode melhorar substancialmente as estrat√©gias de preven√ß√£o do desmatamento, identificando √°reas em risco e facilitando interven√ß√µes preventivas.\nPlanejamento de pol√≠ticas de conserva√ß√£o: A identifica√ß√£o de √°reas com alto risco de desmatamento possibilita o direcionamento eficiente de recursos e esfor√ßos para medidas preventivas, como programas de educa√ß√£o ambiental e refor√ßo da fiscaliza√ß√£o.\nRiscos √† privacidade: O monitoramento detalhado pode levantar preocupa√ß√µes de privacidade, revelando informa√ß√µes sens√≠veis sobre padr√µes de vida e comportamentos das comunidades locais.\nDesigualdade e discrimina√ß√£o: Restri√ß√µes ao uso da terra e acesso limitado √†s ferramentas de an√°lise podem resultar em desigualdades na distribui√ß√£o de recursos para a conserva√ß√£o.\nImpacto nos meios de subsist√™ncia locais: As pol√≠ticas de conserva√ß√£o devem considerar os impactos nas comunidades locais, garantindo que sejam justas e equitativas.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem √©tica e abrangente no uso do agrupamento de s√©ries temporais para a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia.\n\n\n\nA aplica√ß√£o do m√©todo Z-Grouping na an√°lise do consumo e distribui√ß√£o de medicamentos apresenta uma oportunidade significativa para aprimorar a gest√£o de recursos farmac√™uticos, especialmente sob a perspectiva da sa√∫de p√∫blica, com foco na atua√ß√£o da Ag√™ncia Nacional de Vigil√¢ncia Sanit√°ria (ANVISA). Ao identificar padr√µes temporais e regionais no uso de medicamentos, essa abordagem oferece insights valiosos para interven√ß√µes estrat√©gicas na log√≠stica de distribui√ß√£o.\nAs aplica√ß√µes pr√°ticas dessa an√°lise s√£o amplas:\n\nRefinamento da Log√≠stica de Distribui√ß√£o: A identifica√ß√£o de agrupamentos locais de consumo permite ajustes precisos na cadeia de suprimentos, garantindo a disponibilidade adequada de medicamentos essenciais nas regi√µes com maior demanda, o que √© crucial para garantir a continuidade dos tratamentos, especialmente em contextos de doen√ßas cr√¥nicas ou surtos de doen√ßas infecciosas.\nProje√ß√£o de Demandas Futuras: O Z-Grouping possibilita a proje√ß√£o de demandas com base em tend√™ncias hist√≥ricas, permitindo a antecipa√ß√£o de necessidades, como vacinas ou medicamentos antivirais. Essa capacidade preditiva √© fundamental para evitar escassez ou excesso de estoques, possibilitando uma resposta eficiente √†s flutua√ß√µes do mercado e demandas emergentes.\nDiagn√≥stico de Desperd√≠cios e Inefici√™ncias: Al√©m disso, essa abordagem revela padr√µes de subutiliza√ß√£o ou desperd√≠cio de medicamentos, indicando √°reas potenciais para otimiza√ß√£o das pol√≠ticas de distribui√ß√£o e uso racional de recursos farmac√™uticos.\n\nEntretanto, a implementa√ß√£o dessas an√°lises n√£o est√° isenta de desafios e consequ√™ncias, como:\n\nIntegridade e Seguran√ßa dos Dados: A gest√£o cuidadosa da integridade e seguran√ßa dos dados √© essencial para prevenir riscos de comprometimento das an√°lises, garantindo o cumprimento das normativas de prote√ß√£o de dados, como a LGPD.\nJusti√ßa na Distribui√ß√£o de Medicamentos: H√° o risco de que an√°lises baseadas em dados n√£o reflitam com precis√£o a distribui√ß√£o demogr√°fica, resultando em aloca√ß√µes de recursos que perpetuam desequil√≠brios existentes. Portanto, √© crucial que as decis√µes de pol√≠tica farmac√™utica considerem profundamente as necessidades locais.\nRiscos da Depend√™ncia de Modelos Quantitativos: Apesar da robustez do Z-Grouping, sua aplica√ß√£o deve ser complementada por an√°lises qualitativas e conhecimento especializado em sa√∫de p√∫blica para evitar decis√µes que n√£o considerem a complexidade dos padr√µes de sa√∫de espec√≠ficos.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem hol√≠stica e cuidadosa na utiliza√ß√£o do Z-Grouping para an√°lise de consumo de medicamentos e sua distribui√ß√£o, visando garantir benef√≠cios significativos sem comprometer a integridade dos dados ou perpetuar desigualdades existentes."
  },
  {
    "objectID": "seminario1/artigo2.html#contextualiza√ß√£o-do-problema",
    "href": "seminario1/artigo2.html#contextualiza√ß√£o-do-problema",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "A motiva√ß√£o por tr√°s dessa abordagem √© multifacetada. No setor de varejo, por exemplo, a identifica√ß√£o de tend√™ncias locais de compra, como picos de vendas durante per√≠odos festivos, pode ser crucial para otimizar estrat√©gias de marketing e estoque. Da mesma forma, em an√°lises financeiras, compreender as tend√™ncias de mercado pode orientar decis√µes de investimento. Em setores como sa√∫de e biomedicina, a an√°lise de varia√ß√µes sazonais e padr√µes de sono pode contribuir para o desenvolvimento de tratamentos mais eficazes. Al√©m disso, o planejamento de recursos, a detec√ß√£o de anomalias de seguran√ßa e a an√°lise de dados ambientais e clim√°ticos tamb√©m se beneficiam significativamente da capacidade de identificar e compreender padr√µes em s√©ries temporais.\nNeste contexto, este artigo aborda a import√¢ncia da abordagem de agrupamento de s√©ries temporais, com foco no algoritmo Z-groupings. Exploraremos como esse m√©todo oferece uma perspectiva √∫nica para a identifica√ß√£o de grupos locais em s√©ries temporais, destacando sua relev√¢ncia e aplicabilidade em diversas √°reas de estudo e pr√°tica. Ao compreendermos melhor as nuances e potenciais aplica√ß√µes do Z-groupings, podemos abrir novas oportunidades para an√°lises mais precisas e insights mais profundos em uma variedade de dom√≠nios."
  },
  {
    "objectID": "seminario1/artigo2.html#relacionamento-com-m√©todos-cl√°ssicos",
    "href": "seminario1/artigo2.html#relacionamento-com-m√©todos-cl√°ssicos",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "O algoritmo Z-groupings n√£o possui comparativos diretos. No entanto, existem alguns m√©todos cl√°ssicos que realizam tarefas compar√°veis:\n\nK-means: Este m√©todo particiona s√©ries temporais em k clusters, onde os clusters representam grupos locais an√°logos aos encontrados pelo Z-groupings.\nAgrupamento Hier√°rquico: Neste m√©todo, as s√©ries temporais s√£o hierarquicamente divididas com base em uma m√©trica de similaridade. Os grupos resultantes s√£o compar√°veis aos grupos locais identificados pelo Z-groupings.\n\nContudo, √© importante ressaltar que esses algoritmos n√£o s√£o diretamente compar√°veis, pois se limitam a encontrar similaridades dentro de uma √∫nica s√©rie temporal, n√£o considerando rela√ß√µes entre diferentes s√©ries.\nJ√° em rela√ß√£o aos algoritmos de minera√ß√£o de sequ√™ncias, fica evidente que ambos compartilham diversas caracter√≠sticas fundamentais. Ambos os m√©todos t√™m a capacidade de identificar padr√µes sequenciais em conjuntos de dados, baseando-se na frequ√™ncia de ocorr√™ncia desses padr√µes. Al√©m disso, ambos utilizam o conceito de suporte para filtrar padr√µes menos frequentes, priorizando aqueles que s√£o mais relevantes para a an√°lise.\nEntretanto, ao analisar as diferen√ßas entre o Z-groupings e seus equivalentes na minera√ß√£o de sequ√™ncia, destacam-se aspectos distintivos que delineiam a aplica√ß√£o espec√≠fica do Z-groupings em contextos de s√©ries temporais. Enquanto muitos algoritmos de minera√ß√£o de sequ√™ncia s√£o aplic√°veis a diversos tipos de dados, o Z-groupings √© especialmente projetado para lidar com s√©ries temporais. Sua funcionalidade principal reside na capacidade de agrupar sequ√™ncias temporais em grupos locais, visando identificar associa√ß√µes significativas entre os padr√µes temporais presentes nos dados. Essa abordagem mais focalizada confere ao Z-groupings uma vantagem significativa em cen√°rios onde a compreens√£o das rela√ß√µes temporais √© crucial para a an√°lise e interpreta√ß√£o dos dados.\nEssas nuances ressaltam a import√¢ncia do Z-groupings como uma ferramenta especializada e eficaz para a an√°lise de s√©ries temporais, oferecendo insights valiosos e facilitando a descoberta de padr√µes e associa√ß√µes relevantes nos dados."
  },
  {
    "objectID": "seminario1/artigo2.html#impacto-social-e-potenciais-aplica√ß√µes",
    "href": "seminario1/artigo2.html#impacto-social-e-potenciais-aplica√ß√µes",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "Ser√£o examinados tr√™s casos espec√≠ficos que destacam a versatilidade e utilidade do Z-groupings: o agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias, a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento usando agrupamento de s√©ries temporais, e a an√°lise de consumo de medicamentos para otimiza√ß√£o da log√≠stica de distribui√ß√£o. Cada uma dessas aplica√ß√µes oferece uma perspectiva √∫nica sobre como o Z-groupings pode ser empregado para abordar desafios complexos e promover impactos significativos em diversos setores.\n\n\nO agrupamento de s√©ries temporais de consumo de energia el√©trica em resid√™ncias √© uma aplica√ß√£o-chave das redes inteligentes, impulsionadas pela converg√™ncia de sistemas computacionais, de medi√ß√£o e de comunica√ß√£o. Os medidores inteligentes, respons√°veis por capturar e transmitir dados de consumo em intervalos regulares, geram uma quantidade substancial de informa√ß√µes. A an√°lise desses dados, conhecida como agrupamento de curvas de carga, √© essencial para extrair insights relevantes. Neste contexto, o Z-groupings e outros algoritmos semelhantes emergem como ferramentas valiosas.\nAs implica√ß√µes dessa aplica√ß√£o s√£o diversas:\n\nPrevis√£o de demanda de energia: Identificar padr√µes de consumo semelhantes entre diferentes regi√µes possibilita prever com mais precis√£o a demanda futura de energia. Isso facilita o planejamento da produ√ß√£o e distribui√ß√£o de eletricidade pelas empresas de energia.\nDetec√ß√£o de anomalias: Ao conhecer os padr√µes de consumo t√≠picos, torna-se mais f√°cil detectar anomalias que possam indicar falhas nos equipamentos, problemas de efici√™ncia energ√©tica ou atividades suspeitas, como roubo de energia.\nPotencial para discrimina√ß√£o: O uso das informa√ß√µes sobre padr√µes de consumo para segmentar clientes ou estabelecer tarifas diferenciadas pode levar √† discrimina√ß√£o. Alguns grupos demogr√°ficos podem ser penalizados ou exclu√≠dos, aumentando as desigualdades.\nRisco de monop√≥lio: Empresas de distribui√ß√£o de energia com acesso a recursos computacionais avan√ßados para an√°lise de dados t√™m uma vantagem competitiva significativa. Isso pode resultar em um desequil√≠brio de mercado, com grandes empresas dominando e marginalizando empresas menores.\n\nEssas consequ√™ncias ressaltam a import√¢ncia n√£o apenas da aplica√ß√£o eficaz de algoritmos de agrupamento de s√©ries temporais, como o Z-groupings, mas tamb√©m da considera√ß√£o cuidadosa dos impactos sociais e √©ticos das decis√µes baseadas em dados no setor de energia el√©trica.\n\n\n\nA an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia, por meio do agrupamento de s√©ries temporais, destaca-se como uma aplica√ß√£o vital dessa t√©cnica anal√≠tica. Ao examinar as mudan√ßas no √≠ndice de cobertura vegetal ao longo do tempo, √© poss√≠vel identificar padr√µes e tend√™ncias cruciais para o monitoramento e preven√ß√£o do desmatamento, bem como para o planejamento estrat√©gico de pol√≠ticas de conserva√ß√£o.\nAs consequ√™ncias potenciais desse enfoque s√£o variadas:\n\nMonitoramento e preven√ß√£o eficazes do desmatamento: O uso do agrupamento de s√©ries temporais pode melhorar substancialmente as estrat√©gias de preven√ß√£o do desmatamento, identificando √°reas em risco e facilitando interven√ß√µes preventivas.\nPlanejamento de pol√≠ticas de conserva√ß√£o: A identifica√ß√£o de √°reas com alto risco de desmatamento possibilita o direcionamento eficiente de recursos e esfor√ßos para medidas preventivas, como programas de educa√ß√£o ambiental e refor√ßo da fiscaliza√ß√£o.\nRiscos √† privacidade: O monitoramento detalhado pode levantar preocupa√ß√µes de privacidade, revelando informa√ß√µes sens√≠veis sobre padr√µes de vida e comportamentos das comunidades locais.\nDesigualdade e discrimina√ß√£o: Restri√ß√µes ao uso da terra e acesso limitado √†s ferramentas de an√°lise podem resultar em desigualdades na distribui√ß√£o de recursos para a conserva√ß√£o.\nImpacto nos meios de subsist√™ncia locais: As pol√≠ticas de conserva√ß√£o devem considerar os impactos nas comunidades locais, garantindo que sejam justas e equitativas.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem √©tica e abrangente no uso do agrupamento de s√©ries temporais para a an√°lise da rela√ß√£o entre manejos madeireiros e desmatamento na Amaz√¥nia.\n\n\n\nA aplica√ß√£o do m√©todo Z-Grouping na an√°lise do consumo e distribui√ß√£o de medicamentos apresenta uma oportunidade significativa para aprimorar a gest√£o de recursos farmac√™uticos, especialmente sob a perspectiva da sa√∫de p√∫blica, com foco na atua√ß√£o da Ag√™ncia Nacional de Vigil√¢ncia Sanit√°ria (ANVISA). Ao identificar padr√µes temporais e regionais no uso de medicamentos, essa abordagem oferece insights valiosos para interven√ß√µes estrat√©gicas na log√≠stica de distribui√ß√£o.\nAs aplica√ß√µes pr√°ticas dessa an√°lise s√£o amplas:\n\nRefinamento da Log√≠stica de Distribui√ß√£o: A identifica√ß√£o de agrupamentos locais de consumo permite ajustes precisos na cadeia de suprimentos, garantindo a disponibilidade adequada de medicamentos essenciais nas regi√µes com maior demanda, o que √© crucial para garantir a continuidade dos tratamentos, especialmente em contextos de doen√ßas cr√¥nicas ou surtos de doen√ßas infecciosas.\nProje√ß√£o de Demandas Futuras: O Z-Grouping possibilita a proje√ß√£o de demandas com base em tend√™ncias hist√≥ricas, permitindo a antecipa√ß√£o de necessidades, como vacinas ou medicamentos antivirais. Essa capacidade preditiva √© fundamental para evitar escassez ou excesso de estoques, possibilitando uma resposta eficiente √†s flutua√ß√µes do mercado e demandas emergentes.\nDiagn√≥stico de Desperd√≠cios e Inefici√™ncias: Al√©m disso, essa abordagem revela padr√µes de subutiliza√ß√£o ou desperd√≠cio de medicamentos, indicando √°reas potenciais para otimiza√ß√£o das pol√≠ticas de distribui√ß√£o e uso racional de recursos farmac√™uticos.\n\nEntretanto, a implementa√ß√£o dessas an√°lises n√£o est√° isenta de desafios e consequ√™ncias, como:\n\nIntegridade e Seguran√ßa dos Dados: A gest√£o cuidadosa da integridade e seguran√ßa dos dados √© essencial para prevenir riscos de comprometimento das an√°lises, garantindo o cumprimento das normativas de prote√ß√£o de dados, como a LGPD.\nJusti√ßa na Distribui√ß√£o de Medicamentos: H√° o risco de que an√°lises baseadas em dados n√£o reflitam com precis√£o a distribui√ß√£o demogr√°fica, resultando em aloca√ß√µes de recursos que perpetuam desequil√≠brios existentes. Portanto, √© crucial que as decis√µes de pol√≠tica farmac√™utica considerem profundamente as necessidades locais.\nRiscos da Depend√™ncia de Modelos Quantitativos: Apesar da robustez do Z-Grouping, sua aplica√ß√£o deve ser complementada por an√°lises qualitativas e conhecimento especializado em sa√∫de p√∫blica para evitar decis√µes que n√£o considerem a complexidade dos padr√µes de sa√∫de espec√≠ficos.\n\nEssas considera√ß√µes destacam a import√¢ncia de uma abordagem hol√≠stica e cuidadosa na utiliza√ß√£o do Z-Grouping para an√°lise de consumo de medicamentos e sua distribui√ß√£o, visando garantir benef√≠cios significativos sem comprometer a integridade dos dados ou perpetuar desigualdades existentes."
  },
  {
    "objectID": "seminario1/artigo2.html#conceitos-chave",
    "href": "seminario1/artigo2.html#conceitos-chave",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.1 Conceitos Chave",
    "text": "2.1 Conceitos Chave\nPara compreender o algoritmo Z-Grouping, √© fundamental dominar alguns conceitos fundamentais.\n\n\nCode\nfrom zgrouping.zgrouping import grouping, syntheticGenerator, utils\nimport matplotlib.pyplot as plt\n\n\n\nS√©ries Temporais: Uma s√©rie temporal consiste em observa√ß√µes coletadas sequencialmente ao longo do tempo. Cada observa√ß√£o est√° vinculada a um instante espec√≠fico, sendo a ordem das observa√ß√µes de crucial import√¢ncia. Exemplo: Uma s√©rie temporal pode registrar as vendas di√°rias de um produto ao longo de um per√≠odo, como as vendas di√°rias de um modelo de smartphone em uma loja.\n\n\n\nCode\ntc = 50\ntl = 365\nc = 20\nno_outliers = 10\noutlier_size = 10\n\n# GROUPING GENERATION\nn_bins = 5\nalpha = 0.9\neta = 1.5\n\nX_raw, y = syntheticGenerator.createSyntheticData(tc = tc, tl=tl, c = c, no_outliers = no_outliers, outlier_size=outlier_size)\nplt.plot(X_raw[0])\n\n\n\n\n\n\n\n\n\n\nAbstra√ß√£o Temporal: A abstra√ß√£o temporal √© o processo de simplificar ou extrair caracter√≠sticas mais significativas de uma s√©rie temporal, facilitando sua an√°lise. Exemplo: A aplica√ß√£o do Symbolic Aggregate Approximation (SAX) para converter uma s√©rie temporal de vendas di√°rias em uma sequ√™ncia de s√≠mbolos que representam padr√µes de vendas ao longo do tempo.\nEventos em S√©ries Temporais: Um evento em uma s√©rie temporal √© uma ocorr√™ncia distinta ou uma caracter√≠stica identific√°vel nos dados ao longo do tempo, como picos, vales, transi√ß√µes ou padr√µes recorrentes.\nR√≥tulos de Eventos: Os r√≥tulos de eventos s√£o atributos simb√≥licos ou categoriza√ß√µes aplicadas aos eventos em uma s√©rie temporal para represent√°-los de maneira simplificada e compreens√≠vel. Exemplo: Os r√≥tulos podem ser escolhidos de um conjunto discreto de s√≠mbolos ou categorias, como letras, n√∫meros ou outros identificadores simb√≥licos.\nMatriz de Sequ√™ncia de Eventos: Uma matriz que representa a sequ√™ncia de r√≥tulos de eventos derivados das s√©ries temporais ap√≥s a abstra√ß√£o temporal. Cada entrada na matriz representa um evento em uma s√©rie temporal espec√≠fica.\nAgrupamento Local: O agrupamento local refere-se √† identifica√ß√£o de subconjuntos de s√©ries temporais que exibem padr√µes semelhantes em intervalos espec√≠ficos de tempo. No contexto do Z-Grouping, os agrupamentos locais s√£o identificados em cada canal de r√≥tulo de evento.\nAssocia√ß√£o de Agrupamentos Locais: Associa√ß√µes s√£o identificadas entre agrupamentos locais consecutivos ou sobrepostos que compartilham inst√¢ncias de s√©ries temporais semelhantes. O objetivo √© descobrir padr√µes mais amplos e complexos que n√£o seriam detectados apenas nos agrupamentos locais individuais.\nSemigeometric Tiling: Um algoritmo utilizado para identificar padr√µes ou agrupamentos em matrizes bin√°rias, considerando combina√ß√µes de intervalos de tempo e contagens de eventos.\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)\n\n\n\nMatriz de Associa√ß√£o e Valida√ß√£o: Uma representa√ß√£o matricial usada para identificar e validar associa√ß√µes entre agrupamentos locais. Essa matriz registra as rela√ß√µes entre os agrupamentos locais e os agrupamentos globais pr√©-definidos.\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)"
  },
  {
    "objectID": "seminario1/artigo2.html#apresenta√ß√£o-do-algoritmo",
    "href": "seminario1/artigo2.html#apresenta√ß√£o-do-algoritmo",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.2 Apresenta√ß√£o do Algoritmo",
    "text": "2.2 Apresenta√ß√£o do Algoritmo\nO algoritmo Z-Grouping √© composto por quatro passos distintos, cada um focado em uma etapa espec√≠fica do processo de an√°lise de s√©ries temporais. S√£o eles:\n\nGera√ß√£o da Matriz de Sequ√™ncia de Eventos\nNeste passo, uma cole√ß√£o de s√©ries temporais √© convertida em uma matriz de eventos, utilizando t√©cnicas de abstra√ß√£o temporal como o m√©todo SAX. Isso permite uma representa√ß√£o mais simplificada dos dados, facilitando a an√°lise subsequente.\n\n\n\nCode\nX = utils.znorm(X_raw)\nX_sax = utils.SAXify(X, n_bins = 5)\nX_sax[0]\n\n\narray([2, 2, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\n\nCode\nplt.plot(X_raw[0])\nplt.plot(X_sax[0])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCria√ß√£o de canais de r√≥tulos\nA matriz de eventos em seguida √© subdividida em uma matriz bin√°ria de mesmo tamanho para cada r√≥tulo\n\n\n\nCode\nmatrices = utils.createChannels(X_sax)\nmatrices[0]\n\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)\n\n\n\nGera√ß√£o de Agrupamentos Locais\nO pr√≥ximo passo envolve a identifica√ß√£o de agrupamentos locais em cada canal de r√≥tulo de evento da matriz de eventos. Esse processo √© conduzido pelo algoritmo de semigeometric tiling, que busca candidatos a agrupamentos locais com base na contagem de eventos em intervalos de tempo espec√≠ficos. Al√©m disso, o algoritmo utiliza um par√¢metro ùù∞, variando de 0 a 1, para determinar a pureza de um agrupamento local. Por exemplo, ao definir ùù∞ como 0.75, estamos estabelecendo que pelo menos 75% dos elementos do agrupamento devem conter o evento analisado.\nIdentifica√ß√£o de Associa√ß√µes entre Agrupamentos Locais\nNesta etapa, o algoritmo procura associa√ß√µes entre os agrupamentos locais identificados. Isso √© feito atrav√©s da an√°lise de candidatos a associa√ß√µes consecutivas, verificando a proximidade entre elas e identificando inst√¢ncias de s√©ries temporais compartilhadas.\nValida√ß√£o dos Agrupamentos Locais\nPor fim, os agrupamentos locais s√£o validados em rela√ß√£o aos agrupamentos globais pr√©-definidos. Isso √© feito calculando uma pontua√ß√£o de validade com base na propor√ß√£o de inst√¢ncias de s√©ries temporais em comum e utilizando um par√¢metro de densidade para controlar a validade dos agrupamentos locais.\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)\n\n\n\n\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)\n\n\n\n\nFigure¬†1: Um exemplo dos quatro passos do Z-grouping"
  },
  {
    "objectID": "seminario1/artigo2.html#metodologia-experimental",
    "href": "seminario1/artigo2.html#metodologia-experimental",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.3 Metodologia Experimental",
    "text": "2.3 Metodologia Experimental\nA metodologia experimental da pesquisa visa avaliar o desempenho do m√©todo Z-Grouping na identifica√ß√£o de agrupamentos locais em s√©ries temporais. Para isso, foi utilizada uma abordagem abrangente que inclui a an√°lise de conjuntos de dados reais de diferentes setores, bem como um conjunto de dados sint√©tico para investiga√ß√£o detalhada dos par√¢metros do m√©todo. Al√©m disso, alguns m√©todos foram adaptados para efeitos de compara√ß√£o. Abaixo, √© fornecida uma descri√ß√£o mais detalhada da metodologia utilizada.\n\nDatasets: Os conjuntos de dados reais utilizados abrangem tr√™s setores diferentes: ind√∫stria de varejo, mercado de a√ß√µes e epidemias de COVID-19. Al√©m disso, um conjunto de dados sint√©tico foi gerado para investiga√ß√£o detalhada dos par√¢metros do m√©todo. Este conjunto de dados sint√©tico simula a presen√ßa de similaridade local em meio a padr√µes sinusoidais com diferentes frequ√™ncias e amplitudes, al√©m de incorporar ru√≠do e outliers para refletir cen√°rios do mundo real.\nConcorrentes: Como n√£o existe um concorrente direto para o problema, foram feitas adapta√ß√µes nos m√©todos semigeometric tiling, kmeans, kmeans-FLEX e kNN para identificar agrupamentos locais em s√©ries temporais.\nProtocolo do Experimento: Para avaliar o desempenho do m√©todo Z-Grouping, foi desenvolvido um protocolo de experimento que envolve a divis√£o dos dados em conjuntos de treinamento e teste. Durante a fase de treinamento, os agrupamentos locais s√£o identificados nos dados de treinamento. Na fase de teste, o objetivo √© determinar se os agrupamentos identificados podem identificar padr√µes de similaridade local em novas inst√¢ncias n√£o vistas. Para cada amostra de teste, o agrupamento global correspondente √© usado como refer√™ncia. Isso simula situa√ß√µes do mundo real, como identificar padr√µes de vendas de um novo produto com base em produtos existentes.\nM√©tricas de Avalia√ß√£o: Os resultados s√£o avaliados em termos de erros de predi√ß√£o, como erro quadr√°tico m√©dio (MSE) e erro absoluto m√©dio (MAE), bem como a cobertura dos agrupamentos, ou seja, a fra√ß√£o de s√©ries temporais cobertas pelos agrupamentos identificados."
  },
  {
    "objectID": "seminario1/artigo2.html#an√°lise-cr√≠tica-dos-resultados",
    "href": "seminario1/artigo2.html#an√°lise-cr√≠tica-dos-resultados",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.4 An√°lise Cr√≠tica dos Resultados",
    "text": "2.4 An√°lise Cr√≠tica dos Resultados\nEm rela√ß√£o aos resultados alcan√ßados, todos foram validados 10 vezes, e os seguintes par√¢metros foram utilizados:\nŒ±: Este √© um par√¢metro que controla o n√≠vel de ‚Äúpureza‚Äù dos agrupamentos.\nŒª: Este par√¢metro controla o n√∫mero de r√≥tulos de abstra√ß√£o que o algoritmo pode usar.\nŒ∑: Este par√¢metro define o n√∫mero m√≠nimo de amostras necess√°rias para que um agrupamento seja considerado v√°lido.\nw: Este √© o intervalo de tempo (em n√∫mero de amostras) que esses algoritmos usam para identificar os agrupamentos locais.\nk: Este √© o n√∫mero de agrupamentos (clusters) que esses algoritmos tentam formar.\nCorte de silhueta: Este √© um par√¢metro que define um valor de corte para a m√©trica de silhueta.\nOs algoritmos testados utilizaram os seguintes par√¢metros:\nZ-Grouping: Œ± = {0.8, 0.9, 1}, Œª = {3, 5, 10}, e Œ∑ = {1, 1.5, 2}.\nSemigeometric: Œ± = {0.8, 0.9, 1}, e Œ∑ = {1, 1.5, 2}.\nkmeans: intervalo de tempo w = {30, 60, 180} e k = {3, 5, 10}.\nkNN: intervalo de tempo w = {30, 60, 180} e k = {3, 5, 10}.\nkmeans-FLEX: corte de silhueta de 0,1 at√© falha em detectar quaisquer agrupamentos v√°lidos.\nEm rela√ß√£o aos resultados no conjunto de dados sint√©ticos, pode-se analisar atrav√©s da tabela 2 os erros de teste m√©dios do Z-Grouping e seus quatro competidores. Atrav√©s dela podemos chegar a algumas conclus√µes em rela√ß√£o ao Z-Grouping e seus concorrentes:\n\nO Z-Grouping sempre consegue encontrar agrupamentos locais v√°lidos de baixos erros considerando MSE e MAE;\nSemigeometric sofre com sua falta de poder de representa√ß√£o com uma forte suposi√ß√£o bin√°ria superado pelo Z-Grouping em rela√ß√£o aos agrupamentos locais;\nkNN atinge seu melhor escore com {w: 180, k: 3};\nkmeans n√£o mostra diferen√ßas not√°veis com v√°rias configura√ß√µes de par√¢metros, e √© geralmente pior do que seus concorrentes;\nKmeans-FLEX tem seu menor MSE sendo apenas 3,4% menor que o menor erro do kmeans;\nO Semigeometric, kmeans, kNN e kmeans-FLEX s√£o piores do que o Z-Grouping em todas as situa√ß√µes.\n\nAl√©m disso, utilizando os dados de UCR o Z-Grouping apresentou dificuldade para encontrar padr√µes para o agrupamento, performando de forma semelhante aos competidores devido a perda de informa√ß√£o pelo SAX em conjuntos mais uniformes.\nJ√° em rela√ß√£o aos resultados no conjunto de dados reais, com os dados de GARMENT e STOCK o Z-Grouping apresentou resultados com diferen√ßa de 44.3% (MSE) e 25.2% (MAE) com cobertura de 88% dos dados, sendo superior aos competidores. E com os dados da COVID pode-se perceber que o trade-off de minimiza√ß√£o do erro por perda de cobertura acabou levando o algoritmo a desempenhar com pouca melhora, sacrificando bastante da cobertura, cobrindo apenas 40% dos dados.\nPor fim, ao analisarmos o efeito dos par√¢metros, um Œª maior pode levar a uma menor cobertura, um Œ± maior leva a agrupamentos mais puros o que permite um n√∫mero menor de r√≥tulos de evento diferentes, e um Œ∑ maior exige mais amostras no agrupamento local para validade resultando em menos agrupamentos. Os par√¢metros mais altos fazem com que o algoritmo perca sua capacidade de crescer mostrando aproximadamente s√≥ 10% de cobertura, al√©m de gerar erros mais altos devido √† aus√™ncia de pontos de dados para compara√ß√£o. Por isso as associa√ß√µes dos agrupamentos s√£o utilizadas para aumentar a cobertura preenchendo as lacunas criadas pelos altos valores dos par√¢metros.\n\n\n\nTable¬†1: Erros m√©dios de teste dos algoritmos no banco de dados Sint√©tico (CV: Covarege(%))\n\n\n\n\n\nFonte: Z. Lee et al.¬†(2022)"
  },
  {
    "objectID": "seminario1/artigo2.html#sum√°rio-dos-resultados",
    "href": "seminario1/artigo2.html#sum√°rio-dos-resultados",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "3.1 Sum√°rio dos Resultados",
    "text": "3.1 Sum√°rio dos Resultados\nO Z-Grouping foi testado contra quatro solu√ß√µes alternativas para o problema de agrupamentos locais, baseadas em adapta√ß√µes para o problema espec√≠fico proposto no artigo de abordagens utilizadas de maneira geral em agrupamentos de s√©ries temporais. Os cinco foram avaliados em tr√™s datasets com dados do mundo real, um dataset gerado sinteticamente e os 128 datasets cl√°ssicos de s√©ries temporais da UCR (University of California, Riverside). O resultado dos experimentos constatou que o Z-Grouping atingiu taxas de erro menores do que seus competidores, e ao mesmo tempo gerou agrupamentos locais sem limita√ß√µes no tamanho dos intervalos de tempo, o que n√£o pode ser feito utilizando as demais abordagens."
  },
  {
    "objectID": "seminario1/artigo2.html#considera√ß√µes-finais-e-sugest√µes-para-futuras-pesquisas",
    "href": "seminario1/artigo2.html#considera√ß√µes-finais-e-sugest√µes-para-futuras-pesquisas",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "3.2 Considera√ß√µes Finais e Sugest√µes para Futuras Pesquisas",
    "text": "3.2 Considera√ß√µes Finais e Sugest√µes para Futuras Pesquisas\nPoss√≠veis abordagens de pesquisas futuras podem incluir o uso de outras fun√ß√µes de abstra√ß√£o temporal (al√©m da SAX, utilizada no artigo), a aplica√ß√£o de t√©cnicas e heur√≠sticas de otimiza√ß√£o global na cria√ß√£o dos agrupamentos locais e o estudo de adapta√ß√µes do algoritmo para s√©ries temporais multivariadas, isto √©, para a gera√ß√£o de agrupamentos multidimensionais."
  },
  {
    "objectID": "seminario1/artigo2.html#instala√ß√£o",
    "href": "seminario1/artigo2.html#instala√ß√£o",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.1 Instala√ß√£o",
    "text": "5.1 Instala√ß√£o\nPara utilizar o Z-Grouping, √© necess√°rio ter instaladas as extens√µes numba, numpy, pyts e o Python em sua vers√£o 3.7 ou superior. Devido √†s depend√™ncias utilizadas, recomenda-se a utiliza√ß√£o do Python 3.8 ou superior para evitar conflitos de vers√£o.\nPara instalar o Python 3.8, siga os passos abaixo:\n\nInstale as depend√™ncias necess√°rias:\n\nsudo apt-get install libsqlite3-dev ## (ou sqlite-devel dependendo do SO). \ncd /opt/ \nsudo wget https://www.python.org/ftp/python/3.8.3/Python-3.8.3.tgz \nsudo tar -xzf Python-3.8.3.tgz \ncd Python-3.8.3 \nsudo ./configure --enable-optimizations --enable-loadable-sqlite-extensions \nsudo make altinstall \n\nAtive o ambiente com Python 3.8:\n\npython3.8 -m venv ./.venv \nsource .venv/bin/activate \npip install --upgrade pip \npip install numba numpy==1.19.5 pyts matplotlib==3.3.1 \n\nPor fim, para instalar o Z-Grouping, siga estas instru√ß√µes:\n\ngit clone https://github.com/zedshape/zgrouping.git \ncd zgrouping \nCertifique-se de seguir esses passos com aten√ß√£o para garantir uma instala√ß√£o bem-sucedida do Z-Grouping em seu ambiente de desenvolvimento."
  },
  {
    "objectID": "seminario1/artigo2.html#utiliza√ß√£o-do-algoritmo-z-grouping",
    "href": "seminario1/artigo2.html#utiliza√ß√£o-do-algoritmo-z-grouping",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.2 Utiliza√ß√£o do Algoritmo Z-Grouping",
    "text": "5.2 Utiliza√ß√£o do Algoritmo Z-Grouping\nO algoritmo pode ser facilmente executado importando o m√©todo createGroupings do reposit√≥rio fornecido:\nfrom zgrouping.syntheticGenerator import createSyntheticData \nEle recebe os seguintes par√¢metros: * matrices: matriz de labels de evento. Essa matriz pode ser gerada utilizando o m√©todo utils.createChannel sobre as s√©ries temporais de entrada. * alpha: o limiar de pureza. * debug: op√ß√µes de print e debug. * accept: habilita a fun√ß√£o de valida√ß√£o da qualidade dos agrupamentos."
  },
  {
    "objectID": "seminario1/artigo2.html#datasets",
    "href": "seminario1/artigo2.html#datasets",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.3 Datasets",
    "text": "5.3 Datasets\nO reposit√≥rio do Z-Grouping j√° cont√©m bases de dados para teste e avalia√ß√£o do algoritmo, localizadas na pasta datasets. Algumas das bases de dados incluem: * Covid-19: Base de dados referente ao continente do pa√≠s, pa√≠s e contagem de casos de covid no pa√≠s de 22/01/2020 at√© 30/09/2021. * Stocks: Base de dados de a√ß√µes contendo informa√ß√µes como data do registro, valor de abertura do dia, maior valor no dia, menor valor no dia, volume e TAG (nome) da a√ß√£o.\nAl√©m disso, o reposit√≥rio inclui um gerador de bases de dados sint√©ticas, que cria padr√µes entre s√©ries temporais. Este gerador pode ser utilizado importando o m√©todo createSyntheticData do reposit√≥rio:\nfrom zgrouping.syntheticGenerator import createSyntheticData\nO m√©todo syntheticGenerator.createSyntheticData requer os seguintes argumentos: * c: N√∫mero de agrupamentos globais. * tc: N√∫mero de membros da inst√¢ncia por agrupamento. * tl: Tamanho de cada s√©rie temporal. * no_outliers: N√∫mero de outliers. * outlier_size: Tamanho do outlier. * amp: Amplitude. * lineranges: Comprimento de linhas retas. * lineheights: Altura das linhas retas.\nEsses datasets sint√©ticos podem ser utilizados como substitutos para os datasets reais mencionados anteriormente. No entanto, ainda √© necess√°rio passar essas bases pelo m√©todo de cria√ß√£o de canais, que √© o dado de entrada para o algoritmo de agrupamento."
  },
  {
    "objectID": "seminario1/artigo2.html#exemplo-de-uso",
    "href": "seminario1/artigo2.html#exemplo-de-uso",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.4 Exemplo de Uso",
    "text": "5.4 Exemplo de Uso\nPara ilustrar o uso do Z-Grouping, apresentamos a seguir um exemplo pr√°tico de execu√ß√£o do algoritmo. Os passos a seguir demonstram como gerar dados sint√©ticos, aplicar transforma√ß√µes e finalmente executar o Z-Grouping para obter os agrupamentos desejados.\nAp√≥s a gera√ß√£o e transforma√ß√£o dos dados, ser√° obtida uma matriz com padr√µes simb√≥licos, representando s√©ries temporais. A seguir, √© apresentado um exemplo dos dados antes e depois da transforma√ß√£o.\n\n\nCode\nfrom zgrouping.zgrouping import grouping, syntheticGenerator, utils \nimport matplotlib.pyplot as plt \n\n# Synthetic generator \ntc = 50 \ntl = 365 \nc = 20 \nno_outliers = 10 \noutlier_size = 10 \n\n# Grouping generation \nn_bins = 5 \nalpha = 0.9 \neta = 1.5 \n\nX_raw, y = syntheticGenerator.createSyntheticData(tc=tc, tl=tl, c=c, no_outliers=no_outliers, outlier_size=outlier_size) \n\n# Normaliza√ß√£o e Transforma√ß√£o \nX = utils.znorm(X_raw)  \nX_sax = utils.SAXify(X, n_bins=5) \n\n# Visualiza√ß√£o dos dados \nplt.plot(X_raw[150], label='antes') \nplt.plot(X_sax[150], label='depois')\nplt.title('Dados sint√©ticos antes e depois da transforma√ß√£o')\nplt.legend()\nplt.show()\nprint(X_sax[150]) \n\n\n\n\n\n\n\n\n\n[2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4\n 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3\n 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2\n 2 2 2 2 2 2 3 3 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 4 3 3\n 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 4 1 1 1 1 1 1 1 1 1 2 1 2 2 2]\n\n\nAp√≥s a prepara√ß√£o dos dados, eles ser√£o utilizados como entrada para a cria√ß√£o dos canais do Z-Grouping. A matriz resultante deve ter dimens√µes \\(S \\times T\\), onde \\(S\\) √© o n√∫mero de s√©ries temporais e \\(T\\) √© o tamanho de cada s√©rie temporal. Isso significa que cada linha da matriz representa uma s√©rie temporal e cada coluna representa o valor daquela s√©rie temporal em um determinado tempo.\n\n\nCode\nmatrices = utils.createChannels(X_sax)\n\n\nCom os canais devidamente criados, ser√° utilizado o Z-Grouping para obter os agrupamentos desejados. O c√≥digo a seguir demonstra como executar o algoritmo e obter os agrupamentos:\n\n\nCode\ngroupings, associations = grouping.createGroupings(matrices, alpha=alpha, accept=False, debug=True) \n\n\n[DEBUG] BEGIN Local grouping generation\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 44.951890109000004\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 36.923591759\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 26.490854166999995\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 36.19687330400001\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 29.767859024000018\n[DEBUG] BEGIN Association generation\n\n\nA vari√°vel groupings resultante √© uma lista de objetos, onde cada objeto representa um agrupamento detectado. Cada agrupamento cont√©m dois campos importantes: * members: um vetor de booleanos indicando se uma s√©rie temporal pertence ou n√£o a esse agrupamento, funcionando como uma m√°scara. * range: o intervalo de tempo no qual o padr√£o se repete entre as s√©ries temporais.\nAgora, para melhor visualiza√ß√£o dos resultados, foi feita uma fun√ß√£o que desenha os gr√°ficos de algumas das s√©ries temporais pertencentes a um determinado agrupamento e destaca o padr√£o detectado.\n::: {#409c2256 .cell execution_count=9} ``` {.python .cell-code} import random\ndef print_3_examples(data, grouping, number_prints): mask = [(index, value) for (index, value) in enumerate(grouping[‚Äòmembers‚Äô])] members = list(filter(lambda tuple : tuple[1], mask))\nrandIndexList = [random.randint(0, len(members) -1) for i in range(number_prints)] \nchoosedMembers = [members[index][0] for index in randIndexList] \n\ninterval = grouping['range'][0:number_prints] \n\nfig, axs = plt.subplots(nrows=number_prints, ncols=1) \nfig.set_figheight(15) \ni = 0 \nfor ax, i in zip(axs, choosedMembers): \n    thisData = data[i] \n    patternData = list(filter(lambda tuple: interval[0] &lt;= tuple[0] &lt;= interval[1], enumerate(thisData))) \n    patternX = [pattern[0] for pattern in patternData] \n    patternY = [pattern[1] for pattern in patternData] \n    ax.plot(thisData) \n    ax.plot(patternX, patternY, 'r') \n    i += 1 \n\nplt.subplots_adjust(hspace=0.0) \nplt.show() \n\nprint(choosedMembers) \nprint_3_examples(X_raw,groupings[13], 6) ```\n::: {.cell-output .cell-output-display}  :::\n::: {.cell-output .cell-output-stdout} [602, 801, 702, 230, 437, 916] ::: :::"
  },
  {
    "objectID": "seminario1/artigo3.html",
    "href": "seminario1/artigo3.html",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "",
    "text": "A minera√ß√£o de dados √© uma √°rea de estudo e pesquisa cada vez mais frequente devido ao seu impacto e capacidade de extra√ß√£o de informa√ß√µes relevantes em grandes conjuntos de dados. Nesse sentido, uma das principais sub√°reas de minera√ß√£o de dados √© a de minera√ß√£o de subgrafos frequentes.\nEm termos gerais, dado um grafo, essa √°rea de pesquisa se concentra em descobrir algoritmos e heur√≠sticas que permitem analisar quais s√£o os subgrafos de maior import√¢ncia (motif) e que ocorrem com maior frequ√™ncia dentro desse mesmo grafo. Sabe-se que esse √© um problema de natureza dif√≠cil, devido √† alta explos√£o combinat√≥ria do espa√ßo de solu√ß√£o. Por isso, muitos estudos s√£o feitos para desenvolver uma abordagem eficiente de solu√ß√£o do problema."
  },
  {
    "objectID": "seminario1/artigo3.html#contextualiza√ß√£o-do-problema",
    "href": "seminario1/artigo3.html#contextualiza√ß√£o-do-problema",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Contextualiza√ß√£o do Problema",
    "text": "Contextualiza√ß√£o do Problema\nA motiva√ß√£o para desenvolver solu√ß√µes nesse tipo de an√°lise de dados √© diversa. Dentre as √°reas em que √© poss√≠vel aplicar essa t√©cnica, podemos destacar: a biologia e a qu√≠mica, no estudo e pesquisa de f√°rmacos e das rela√ß√µes entre √°tomos e liga√ß√µes qu√≠micas; o setor de transporte, na an√°lise de rotas mais eficientes e baratas para deslocamento; assim como redes de computadores, no estudo das conex√µes entre diferentes computadores e servidores de modo a encontrar redistribui√ß√µes mais r√°pidas e eficientes de pacotes, entre outras."
  },
  {
    "objectID": "seminario1/artigo3.html#algoritmos-cl√°ssicos",
    "href": "seminario1/artigo3.html#algoritmos-cl√°ssicos",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Algoritmos Cl√°ssicos",
    "text": "Algoritmos Cl√°ssicos\nOs algoritmos cl√°ssicos de minera√ß√£o de subgrafos frequentes baseiam-se em abordagens similares √†quelas usadas na minera√ß√£o de conjuntos de itens frequentes. Em resumo, consistem na gera√ß√£o de candidatos e no crescimento de padr√µes para encontrar os subgrafos recorrentes na base de dados.\nTais abordagens apresentam tanto vantagens como desvantagens, dentre as quais vale destacar:\n\n\n\n\n\n\n\n\n\nGera√ß√£o de Candidatos\nCrescimento de Padr√µes\n\n\n\n\nVantagens\n- Simples\n- Redu√ß√£o do espa√ßo de busca por meio de podas\n\n\n\n- Natural\n- Elimina√ß√£o de redund√¢ncias\n\n\n\n\n\n\n\nDesvantagens\n- Explos√£o combinat√≥ria do n√∫mero de candidatos\n- Alto custo na verifica√ß√£o dos subgrafos\n\n\n\n- Extremamente ineficiente em grandes grafos\n- Ineficiente em grandes grafos\n\n\n\n- Consome grande quantidade de recursos como mem√≥ria"
  },
  {
    "objectID": "seminario1/artigo3.html#spminer-uma-abordagem-inovadora",
    "href": "seminario1/artigo3.html#spminer-uma-abordagem-inovadora",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "SPMiner: Uma abordagem inovadora",
    "text": "SPMiner: Uma abordagem inovadora\nCom o problema contextualizado, fica evidente a import√¢ncia da pesquisa conduzida pelos autores do artigo. A abordagem proposta por eles consiste no uso de aprendizado profundo para tornar a computa√ß√£o dos subgrafos frequentes eficiente. A ideia principal √© utilizar uma Rede Neural em Grafos (GNN) para mapear subgrafos para um espa√ßo ordenado de embeddings multidimensional de modo que a busca por subgrafos frequentes nesse espa√ßo seja mais r√°pida.\nA constru√ß√£o da rede neural foi feita justamente com esse objetivo, de modo que a arquitetura e a fun√ß√£o de perda utilizada garantam que a rela√ß√£o de ordem parcial entre subgrafos seja mantida. Em termos gerais, se um subgrafo A √© subgrafo de B, ent√£o A se encontra abaixo e √† esquerda de B no espa√ßo de embeddings citado."
  },
  {
    "objectID": "seminario1/artigo3.html#o-algoritmo-do-spminer",
    "href": "seminario1/artigo3.html#o-algoritmo-do-spminer",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "O Algoritmo do SPMiner",
    "text": "O Algoritmo do SPMiner\nIdentificar subgrafos frequentes de import√¢ncia, tamb√©m chamados de Redes Funcionais (Network Motif) √© crucial para analisar e prever propriedades de redes do mundo real. Contudo, encontrar grandes redes funcionais comuns √© um problema desafiador n√£o apenas devido √† sua sub-rotina NP Dif√≠cil de contagem de subgrafos, mas tamb√©m ao crescimento exponencial do n√∫mero de poss√≠veis padr√µes de subgrafos.\nO algoritmo SPMiner alia o poder das seguintes √°reas: redes neurais de grafos, espa√ßos latentes ordenados (order embedding space) e uma estrat√©gia de busca eficiente no espa√ßo de possibilidades. Isso possibilita a identifica√ß√£o de padr√µes de subgrafos de rede que aparecem com mais frequ√™ncia no grafo de destino.\nPara tal, de forma simplificada e ordenada, ele segue os seguintes passos:\n\nDecomp√µe o grafo de destino em subgrafos sobrepostos ancorados;\nMapeia cada subgrafo do passo anterior em um espa√ßo multidimensional latente ordenado;\nUtiliza um caminhamento monot√¥nico no espa√ßo resultante do passo anterior;\nIdentifica as Redes Funcionais frequentes.\n\nO algoritmo n√£o √© exato, por√©m o tempo de execu√ß√£o √© mais de 100 vezes menor do que os algoritmos exatos e √© preciso para subgrafos pequenos. Como limita√ß√£o ele n√£o √© capaz de retornar a frequ√™ncia dos elementos. De uma maneira geral ele representa uma inova√ß√£o na √°rea e sua estrutura b√°sica pode inspirar na busca de solu√ß√µes para outros problemas de mesma magnitude, a exemplo dos combinatoriais.\n\n\n\nDiagrama representativo do encoder e decoder do SPMiner\n\n\nAbaixo segue a descri√ß√£o detalhada de cada passo.\nA decomposi√ß√£o do grafo inicial √© baseada na defini√ß√£o de redes funcionais ancoradas. Define-se \\(G_T\\) o grafo inicial, decomposto em seus v√©rtices \\(V_T\\) e arestas \\(E_T\\) da seguinte forma \\(G_T=(V_T,E_T)\\). Analogamente, define-se \\(G_Q=(V_Q,E_Q)\\) como sendo a busca de uma rede funcional. O problema √© determinar se uma c√≥pia isom√≥rfica de \\(G_Q\\) aparece em \\(G_T\\), ou seja, se existe uma fun√ß√£o injetora entre os v√©rtices e arestas de ambos.\nA defini√ß√£o de um subgrafo ancorado √© dada da seguinte forma: Seja \\((G_Q, v)\\) um padr√£o de subgrafo ancorado no v√©rtice \\(v\\). A frequ√™ncia do motivo \\(G_Q\\) no conjunto de dados do grafo \\(G_T\\), em rela√ß√£o √† √¢ncora \\(v\\), √© o n√∫mero de v√©rtices \\(u\\), em \\(G_T\\) para o qual existe um isomorfismo de subgrafo \\(f: V_Q‚Üí V_T\\) tal que \\(f(v) = u\\).\nDefine-se a frequ√™ncia como o n√∫mero de subconjuntos exclusivos de v√©rtices \\(S ‚äÇ V_T\\) para onde existe um isomorfismo de subgrafo \\(f : V_Q ‚Üí V_T\\) cuja imagem √© \\(S\\). Comparado com estado da arte, esta medida √© mais robusta a outliers, prov√™ uma vis√£o hol√≠stica e satisfaz a propriedade de Downward Closure Property (DCP).\n\n\n\nDiferen√ßa entre a frequ√™ncia de subgrafos ancorados em n√≥s e em n√≠vel de grafo.\n\n\nNa imagem acima, encontram-se no grafo √† esquerda uma frequ√™ncia de \\(\\binom{100}{6}\\) subgrafos isom√≥rficos ao grafo da direita e uma medida ancorada de 1.\nPortanto, dado um grafo \\(G_T\\), um par√¢metro de tamanho de subgrafo \\(K\\) e o n√∫mero desejado de resultados \\(R\\), o objetivo do SPMiner √© identificar, dentre todos os poss√≠veis grafos de \\(K\\) v√©rtices, os \\(R\\) subgrafos com a maior frequ√™ncia em \\(G_T\\).\nDadas as defini√ß√µes, a decomposi√ß√£o de \\(G_T\\) √© feita extraindo os k-hop vizinhos \\(G_V\\) ancorada em cada v√©rtice \\(v\\), ou seja, os que cont√©m todos os v√©rtices que t√™m o caminho mais curto de no m√°ximo \\(k\\) para o v√©rtice \\(v\\).\nO processo de mapeamento para o espa√ßo latente ordenado √© feito por uma rede neural utilizando o n√≥ √¢ncora como uma feature categ√≥rica. O SPMiner usa essa Rede Neural de Grafo (GNN) para aprender uma fun√ß√£o de incorpora√ß√£o œÜ, que mapeia os vizinhos ancorados em n√≥s em pontos no espa√ßo latente tal que a propriedade do subgrafo √© preservada. √â importante ressaltar que o SPMiner GNN √© treinado apenas uma vez e depois pode ser aplicado a qualquer grafo de destino em qualquer dom√≠nio.\nPara caminhar no espa√ßo latente, o trabalho sugere tr√™s estrat√©gias: a heur√≠stica gulosa, a busca em feixes e o algoritmo Monte Carlo Tree Search (MTCS). Para a estrat√©gia gulosa, o trabalho apresenta a fun√ß√£o de perda que ser√° avaliada. No algoritmo de busca em feixe, concilia-se a busca em profundidade com a estrat√©gia gulosa. J√° para o algoritmo MTCS, o trabalho apresenta uma fun√ß√£o objetivo com base no crit√©rio superior de confian√ßa para √°rvores (UCT).\nDessa forma, dado o resultado da explora√ß√£o do espa√ßo, o algoritmo informa os subgrafos mais frequentes."
  },
  {
    "objectID": "seminario1/artigo3.html#metodologia-experimental",
    "href": "seminario1/artigo3.html#metodologia-experimental",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Metodologia Experimental",
    "text": "Metodologia Experimental\nO SPMiner foi comparado com outros m√©todos aproximativos e, quando vi√°vel, com m√©todos de enumera√ß√£o exata. As compara√ß√µes podem ser divididas em 3 grupos: subgrafos pequenos, subgrafos grandes plantados e subgrafos grandes reais.\nPara os subgrafos pequenos, a compara√ß√£o com m√©todos de enumera√ß√£o exata √© poss√≠vel, o que torna a compara√ß√£o de desempenho mais s√≥lida. Os subgrafos grandes plantados s√£o subgrafos gerados artificialmente. A ideia √© ter um par√¢metro mais realista do desempenho na pr√°tica. A abordagem √© vantajosa, pois combina grafos maiores, que s√£o o conjunto de interesse para a aplica√ß√£o, e permite avaliar o desempenho de forma mais objetiva. A √∫ltima abordagem, a de compara√ß√£o com grafos grandes reais, contrasta com os m√©todos aproximativos, mas √© a que melhor aproxima o uso pr√°tico. Os datasets utilizados nessa fase incluem aplica√ß√µes em diversos dom√≠nios: biologia (ENZYMES), qu√≠mica (COX2) e imagens (MSRC).\nTamb√©m foi feita uma compara√ß√£o do tempo de execu√ß√£o. Foram usados dois algoritmos como baseline: o MFInder (Kashtan et al., 2004) e o RAND-ESU (Wernicke, 2006). Os par√¢metros foram adequados para se obter um n√∫mero compar√°vel de subgrafos e tempo de execu√ß√£o."
  },
  {
    "objectID": "seminario1/artigo3.html#resultados",
    "href": "seminario1/artigo3.html#resultados",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Resultados",
    "text": "Resultados\nO SPMiner tem uma acur√°cia significativa na identifica√ß√£o de motifs nos subgrafos pequenos. O SPMiner encontra motifs de tamanho 5 e 6 em at√© 90% das vezes. A compara√ß√£o de tempo de execu√ß√£o √© dr√°stica: o m√©todo de enumera√ß√£o ESU (Wernicke, 2006) demora cerca de 10 horas, enquanto o SPMiner executa em apenas 5 minutos. Similarmente, para os subgrafos plantados, o desempenho tamb√©m foi satisfat√≥rio.\n\n\n\nCompara√ß√£o entre SPMiner e principais algoritmos aproximados de minera√ß√£o de subgrafos. Os 10 principais motifs identificados pelo SPMiner t√™m frequ√™ncia mais alta do que aqueles encontrados pelas baselines, para motifs de tamanho 5 e tamanho 6\n\n\n\n\n\nCompara√ß√£o das frequ√™ncias medianas de motifs identificados por diferentes estrat√©gias de busca e baselines.O SPMiner encontra padr√µes com uma frequ√™ncia ancorada em n√≥s mais alta do que as baselines MLP neural ou as baseadas em amostragem Rand-ESU e MFinder, nos conjuntos de dados COX2 (A), ENZYMES (B) e ENZYMES (C)\n\n\n\n\n\nFrequ√™ncia de motifs identificados por Gaston, gSpan, Motivo e SPMiner. O SPMiner √© capaz de identificar motifs de alta frequ√™ncia de grande tamanho\n\n\n\n\n\nCompara√ß√£o de tempo de execu√ß√£o entre m√©todos n√£o neurais e o SPMiner\n\n\nPara os subgrafos grandes reais, a identifica√ß√£o dos motifs foi de 10 a 100 vezes mais frequente. Al√©m disso, o SPMiner consegue identificar motifs grandes, com 10 v√©rtices ou mais, enquanto a mediana dos baselines √© 3. Uma das vantagens do SPMiner √© o pr√©-treinamento, que √© executado apenas uma vez e √© generaliz√°vel para qualquer grafo. Isso reduz drasticamente o tempo de execu√ß√£o, em particular se comparado aos m√©todos exatos.\nApesar das vantagens, o algoritmo tamb√©m possui suas limita√ß√µes. O treino com grafos aleat√≥rios pode limitar sua aplicabilidade em an√°lise de bancos de dados reais. Al√©m disso, o algoritmo retorna apenas os k motifs mais frequentes, sem considerar a ordena√ß√£o."
  },
  {
    "objectID": "seminario1/artigo3.html#aplica√ß√µes-e-desafios",
    "href": "seminario1/artigo3.html#aplica√ß√µes-e-desafios",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Aplica√ß√µes e Desafios",
    "text": "Aplica√ß√µes e Desafios\nO uso de algoritmos de recupera√ß√£o de informa√ß√£o relacionados a subgrafos √© amplamente difundido no meio industrial, acad√™mico e social, tais como: 1. no meio industrial, destacam-se a ind√∫stria qu√≠mica e farmac√™utica na produ√ß√£o de elementos qu√≠micos espec√≠ficos e f√°rmacos; 2. na engenharia de software, destaca-se a sua utiliza√ß√£o no desenvolvimento de fluxos de controle de aplica√ß√µes; 3. no com√©rcio eletr√¥nico, t√™m-se os sistemas de recomenda√ß√£o; 4. no setor banc√°rio, atua na detec√ß√£o de fraudes, 5. na cadeia de suprimentos, detecta rotas e identifica padr√µes log√≠sticos; 6. no meio acad√™mico, a √°rea da bioinform√°tica destaca-se em quest√µes ligadas a redes de prote√≠nas e conjuntos de prote√≠nas; 7. na ci√™ncia ambiental, auxilia na identifica√ß√£o de habitats cr√≠ticos para a conserva√ß√£o; 8. no meio social, destaca-se detec√ß√£o de rotas frequentes para planejamento urbano, novos neg√≥cios e defini√ß√£o de rotas de fuga.\nO algoritmo tamb√©m possui tais desvantagens: 1. pela an√°lise de redes sociais √© poss√≠vel propagar informa√ß√µes maliciosas, perda de privacidade e perda da autonomia individual; 2. na √°rea comercial √© poss√≠vel induzir o consumo desnecess√°rio.\nDentre os usos espec√≠ficos do algoritmo, incluem-se artigos de aplica√ß√£o para a detec√ß√£o de rumores ou not√≠cias falsas em redes sociais (Detecting rumours with latency guarantees using massive streaming data). E um novo algoritmo chamado Multi-SPMiner j√° foi proposto (Multi-SPMiner: A Deep Learning Framework for Multi-Graph Frequent Pattern Mining with Application to spatiotemporal Graphs)."
  },
  {
    "objectID": "seminario1/artigo3.html#como-usar-o-spminer",
    "href": "seminario1/artigo3.html#como-usar-o-spminer",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Como Usar o SPMiner",
    "text": "Como Usar o SPMiner\nJure Leskovec, professor da Universidade Stanford e um dos autores do artigo que apresenta o SPMiner, comanda um projeto denominado Stanford Network Analysis Platform (SNAP). O projeto consiste no desenvolvimento e manuten√ß√£o de um sistema de c√≥digo aberto para a an√°lise de redes complexas. Um dos m√≥dulos do SNAP, √© o Neural Subgraph Learning (NSL), que consiste em uma biblioteca com v√°rias rotinas dedicadas ao aprendizado de rela√ß√µes de subgrafos, e um dos algoritmos implementados √© o SPMiner.\nA fim de solucionar problemas de compatibilidade de bibliotecas, conflitos de instala√ß√£o e facilitar a execu√ß√£o em ambientes diferentes, foram feitas modifica√ß√µes na implementa√ß√£o disponibilizada pelo SNAP e gerado um arquivo para a cria√ß√£o de um ambiente Docker. O reposit√≥rio completo, que inclui um pequeno tutorial para a execu√ß√£o do SPMiner via Docker, pode ser acessado neste link.\nAl√©m da implementa√ß√£o do SPMiner, os desenvolvedores do projeto SNAP tamb√©m disponibilizaram datasets que podem ser utilizados para testar o funcionamento do algoritmo, al√©m de scripts para diferentes an√°lises dos resultados. Experimentos locais utilizando o dataset COX2, executando o SPMiner, sem GPU, obtiveram tempo de execu√ß√£o pr√≥ximo de 40 minutos.\n\n\n\nSubgrafos frequentes de tamanho 5, 12 e 20, respectivamente, resultantes da minera√ß√£o de padr√µes no dataset COX2, composto por 467 grafos. A minera√ß√£o foi realizada utilizando a estrat√©gia de pesquisa Greedy, com padr√µes identificados tendo tamanho m√≠nimo de 5 e m√°ximo de 20. O processo de minera√ß√£o levou 40 minutos e 17 segundos\n\n\n\nDados de entrada\nH√° alguns datasets no reposit√≥rio, mas para uma aplica√ß√£o real, o usu√°rio pode alterar o arquivo de entrada, bem como outros par√¢metros: tamanho m√≠nimo e/ou m√°ximo dos subgrafos frequentes, estrat√©gia de pesquisa, dentre outros.\nOs dados de entrada est√£o no formato txt:\n\nA representa√ß√£o de cada grafo √© inicializada por uma linha do tipo:\nt # {id do grafo}\nEm seguida, n linhas, cada uma representa um v√©rtice:\nv {id do v√©rtice} {r√≥tulo do v√©rtice}\nE por fim, m arestas, novamente, uma por linha:\ne {id do v√©rtice de origem} {id do v√©rtice de destino} {r√≥tulo da aresta}\n\nContudo, o c√≥digo aceita outras estrutura√ß√µes dos grafos (por exemplo, os dados do TUDataset tem um .txt com uma lista de adjac√™ncia, entre outros adicionais).‚Äã"
  },
  {
    "objectID": "seminario1/artigo3.html#conclus√£o",
    "href": "seminario1/artigo3.html#conclus√£o",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Conclus√£o",
    "text": "Conclus√£o\nO SPMiner representa um avan√ßo significativo para a minera√ß√£o de subgrafos frequentes, oferecendo uma abordagem inovadora e eficiente para a identifica√ß√£o de padr√µes em dados complexos. Com seu potencial de aplica√ß√£o em uma variedade de dom√≠nios, o SPMiner promete abrir novas oportunidades de pesquisa e inova√ß√£o. Ao aproveitar o poder do aprendizado profundo, o SPMiner por auxiliar na revela√ß√£o de padr√µes ocultos e oferecer insights valiosos."
  },
  {
    "objectID": "seminario1/artigo3.html#refer√™ncias",
    "href": "seminario1/artigo3.html#refer√™ncias",
    "title": "Artigo 3: Representation Learning for Frequent Subgraph Mining",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\n\nYing, R., Fu, T., Wang, A., You, J., Wang, Y., & Leskovec, J. (2024). Representation Learning for Frequent Subgraph Mining. arXiv preprint arXiv:2402.14367. https://doi.org/10.48550/arXiv.2402.14367‚Äã\nSIMPLEDATAMINING. Graph Pattern Mining (gSpan) - Introduction. Dispon√≠vel em: https://simpledatamining.blogspot.com/2015/03/graph-pattern-mining-gspan-introduction.html. Acesso em: 19 abr. 2024.‚Äã\nJ, Vamsi. GRAPH MINING. Dispon√≠vel em: https://www.youtube.com/watch?v=KoG5lEAJmgI&t=1694s. Acesso em: 18 abr. 2024.‚Äã\nRex Ying et al.¬†Frequent Subgraph Mining by Walking in Order Embedding Space. In: INTERNATIONAL CONFERENCE ON MACHINE LEARNING, 37., 2020, Virtual. Workshop details. Dispon√≠vel em: https://icml.cc/virtual/2020/7061. Acesso em: 22 abr. 2024.‚Äã\nFrequent Subgraph Mining by Walking in Order Embedding Space. R. Ying, A. Wang, J. You, J. Leskovec, 2020. Dispon√≠vel em:https://snap.stanford.edu/frequent-subgraph-mining/‚Äã\nNguyen, T.T., Huynh, T.T., Yin, H. et al.¬†Detecting rumours with latency guarantees using massive streaming data. The VLDB Journal 32, 369‚Äì387 (2023). https://doi.org/10.1007/s00778-022-00750-4‚Äã\nZEGHINA, Assaad et al.¬†Multi-SPMiner: A Deep Learning Framework for Multi-Graph Frequent Pattern Mining with Application to spatiotemporal Graphs. Procedia Computer Science, v. 225, p.¬†1094-1103, 2023. ISSN 1877-0509. Dispon√≠vel em: https://doi.org/10.1016/j.procs.2023.10.097. Acesso em: 22 abr. 2024."
  },
  {
    "objectID": "seminario1.html",
    "href": "seminario1.html",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Os semin√°rios da disciplina consistem em uma apresenta√ß√£o coletiva (da turma) de um artigo mais recente sobre t√≥picos diretamente relacionados ao conte√∫do visto em sala. A ideia √© que a turma como um todo estude os artigos mais recentes da √°rea e discuta esses trabalhos em sala. Em cada sess√£o, discutimos tr√™s artigos recentes relacionados aos t√≥picos abordados nas aulas te√≥ricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canad√°) ‚Äì veja a proposta original em https://colinraffel.com/blog/role-playing-seminar.html. A proposta consiste em fazer uma encena√ß√£o de pap√©is (role play) cient√≠ficos para a apresenta√ß√£o do semin√°rio. Nessa proposta, cada grupo cumprir√° um papel na apresenta√ß√£o. Ao final, uma apresenta√ß√£o em formato de slides e um documento textual s√£o produzidos. A apresenta√ß√£o √© usada em sala de aula para fomentar as discuss√µes, enquanto o documento fornece uma descri√ß√£o textual das impress√µes da turma com a inten√ß√£o de descrever o tema do artigo para um p√∫blico amplo interessado em aprendizado de m√°quina e minera√ß√£o de dados.\nS√£o apresentados a seguir os artigos discutidos no semestre 2024/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\nA Survey of High Utility Itemset Mining\nby Fournier-Viger, Philippe, Jerry Chun-Wei Lin, Tin Truong-Chi, and Roger Nkambou. 2019\nhttps://doi.org/10.1007/978-3-030-04921-8_1\n\n\n\nFinding Local Groupings of Time Series\nby Lee, Zed, Marco Trincavelli, and Panagiotis Papapetrou. 2023\nhttps://doi.org/10.1007/978-3-031-26422-1_5\n\n\n\nRepresentation Learning for Frequent Subgraph Mining\nby Ying, Rex, Tianyu Fu, Andrew Wang, Jiaxuan You, Yu Wang, and Jure Leskovec. 2024\nhttps://arxiv.org/abs/2402.14367"
  },
  {
    "objectID": "seminario1.html#artigo-1",
    "href": "seminario1.html#artigo-1",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "A Survey of High Utility Itemset Mining\nby Fournier-Viger, Philippe, Jerry Chun-Wei Lin, Tin Truong-Chi, and Roger Nkambou. 2019\nhttps://doi.org/10.1007/978-3-030-04921-8_1"
  },
  {
    "objectID": "seminario1.html#artigo-2",
    "href": "seminario1.html#artigo-2",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Finding Local Groupings of Time Series\nby Lee, Zed, Marco Trincavelli, and Panagiotis Papapetrou. 2023\nhttps://doi.org/10.1007/978-3-031-26422-1_5"
  },
  {
    "objectID": "seminario1.html#artigo-3",
    "href": "seminario1.html#artigo-3",
    "title": "Introdu√ß√£o",
    "section": "",
    "text": "Representation Learning for Frequent Subgraph Mining\nby Ying, Rex, Tianyu Fu, Andrew Wang, Jiaxuan You, Yu Wang, and Jure Leskovec. 2024\nhttps://arxiv.org/abs/2402.14367"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizado Descritivo",
    "section": "",
    "text": "Aprendizado Descritivo ‚Äî DCC/UFMG   Prof.¬†Renato Vimieiro \n\nEssa disciplina √© ofertada no Programa de P√≥s-Gradua√ß√£o em Ci√™ncia da Computa√ß√£o da Universidade Federal de Minas Gerais. Ela tem como objetivo apresentar t√©cnicas avan√ßadas para identifica√ß√£o de padr√µes descritivos em bases de dados. A(o) aluna(o) ter√° contato com t√©cnicas para aprendizado de padr√µes n√£o-supervisionados e supervisionados. Ser√£o discutidas as dificuldades computacionais da busca por tais padr√µes, bem como sua utilidade para an√°lise explorat√≥ria de dados.\nOs t√≥picos abordados na disciplina s√£o:\n\nDiferen√ßas entre aprendizado descritivo e preditivo.\nAprendizado descritivo n√£o-supervisionado.\nAprendizado descritivo supervisionado.\nRepresenta√ß√µes condensadas.\nM√©tricas de qualidade de padr√µes descritivos.\nAlgoritmos de aprendizado de padr√µes descritivos supervisionados e n√£o-supervisionados.\nEstudos de casos e aplica√ß√µes em problemas reais.\n\nOs t√≥picos s√£o apresentados atrav√©s de aulas expositivas sobre o assunto, leitura e apresenta√ß√£o de semin√°rios sobre artigos recentes na literatura, e projetos de aplica√ß√£o dos m√©todos estudados para extra√ß√£o de conhecimento de bases de dados.\nUtilize o menu acima ou o link a seguir para visualizar o conte√∫do produzido nos semin√°rios e projetos desenvolvidos pelos alunos.\n\nSemin√°rios: Padr√µes frequentes; Descoberta de subgrupos; Aplica√ß√µes"
  },
  {
    "objectID": "seminario1/artigo1.html",
    "href": "seminario1/artigo1.html",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "",
    "text": "No campo da minera√ß√£o e an√°lise de dados, a minera√ß√£o de padr√µes frequentes possui uma relev√¢ncia bastante significativa, sendo importante para encontrar associa√ß√µes e correla√ß√µes entre diferentes vari√°veis. Essa √°rea de estudo surgiu juntamente com o crescimento exponencial da quantidade de dados dispon√≠veis em diversos setores da vida cotidiana, em especial o com√©rcio, tendo sido batizada com o nome de ‚ÄúAnalise da cesta de compras‚Äù.\nPara dar seguimento a este artigo, √© necess√°rio definir (ou relembrar) alguns conceitos:\nA an√°lise final dos padr√µes identificados como frequentes atrav√©s da minera√ß√£o executada pode muitas vezes ser complicada, por se tratar de uma t√©cnica de aprendizado n√£o supervisionado. Mas al√©m da complexidade inata da an√°lise de resultados, existe tamb√©m a possibilidade dos padr√µes obtidos n√£o significarem nada, ou simplesmente serem pouco √∫teis para os objetivos do neg√≥cio.\nPor exemplo, considere que na an√°lise de uma papelaria os itens ‚Äúl√°pis‚Äù e ‚Äúborracha‚Äù s√£o frequentemente inclu√≠dos em uma mesma transa√ß√£o, o pre√ßo final pago pelo consumidor por apenas esse conjunto de itens ser√° muito baixo, n√£o trazendo os benef√≠cios esperados da an√°lise. Por√©m, na mesma papelaria, pode ser que os itens impressora e cartucho de tinta tamb√©m s√£o frequentemente comprados juntos, o que leva a um pre√ßo final maior pago pelo consumidor.\nO exemplo anterior √© b√°sico, mas ilustra a ideia de que os itens serem apenas frequentes pode n√£o ser o suficiente, sendo necess√°rio que as combina√ß√µes analisadas sejam tamb√©m √∫teis para o analista. √â nesse contexto que surge a minera√ß√£o de padr√µes frequentes de alta utilidade, tratada no artigo ‚ÄúA Survey of High Utility Itemset Mining‚Äù, que aborda diferentes algoritmos para resolver esse problema.\nPara entender esses algoritmos, √© primeiro necess√°rio fazer uma segunda leva de defini√ß√µes sobre o assunto, dessa vez mais espec√≠ficas ao escopo de minera√ß√£o de padr√µes de alta utilidade:\nPerceba que, de acordo com essas defini√ß√µes, todos os algoritmos que s√£o utilizados para minera√ß√£o de padr√µes frequentes de alta utilidade podem tamb√©m ser utilizados para minerar padr√µes frequentes, basta que a utilidade interna e externa de todos os itens seja definida com o mesmo valor, preferencialmente ‚Äú1‚Äù. Para entender melhor as semelhan√ßas e diferen√ßas entre as duas t√©cnicas de minera√ß√£o de dados, verifique a tabela a seguir:"
  },
  {
    "objectID": "seminario1/artigo1.html#t√©cnicas-e-algoritmos-usados",
    "href": "seminario1/artigo1.html#t√©cnicas-e-algoritmos-usados",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "T√©cnicas e Algoritmos usados",
    "text": "T√©cnicas e Algoritmos usados\nO artigo estudado tem por objetivo apresentar a √°rea de minera√ß√£o de padr√µes frequentes de alta utilidade, al√©m de mostrar ao leitor diferentes algoritmos para realizar essa minera√ß√£o. As principais t√©cnicas para a confec√ß√£o dos algoritmos s√£o a de ‚ÄúDuas fases‚Äù e de ‚ÄúUma fase‚Äù, essas t√©cnicas ser√£o explicadas nas pr√≥ximas subse√ß√µes, juntamente com um algoritmo representante de cada classe.\n\nAlgoritmos de duas fases\nAlgoritmos que seguem essa t√©cnica usam o conceito de ‚ÄúUtilidade da transa√ß√£o‚Äù, ou Transaction Utility (TU), que pode ser definido como a soma da utilidade de todos os itens que est√£o presentes em uma transa√ß√£o, para definir limites superiores do qu√£o alta a utilidade de um subconjunto dessa transa√ß√£o pode ser. Esse limite superior √© calculado para cada um dos padr√µes (itemsets) candidatos atrav√©s de uma ‚ÄúUtilidade com peso em transa√ß√µes‚Äù, ou Transaction Weighted Utility (TWU), que √© definida como a soma da utilidade de todas as transa√ß√µes que cont√™m o padr√£o em evid√™ncia.\nO valor obtido de TWU para um itemset, √© o limite superior para todos os superconjuntos que possam ser formados a partir dele. Por exemplo, suponha a exist√™ncia de um itemset base {a, b} que possui TWU igual a 10, isso significa que qualquer itemset da forma {a, b, _}, onde o terceiro e √∫ltimo item pode ser qualquer um do universo de itens dispon√≠vei, ter√° necessariamente uma utilidade menor que 10. A aplica√ß√£o dessa propriedade nos algoritmos traz um importante avan√ßo, que √© o estabelecimento de um decrescimento monot√¥nico do TWU de acordo com o aumento dos itens em um itemset.\nA partir dessas propriedades, √© definido um suporte de utilidade m√≠nimo que elimina todos os itemsets que tenham TWU abaixo desse limiar assim que s√£o identificados, evitando a gera√ß√£o de superconjuntos que n√£o t√™m chances de serem de alta utilidade.\n\n\n\nExemplo de c√°lculo do TWU.\n\n\nA primeira fase dos algoritmos consiste em gerar o TWU de todos os itens dispon√≠veis, j√° que eles s√£o o menor itemset poss√≠vel (excluindo o conjunto vazio). Ap√≥s o c√°lculo, todos os itemsets unit√°rios que tenham um TWU que estejam abaixo do suporte de utilidade m√≠nimo definido s√£o eliminados do espa√ßo de busca, evitando que candidatos infrut√≠feros sejam gerados. Em seguida, a gera√ß√£o de candidatos continua para os itemsets de dois elementos gerados a partir dos remanescentes do filtro anterior, sendo que esses novos candidatos ser√£o tamb√©m removidos no caso de terem TWU menor que o suporte m√≠nimo. Essa sequ√™ncia de a√ß√µes continua em repeti√ß√£o at√© que j√° n√£o seja mais poss√≠vel gerar novos candidatos.\n\nNote que nessa primeira fase est√° sendo calculado o TWU, que √© o limite superior de utilidade, e n√£o a utilidade dos itemsets em si\n\nA segunda fase do algoritmo consiste em calcular a utilidade de todos os candidatos que sobraram da fase anterior, eliminando aqueles que tenham utilidade menor que o limite inferior estabelecido.\nO primeiro algoritmo desenvolvido para essa t√©cnica se chama Two-Phase Algorithm, tendo sido baseado no algoritmo Apriori para minera√ß√£o de padr√µes frequentes. √â poss√≠vel ver uma imagem do pseudoc√≥digo desse algoritmo a seguir:\n\n\n\nPseudoc√≥digo do algoritmo Two-Phase.\n\n\nPerceba que a fun√ß√£o ITEMSETGENERATION() recebe apenas o conjunto de candidatos da itera√ß√£o anterior como par√¢metro, n√£o verificando a base de dados de transa√ß√£o para gerar os candidatos, o que pode levar a itemsets que n√£o ocorrem em nenhuma transa√ß√£o, resultando em um desperd√≠cio de tempo consider√°vel para os c√°lculos deles.\nOutra limita√ß√£o do algoritmo √© que ele itera pelo conjunto de dados v√°rias vezes para calcular o TWU dos itemsets, elevando o custo do algoritmo. Note que a explora√ß√£o do espa√ßo de busca desse algoritmo segue a t√©cnica de Breadth First Search (BFS), o que leva a uma maior demora para elimina√ß√£o de candidatos infrut√≠feros, principalmente pelo fato de que o TWU √© uma m√©trica de limite extrapolada.\n\n\nAlgoritmos de uma fase\nEsses algoritmos s√£o mais diretos, fazendo o c√°lculo da utilidade de cada padr√£o considerado no espa√ßo de busca, o que permite identificar imediatamente se um itemset √© de alta ou baixa utilidade sem a necessidade de guard√°-lo em mem√≥ria principal (RAM).\nOutra novidade desses algoritmos √© que eles trazem uma nova forma de calcular os limites superiores de utilidade, sendo mais pr√≥xima √† utilidade real dos itemsets do que o TWU usado nos algoritmos de duas fases. Como exemplo de algoritmo dessa t√©cnica, ser√° utilizado o Fast High-Utility Miner (FHM), que introduz o conceito de Listas de Utilidade, ou Utility List (UL), para representar o banco de dados das transa√ß√µes.\nConsiderando um itemset X, a lista de utilidade UL(X) ser√° uma lista de tuplas para todas as ocorr√™ncias de X nas transa√ß√µes do banco, sendo que cada tupla armazenar√° o ID da transa√ß√£o em que o itemset est√° presente, a utilidade do itemset naquela transa√ß√£o e a soma da utilidade de todos os itens com ordem lexicogr√°fica superior aos itens de X. O algoritmo se inicia calculando as listas de utilidade de todos os itemsets de um √∫nico elemento, sendo que as listas de utilidades dos superconjuntos desses itemsets ser√° calculada a partir dos componentes delas.\nPor exemplo, suponha as listas de utilidade dos conjuntos unit√°rios UL({a}) e UL({d}), para gerar a lista de utilidade e calcular a utilidade do itemset {a, d}, ser√° calculada a interse√ß√£o das transa√ß√µes que est√£o em UL({a}) e UL({d}). A utilidade do novo itemset ser√° simplesmente a soma das utilidades dos itemsets geradores, enquanto a utilidade dos itens com ordem lexicogr√°fica superior ser√° igual a presente no itemset gerador de maior ordem lexicogr√°fica, no caso do exemplo, ser√° o mesmo de {b}.\n\n\n\nExemplo de c√°lculo das listas de utilidade.\n\n\nO c√°lculo do limite superior para esse algoritmo √© chamado de ‚ÄúLimite Superior por Utilidade Residual‚Äù, ou Remaining Utility Upper-Bound, √© feito somando a utilidade de um item (iutil) com a utilidade dos itens residuais de ordem lexicogr√°fica maior (rutil) para todas as transa√ß√µes presentes na lista de utilidade. Caso esse resultado final seja menor que a utilidade m√≠nima definida, aquele itemset √© eliminado do espa√ßo de busca, evitando que novos candidatos sejam gerados. A figura a seguir mostra o pseudoc√≥digo para o algoritmo FHM:\n\n\n\nPseudoc√≥digo do algoritmo FHM.\n\n\nAlgoritmos baseados em listas de utilidade, como o FHM, s√£o at√© duas ordens de magnitude mais r√°pidos que os algoritmos de duas fases. Por√©m, a gera√ß√£o de candidatos ainda √© baseada em itemsets anteriores, sem verificar o banco de dados de transa√ß√µes, o que pode levar a candidatos inexistentes e aumento no custo total do algoritmo por gastar recursos verificando possibilidades desnecess√°rias.\nAl√©m disso, o custo de mem√≥ria para o armazenamento das listas de utilidade de cada itemset verificado pode vir a ser preocupante. Outro ponto de aten√ß√£o de algoritmos que seguem essa estrat√©gia √© o fato de que s√£o feitas muitas compara√ß√µes com listas de utilidade anteriores no processo de gera√ß√£o de candidatos, j√° que um candidato com k itens dever√° fazer compara√ß√µes com k-1 listas de utilidade anteriores."
  },
  {
    "objectID": "seminario1/artigo1.html#metodologia-do-artigo",
    "href": "seminario1/artigo1.html#metodologia-do-artigo",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Metodologia do artigo",
    "text": "Metodologia do artigo\nO artigo adota uma abordagem metodol√≥gica baseada em Survey, delineando inicialmente o problema em quest√£o e, em seguida, apresentando algoritmos destinados √† sua resolu√ß√£o. Uma filtragem criteriosa de artigos relevantes no dom√≠nio da minera√ß√£o de itemsets de alta utilidade foi realizada, seguida pela compila√ß√£o e s√≠ntese dos algoritmos destacados, abordando suas estruturas e conceitos fundamentais.\nOs primeiros algoritmos abrangentes para identificar conjuntos de itens de alta utilidade operam em duas fases distintas: primeiro, geram-se candidatos que s√£o subsequentemente avaliados quanto √† sua utilidade efetiva. Esses algoritmos introduziram uma inova√ß√£o crucial ao estabelecer uma medida mon√≥tona que serviria como limite superior para a utilidade dos conjuntos de itens. Uma dessas medidas pioneiras foi a TWU (Transaction-Weighted Utilization), a qual permitiu uma poda eficiente do espa√ßo de busca. Em est√°gios posteriores, surgiram algoritmos de uma √∫nica fase, cujo prop√≥sito √© economizar tempo ao integrar a gera√ß√£o e avalia√ß√£o de candidatos em um √∫nico passo. Vale ressaltar que muitos desses algoritmos propostos representam generaliza√ß√µes de t√©cnicas de minera√ß√£o de conjuntos de itens frequentes estabelecidas, como o Two Phase (uma extens√£o do Apriori) e o UP-Growth (uma extens√£o do FP-Growth).\nDentre os algoritmos apresentados para a minera√ß√£o de padr√µes frequentes de alta utilidade s√£o destacados os seguintes:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTipo de Busca\nFases\nRepresenta√ß√£o dos Dados\nExtende\n\n\n\n\nTwo-Phase\nBusca em Largura\nDuas\nHorizontal\nApriori\n\n\nHUP-Growth\nBusca em Profundidade\nDuas\nHorizontal (√Årvore de Prefixos)\nFP-Growth\n\n\nD2HUP\nBusca em Profundidade\nUma\nVertical (Hiperestrutura)\nH-Mine\n\n\nFHM\nBusca em Profundidade\nUma\nVertical (Listas de Utilidade)\nEclat\n\n\nEFIM\nBusca em Profundidade\nUma\nVertical (com fus√µes)\nLCM\n\n\n\nO artigo por√©m n√£o se cont√©m somente em discutir os algoritmos completos de minera√ß√£o de padr√µes, mas tamb√©m, reconhecendo a import√¢ncia de representa√ß√µes com um n√≠vel maior de significado. √â nesse ponto em que s√£o apresentados os algoritmos que mineram representa√ß√µes concisas dos subconjuntos de alta utilidade:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nPadr√µes\nFases\nRepresenta√ß√£o dos Dados\nExtende\n\n\n\n\nMinFHM\nMinUIs\nUma\nVertical (Listas de Utilidade)\nFHM\n\n\nCHUD\nCHUIs\nDuas\nVertical (Listas de Utilidade)\nDCI Closed\n\n\nEFIM-CLOSED‚Äã\nCHUIs\nUma\nHorizontal (com fus√µes)\nEFM\n\n\nGUIDE\nMHUIs One\nUma\nStream\nUpGrowth\n\n\n\nPor fim, s√£o apresentados algoritmos que retornam apenas os K subconjuntos de alta utilidade mais frequentes no conjunto de transa√ß√µes:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTipo de Busca\nFases\nRepresenta√ß√£o dos Dados\nExtende\n\n\n\n\nTKU‚Äã\nBusca em Profundidade‚Äã\nDuas\nHorizontal (√Årvore de Prefixos)\n‚Äã UP-Growth‚Äã\n\n\nTKO‚Äã\nBusca em Profundidade‚Äã\nUma\nVertical (Listas de Utilidade)\nHUI-Miner‚Äã\n\n\nREPT‚Äã\nBusca em Profundidade‚Äã\nUma\nHorizontal (√Årvore de Prefixos)‚Äã\nMU-Growth‚Äã\n\n\nkHMC‚Äã\nBusca em Profundidade‚Äã\nUma\nVertical (Listas de Utilidade)‚Äã\nFHM‚Äã"
  },
  {
    "objectID": "seminario1/artigo1.html#aplica√ß√µes-e-desafios-√©ticos-e-sociais",
    "href": "seminario1/artigo1.html#aplica√ß√µes-e-desafios-√©ticos-e-sociais",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Aplica√ß√µes e Desafios √âticos e Sociais",
    "text": "Aplica√ß√µes e Desafios √âticos e Sociais\nH√° uma vasta gama de problemas do mundo real que podem se beneficiar significativamente do uso de algoritmos de minera√ß√£o de subconjuntos frequentes de alta utilidade. Entre eles:\n\nMercado de Varejo: Potencial para aumentar os lucros ao impulsionar as vendas de produtos mais rent√°veis.\nMercado de Compra Conjunta: Oportunidade de melhorar a lucratividade ao associar produtos visando redu√ß√£o de impostos.\nSistema de Recomenda√ß√£o: Aprimoramento da capacidade de gerar lucro ao focar em produtos mais rent√°veis.\nCross-Selling e Up-Selling: Est√≠mulo para compras de produtos complementares e promo√ß√£o de vendas casadas.\nTratamento de Sa√∫de: Desenvolvimento de conjuntos de tratamentos visando maior efici√™ncia.\nDetec√ß√£o de Fraudes: Identifica√ß√£o de padr√µes pouco frequentes, por√©m altamente √∫teis, na detec√ß√£o de fraudes. Uso da Internet:__ An√°lise do comportamento dos usu√°rios para aprimorar a import√¢ncia do site.\nTelecomunica√ß√µes: Utiliza√ß√£o na identifica√ß√£o de padr√µes de comunica√ß√£o que resultam em maior lucratividade.\nMinera√ß√£o de Texto: Identifica√ß√£o de textos com elevado valor agregado.\n\nNo entanto, a implementa√ß√£o de algoritmos de minera√ß√£o de alta utilidade suscita preocupa√ß√µes sociais e √©ticas que demandam uma aten√ß√£o cuidadosa. Um ponto crucial √© a amea√ßa √† privacidade, uma vez que a identifica√ß√£o de indiv√≠duos a partir de dados aparentemente an√¥nimos pode comprometer a seguran√ßa dos mesmos. Ademais, h√° o risco de manipula√ß√£o do mercado e do comportamento do consumidor, onde o conhecimento de padr√µes de consumo pode ser utilizado de maneira indevida para influenciar escolhas.\nOutra quest√£o relevante √© a elis√£o fiscal, na qual empresas utilizam o conhecimento de padr√µes de alta utilidade para minimizar suas obriga√ß√µes fiscais de forma legal, mas question√°vel do ponto de vista √©tico. Esses desafios destacam a import√¢ncia de regulamenta√ß√µes s√≥lidas e transpar√™ncia no uso de algoritmos de minera√ß√£o de dados, garantindo que o impacto social e √©tico seja considerado em todas as etapas, desde a implementa√ß√£o at√© a opera√ß√£o dessas ferramentas avan√ßadas."
  },
  {
    "objectID": "seminario1/artigo1.html#como-usar",
    "href": "seminario1/artigo1.html#como-usar",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Como usar",
    "text": "Como usar\nNeste guia iremos ensinar o passo a passo para poder executar o SPMF, um software livre que tem implementado v√°rios algoritmos de minera√ß√£o de itemsets de alta qualidade.\nA execu√ß√£o do SPMF exige o JAVA vers√£o m√≠nima 1.8, aqui iremos mostrar a instala√ß√£o tanto do JAVA quanto do SPMF para o Windows, o processo de instala√ß√£o do programa deve ser o mesmo no Linux, j√° que o programa √© baseado em JAVA, a diferen√ßa se dar√° na instala√ß√£o do JAVA.\n\nInstala√ß√£o\nInicialmente segui o guia de instala√ß√£o do JAVA deste link, mas na hora de execu√ß√£o do SPMF o programa n√£o funcionou e a solu√ß√£o foi reinstalar o JAVA de outra forma. Apenas a fim de documentar um poss√≠vel erro que voc√™ encontre ao tentar executar o SPMF, fica aqui o v√≠deo do processo de instala√ß√£o que n√£o funcionou.\n\n\n\n\n\nInstala√ß√£o da vers√£o errada do JAVA\n\n\nA instala√ß√£o do SPMF √© simples e se encontra neste link. O v√≠deo a seguir mostra o processo inteiro:\n\n\n\n\n\nInstala√ß√£o do software SPMF\n\n\nComo dito anteriormente, no final obtemos um erro do JAVA que √© concertado pela re-instala√ß√£o de uma vers√£o atual neste link, tal processo √© mostrado no v√≠deo a seguir:\n\n\n\n\n\nInstala√ß√£o da vers√£o mais recente do JAVA\n\n\n\n\nExecu√ß√£o\n\nArquivo de Entrada\nO SPMF suporta arquivos de entrada no formato .txt.\nA primeira parte do arquivo de entrada √© opcional e √© usada para nomear os itens presentes no banco de dados.\n\nLinhas come√ßando com @‚Äã.\nPrimeira linha com ‚Äú@CONVERTED_FROM_TEXT‚Äù‚Äã\nDemais linhas fazem a liga√ß√£o do item com sua descri√ß√£o no formato @ITEM={ID}={DESCRICAO}\n\n{ID} √© o n√∫mero do item\n{DESCRICAO} √© o nome do item\n\n\n\n\n\nPrimira parte do arquivo de entrada (opcional)\n\n\nA segunda parte cont√©m os dados das transa√ß√µes, com cada linha representando uma transa√ß√£o e cada coluna separada por ‚Äú:‚Äù contendo o itemset, a utilidade total do itemset e a utilidade de cada item do itemset, respectivamente.\n\nLinhas representam as transa√ß√µes‚Äã\nCada linha possui 3 colunas separadas pelo caractere ‚Äò:‚Äô‚Äã\n\nColuna 1: itemset com os ids dos itens separados por espa√ßo simples.\nColuna 2: utilidade total do itemset.\nColuna 3: utilidade respectiva de cada item do itemset separadas por espa√ßo simples.‚Äã\n\n\n\n\n\nSegunda parte do arquivo de entrada\n\n\n\n\nExecu√ß√£o do Software\nV√≠deo tutorial de como se deve executar o programa a partir do dado de entrada, o algoritmo escolhido no tutorial foi o Two-Phase:\n\n\n\n\n\nApesar de no tutorial ser mostrado a execu√ß√£o com o algoritmo Two-Phase, temos v√°rias op√ß√µes de algoritmos para minera√ß√£o de itensets de alta utilidade, como UP-Growth, UP-Growth+, FHM e HUI-Miner.\n\n\nArquivo de Sa√≠da\nA sa√≠da do algoritmo tamb√©m √© um arquivo .txt, contendo os itemsets de alta utilidade encontrados, o suporte do itemset (nem todos os algoritmos geram esse valor) e a utilidade do itemset.\n\nLinhas representam itemsets de alta utilidade encontrados.‚Äã\nCada linha possui 3 se√ß√µes:‚Äã\n\nO itemset, com os ids ou nomes dos itens separados por espa√ßo simples, depende da exist√™ncia da 1¬™ parte do arquivo de entrada.‚Äã\n‚Äú#SUP: {VALOR}‚Äù onde {VALOR} √© o suporte do itemset (nem todos os algoritmos geram esse valor)‚Äã\n‚Äú#UTIL: {VALOR}‚Äù onde {VALOR} √© a utilidade do itemset.\n\n\n\n\n\nArquivo de sa√≠da"
  },
  {
    "objectID": "seminario1/artigo1.html#refer√™ncias",
    "href": "seminario1/artigo1.html#refer√™ncias",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\n\nFournier-Viger, P., Chun-Wei Lin, J., Truong-Chi, T., Nkambou, R. (2019). A Survey of High Utility Itemset Mining. In: Fournier-Viger, P., Lin, JW., Nkambou, R., Vo, B., Tseng, V. (eds) High-Utility Pattern Mining. Studies in Big Data, vol 51. Springer, Cham. https://doi.org/10.1007/978-3-030-04921-8_1\nFOURNIER-VIGER, P. et al.¬†FHM: Faster High-Utility Itemset Mining Using Estimated Utility Co-occurrence Pruning. ReserachGate, Taiwan, jul./2014. Dispon√≠vel em: https://www.researchgate.net/publication/263696687. Acesso em: 23 abr. 2024.\n\nFournier-Viger, Philippe. ‚ÄúSPMF: A Java Open-Source Pattern Mining Library.‚Äù Dispon√≠vel em: https://www.philippe-fournier-viger.com/spmf/index.php. Acesso em: 22 de Abril de 2024.\nLIU, Mengchi; QU, Junfeng. Mining High Utility Itemsets without Candidate Generation. ResearchGate, Wuhan, nov./2020. Dispon√≠vel em: https://www.researchgate.net/publication/262369808. Acesso em: 23 abr. 2024."
  },
  {
    "objectID": "seminario2/artigo5.html",
    "href": "seminario2/artigo5.html",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "",
    "text": "A descoberta de subgrupos (SD) √© um m√©todo de minera√ß√£o de dados que visa identificar padr√µes interessantes dentro de grandes conjuntos de dados, destacando segmentos espec√≠ficos que diferem de forma significativa do restante. Este m√©todo √© particularmente √∫til para explorar dados e encontrar subgrupos que apresentam comportamentos ou caracter√≠sticas not√°veis.\nNo contexto da SD, os dados num√©ricos desempenham um papel crucial. Eles podem ser usados tanto como atributos de descri√ß√£o, que ajudam a definir os subgrupos, quanto como alvos, onde se analisa o valor num√©rico em si. A forma como esses dados num√©ricos s√£o tratados pode impactar significativamente a qualidade e a utilidade dos subgrupos descobertos. Com isso, √© importante que a aplica√ß√£o de m√©todos SD sejam adaptadas para lidar com esse tipo de dado da melhor forma poss√≠vel."
  },
  {
    "objectID": "seminario2/artigo5.html#contextualiza√ß√£o-do-problema",
    "href": "seminario2/artigo5.html#contextualiza√ß√£o-do-problema",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Contextualiza√ß√£o do problema",
    "text": "Contextualiza√ß√£o do problema\nHistoricamente, o tratamento de dados num√©ricos em algoritmos de descoberta de subgrupos tem sido predominantemente est√°tico e global. Um exemplo disso √© o mergeSD (2009), que abordou o tratamento de dados num√©ricos, embora com um aumento significativo no custo computacional. No entanto, muitos algoritmos cl√°ssicos ainda n√£o tratam adequadamente os atributos num√©ricos, resultando na perda de informa√ß√µes relevantes e na diminui√ß√£o da efici√™ncia do modelo.\nPara abordar essa quest√£o, o artigo investiga qual abordagem √© mais eficaz para lidar com esses atributos, utilizando um framework que compara diferentes estrat√©gias de discretiza√ß√£o de dados num√©ricos e de busca de subgrupos. A motiva√ß√£o central dos autores √© compreender como a discretiza√ß√£o dos valores num√©ricos pode ser realizada de maneira a preservar a qualidade e a redund√¢ncia m√≠nima nos subgrupos descobertos. Assim, o artigo pode ser visto como uma revis√£o dos principais m√©todos de tratamento de atributos num√©ricos em SD."
  },
  {
    "objectID": "seminario2/artigo5.html#conceitos-importantes",
    "href": "seminario2/artigo5.html#conceitos-importantes",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Conceitos importantes",
    "text": "Conceitos importantes\nA descoberta de subgrupos lida com atributos num√©ricos por meio de condi√ß√µes nos valores, discretizando-os em intervalos para tornar o problema trat√°vel. A discretiza√ß√£o pode ser realizada de forma global, no in√≠cio do processo, com todos os pontos de corte definidos de uma vez, ou de forma local, sendo realizada dinamicamente durante a minera√ß√£o.\nOs intervalos gerados pela discretiza√ß√£o podem ser bin√°rios ou nominais. Intervalos bin√°rios referem-se a divis√µes simples em duas categorias, como ‚Äúbaixo‚Äù e ‚Äúalto‚Äù, enquanto intervalos nominais podem ter m√∫ltiplas categorias como ‚Äúbaixo‚Äù, ‚Äúm√©dio‚Äù e ‚Äúalto‚Äù. No entanto, os autores mencionam que essa simplifica√ß√£o resultante da discretiza√ß√£o pode descaracterizar os dados, pois os valores perdem certas propriedades ao serem agrupados em categorias. Por exemplo, ao comparar valores num√©ricos em um conjunto que varia de 1 a 10, os valores 7 e 8 podem ser categorizados como ‚Äúalto‚Äù, fazendo com que 7 deixe de ser menor que 8, pois ambos s√£o apenas ‚Äúalto‚Äù.\nA tabela abaixo mostra um exemplo pr√°tico de discretiza√ß√£o do atributo ‚Äúheight‚Äù (altura) de um grupo de 13 indiv√≠duos usando a estrat√©gia nominal e bin√°ria. Na estrat√©gia nominal (coluna heightn), os pontos de corte foram definidos para os intervalos a ‚â§ 170 &lt; b ‚â§ 179 &lt; c.¬†J√° na estrat√©gia bin√°ria temos duas categorias: low (coluna heightl) e low/medium (coluna heightlm) que correspondem a uma forma alternativa de discretizar os pontos de corte da estrat√©gia nominal.\n\n\n\nExemplo de estrat√©gias de discretiza√ß√£o para atributos num√©ricos\n\n\nA granularidade para discretiza√ß√£o refere-se ao n√≠vel de detalhe ou ao n√∫mero de candidatos (intervalos) em que os dados num√©ricos s√£o divididos. Granularidade fina envolve a cria√ß√£o de muitos intervalos pequenos, enquanto a granularidade grossa gera poucos intervalos maiores. Uma granularidade mais fina permite uma an√°lise mais detalhada, mas pode aumentar o custo computacional. A sele√ß√£o de candidatos pode incluir todos os poss√≠veis subgrupos (all) ou apenas um subconjunto (best), o que tamb√©m impacta o custo computacional."
  },
  {
    "objectID": "seminario2/artigo5.html#entendendo-os-algoritmos-usados",
    "href": "seminario2/artigo5.html#entendendo-os-algoritmos-usados",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Entendendo os algoritmos usados",
    "text": "Entendendo os algoritmos usados\nPara dar suporte √† investiga√ß√£o, os pesquisadores parametrizaram e executaram dois algoritmos de base: um para a descoberta de subgrupos e outro para a discretiza√ß√£o de atributos num√©ricos.\nO primeiro algoritmo, SDMM, realiza a busca de subgrupos v√°lidos em uma base de dados, utilizando uma fun√ß√£o de qualidade, restri√ß√µes e estrat√©gias de busca pr√©-estabelecidas. O algoritmo explora o dados, criando um primeiro subgrupo de busca e refinando o banco de dados a partir dele, com o objetivo de gerar novos candidatos para valida√ß√£o. Cada candidato √© analisado, uma fun√ß√£o de qualidade √© associada a ele e √© verificado se os candidatos seguem o padr√£o de qualidade estabelecido. Se sim, esses dados s√£o adicionados ao conjunto solu√ß√£o; caso contr√°rio, a busca √© reiniciada.\nO segundo algoritmo, Equal Frequency Discretisation, √© um algoritmo de discretiza√ß√£o que desenvolve intervalos de classe. No in√≠cio do processo, √© definido como os atributos num√©ricos ser√£o discretizados, estabelecendo o n√∫mero de intervalos de classes e, a partir desse n√∫mero, o algoritmo define os pontos de corte das classes para categorizar os atributos."
  },
  {
    "objectID": "seminario2/artigo5.html#estrat√©gias-de-busca",
    "href": "seminario2/artigo5.html#estrat√©gias-de-busca",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Estrat√©gias de busca",
    "text": "Estrat√©gias de busca\nPara gerar os quadros de simula√ß√µes poss√≠veis e comparar as melhores solu√ß√µes de descoberta de subgrupos, s√£o utilizados tr√™s m√©todos principais: busca em feixe tradicional, busca em feixe CBSS e busca completa.\nA busca em feixe tradicional √© uma busca em n√≠vel, que limita o n√∫mero de candidatos e a cada processamento. O m√©todo √© ajustado para buscar subgrupos de acordo com um valor predefinido, restringindo o n√∫mero de candidatos considerados em cada etapa.\nA busca em feixe em CBSS √© uma varia√ß√£o do feixe tradicional, que gera supercandidatos preliminares. Para otimizar a busca dos melhores candidatos, ele incrementa o n√∫mero de candidatos, visando aumentar a diversidade do processo.\nA busca completa realiza uma busca extensa usando todos os candidatos na busca de subgrupos. Embora isso aumente a qualidade da descoberta, h√° um custo operacional elevado e redund√¢ncia. Trabalhar com grandes bancos de dados pode ser dif√≠cil e, apesar de melhorar a qualidade, a performance pode ser prejudicada.\n\n\n\nDiagrama de etapas do processamento de dados para descoberta de subgrupos"
  },
  {
    "objectID": "seminario2/artigo5.html#metodologia",
    "href": "seminario2/artigo5.html#metodologia",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Metodologia",
    "text": "Metodologia\nNo que diz respeito √† metodologia do artigo, os autores realizaram uma s√©rie de testes, com todas as combina√ß√µes de hiperpar√¢metros e estrat√©gias poss√≠veis. Ao todo, forma avaliados 5 aspectos diferentes de SD e como cada um deles impacta os resultados, s√£o estes:\n\nHiperpar√¢metros, que se dividem em 2 tipos:\n\nN√∫mero de bins: quantidade de quebras na discretiza√ß√£o.\nProfundidade: n√∫mero de descritores.\n\nEstrat√©gias para o SD num√©rico que variam em 4 dimens√µes, havendo duas op√ß√µes para cada e, portanto, 2^4 possibilidades:\n\nMomento de discretiza√ß√£o (local ou global).\nTipo de intervalo (bin√°rio ou nominal).\nGranularidade (fina ou grossa).\nM√©todos de sele√ß√£o (‚Äúall‚Äù ou ‚Äúbest‚Äù).\n\nDatasets utilizados, que podem ser para dois tipos de problemas:\n\nDatasets de classifica√ß√£o e regras n√£o supervisionados, ex: covertype, credit-a, outros.\nDatasets de regress√£o, ex: auto-mpg, abalone, outros.\n\nEstrat√©gia de busca:\n\nComplete search: envolve a explora√ß√£o de todo o espa√ßo de busca.\nBeam search: limita o n√∫mero de candidatos a cada n√≠vel da busca.\nBeam search + CBSS: otimiza√ß√£o para tentar reduzir a redund√¢ncia dos subgrupos.\n\nM√©tricas de avalia√ß√£o:\n\nWRAcc: para classifica√ß√£o.\nz-score: para regress√£o.\nEntropia conjunta: para calcular a redund√¢ncia dos top 10 subgrupos.\n\n\nPara avaliar esses aspectos, foram realizados 17.020 experimentos, utilizando o algoritmo SDMM. Os experimentos utilizaram seis datasets de classifica√ß√£o e seis datasets de regress√£o e foram avaliados atrav√©s de WRAcc para classifica√ß√£o e |z-score| para regress√£o."
  },
  {
    "objectID": "seminario2/artigo5.html#resultados-obtidos",
    "href": "seminario2/artigo5.html#resultados-obtidos",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Resultados obtidos",
    "text": "Resultados obtidos\nAs conclus√µes sobre v√°rios aspectos obtidas com os resultados dos experimentos podem ser vistas de forma resumina no quadro a seguir:\n\n\n\n\n\n\n\nAspecto metodol√≥gico\nConclus√£o\n\n\n\n\nDiscretiza√ß√£o\nN√£o existe regra universal para o n√∫mero de bins. Estrat√©gias nominais t√™m melhor desempenho com n√∫meros de bins menores, mas estrat√©gias bin√°rias s√£o prefer√≠veis em todos os contextos e aplica√ß√µes. A discretiza√ß√£o local √© sempre melhor.\n\n\nBusca\nA escolha da heur√≠stica de busca tem pouco impacto. Beam search √© recomendada por ser eficiente e apresentar resultados bons quanto √† complete search. Em datasets pequenos, a busca completa pode ser √∫til. CBSS reduz a redund√¢ncia, mas n√£o melhora a qualidade.\n\n\nM√©tricas de Qualidade\nAs m√©tricas impactam significativamente nos subgrupos gerados, especialmente nos tamanhos, favorecendo subgrupos maiores. Avalia√ß√£o feita com a correla√ß√£o de Pearson.\n\n\nGranularidade\nA granularidade fina √© melhor, mas em grandes profundidades, granularidades fina e grossa s√£o equivalentes.\n\n\nM√©todo de Sele√ß√£o\nO m√©todo ‚Äúall‚Äù √© melhor, mas o ‚Äúbest‚Äù melhora a efici√™ncia sem grandes perdas de qualidade.\n\n\n\nNo artigo, as estrat√©gias utilizadas s√£o denotadas por siglas que combinam v√°rias letras, cada uma representando um hiperpar√¢metro espec√≠fico da metodologia aplicada. Abaixo segue uma explica√ß√£o simplificada do que cada letra nas iniciais das estrat√©gias representa:\n\nL: Refere-se ao uso de discretiza√ß√£o local.\nG: Refere-se ao uso de discretiza√ß√£o global.\nB: Indica o uso de intervalos bin√°rios.\nN: Indica o uso de intervalos nominais.\nF: Representa a abordagem de granulidade fina na discretiza√ß√£o dos dados.\nC: Representa a abordagem de granulidade grossa na discretiza√ß√£o dos dados.\nA: Refere-se √† categoria All no m√©todo de sele√ß√£o.\nB: Refere-se √† categoria Best no m√©todo de sele√ß√£o.\n\nAssim, por exemplo, uma estrat√©gia LBFA aplica discretiza√ß√£o local com intervalos bin√°rios, granularidade fina e m√©todo de sele√ß√£o ‚Äúall‚Äù.\nPor fim, os autores apresentaram uma tabela dos resultados com as melhores escolhas para as 4 dimens√µes de estrat√©gias em forma de ranking. Essa tabela se divide em duas partes, a primeira coluna que √© baseada apenas na avalia√ß√£o do melhor subgrupo gerado e a segunda leva em conta os 10 melhores subgrupos.\n\n\n\nRank final das estrat√©gias utilizadas\n\n\nDe modo geral, os melhores resultados foram obtidos pelas estrat√©gias LBFA e LBFB. Entretanto, esse ranking geral n√£o tem garantia de estat√≠stica, visto que ele foi criado a partir de uma combina√ß√£o de v√°rios testes.\nVale ressaltar que uma estrat√©gia em particular (LXFB) tamb√©m apresentou resultados bons mas se distingue das demais por usar intervalos cartesianos como t√©cnica de discretiza√ß√£o, ao inv√©s dos bin√°rios ou nominais. Devido √†s suas limita√ß√µes de aplicabilidade, ela foi testada separadamente e teve performance melhor que todas as demais, sendo a melhor estrat√©gia quando o objetivo principal √© obter subgrupos de alta qualidade para classifica√ß√£o. No entanto, ela n√£o √© aplic√°vel para regress√£o."
  },
  {
    "objectID": "seminario2/artigo5.html#aplica√ß√µes-e-desafios",
    "href": "seminario2/artigo5.html#aplica√ß√µes-e-desafios",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Aplica√ß√µes e desafios",
    "text": "Aplica√ß√µes e desafios\nA descoberta de subgrupos com atributos num√©ricos tem diversas aplica√ß√µes, como por exemplo nas √°reas da sa√∫de, educa√ß√£o e setor financeiro. No entanto, tamb√©m apresenta desafios espec√≠ficos em cada uma dessas √°reas.\nNa sa√∫de, os modelos podem ser utilizados para predi√ß√£o de riscos, identificando subgrupos de pessoas mais suscet√≠veis a doen√ßas de alto risco. Al√©m disso, s√£o √∫teis na an√°lise de resposta a tratamentos, permitindo encontrar subgrupos que reagem de forma diferenciada a determinadas terapias, e no controle de doen√ßas cr√¥nicas, identificando subgrupos que necessitam de cuidados espec√≠ficos. Outra aplica√ß√£o interessante √© o mapeamento de √°reas de risco em uma cidade, identificando regi√µes negligenciadas pelo sistema de sa√∫de, que necessitem de maior aten√ß√£o e investimento.\nNa educa√ß√£o, os modelos de descoberta de subgrupos podem ser aplicados para melhorar a performance acad√™mica, identificando subgrupos de alunos com caracter√≠sticas similares para personalizar a abordagem pedag√≥gica. Outra aplica√ß√£o potencial √© a predi√ß√£o de desist√™ncia, onde √© poss√≠vel identificar subgrupos de alunos com maiores √≠ndices de evas√£o, e assim, oferecer medidas de apoio adequadas. Adicionalmente, √© poss√≠vel identificar √°reas de risco educacional, destacando regi√µes com baixo investimento em educa√ß√£o para cria√ß√£o de novas pol√≠ticas p√∫blicas que visem melhorar a qualidade do ensino nessas √°reas.\nNo setor financeiro, os modelos podem ser utilizados para otimiza√ß√£o de portf√≥lio, identificando subgrupos de a√ß√µes que melhor se encaixam no perfil de determinados investidores. Al√©m disso, tamb√©m podem ser empregados na detec√ß√£o de fraude, identificando subgrupos de transa√ß√µes que apresentam caracter√≠sticas an√¥malas. Na an√°lise de cr√©dito, √© poss√≠vel identificar subgrupos de pessoas com maior propens√£o a cometer fraudes banc√°rias, a fim de adotar medidas preventivas.\nApesar dos benef√≠cios das diversas aplica√ß√µes, a descoberta de subgrupos com atributos num√©ricos apresenta desafios comuns nas tr√™s √°reas discutidas. A privacidade dos dados √© uma preocupa√ß√£o constante, sendo necess√°rio garantir o controle sobre onde os dados, como ser√£o utilizados e quem pode acess√°-los. A discrimina√ß√£o e a equidade de tratamento tamb√©m s√£o quest√µes importantes, uma vez que a identifica√ß√£o de subgrupos pode gerar prefer√™ncia de tratamento para determinados grupos, prejudicando outros."
  },
  {
    "objectID": "seminario2/artigo5.html#execu√ß√£o-dos-algoritmos-usados-no-artigo",
    "href": "seminario2/artigo5.html#execu√ß√£o-dos-algoritmos-usados-no-artigo",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Execu√ß√£o dos algoritmos usados no artigo",
    "text": "Execu√ß√£o dos algoritmos usados no artigo\nDois reposit√≥rios podem ser destacados para a execu√ß√£o do c√≥digo proposto para an√°lise de algoritmos de descoberta de subgrupos. O primeiro reposit√≥rio √© o da Universidade de Leiden, que disponibiliza o sistema Cortana. Esse sistema possui tanto o c√≥digo-fonte quanto o bin√°rio compilado para execu√ß√£o. A p√°gina oficial do Cortana fornece informa√ß√µes gerais sobre a ferramenta e o bin√°rio pode ser baixado diretamente da p√°gina disponibilizada. Al√©m disso, o c√≥digo-fonte est√° dispon√≠vel para desenvolvedores que desejam explorar ou modificar o sistema.\nO Cortana se destaca pela sua documenta√ß√£o extensa, encontrada no diret√≥rio /javadoc do c√≥digo-fonte. No entanto, apresenta uma limita√ß√£o significativa: a falta de um hist√≥rico de atualiza√ß√µes e uma descri√ß√£o detalhada das fun√ß√µes. Isso pode dificultar a compreens√£o completa do sistema e a rastreabilidade de mudan√ßas ao longo do tempo, o que √© crucial para desenvolvedores e pesquisadores que precisam entender a evolu√ß√£o do software.\nO segundo reposit√≥rio discutido foi o SubDisc, dispon√≠vel no GitHub e atualizado regularmente, com a √∫ltima atualiza√ß√£o registrada em 12 de outubro de 2023. O SubDisc √© escrito em Java e se foca principalmente na usabilidade e interface do usu√°rio. Uma das grandes vantagens desse reposit√≥rio √© a inclus√£o de um guia detalhado em PDF, que fornece instru√ß√µes claras sobre como utilizar a ferramenta, tornando-a acess√≠vel mesmo para aqueles que n√£o s√£o especialistas na √°rea.\nA qualidade dos reposit√≥rios varia, mas ambos t√™m suas particularidades e utilidades. O Cortana, apesar de sua documenta√ß√£o extensa, carece de detalhes hist√≥ricos e descri√ß√µes de fun√ß√µes, o que pode ser um desafio. Por outro lado, o SubDisc se sobressai com sua documenta√ß√£o voltada para o usu√°rio final e um guia de uso detalhado, embora n√£o haja men√ß√£o √† profundidade da documenta√ß√£o t√©cnica. A escolha entre essas ferramentas depender√° das necessidades espec√≠ficas dos usu√°rios, seja para um entendimento profundo do funcionamento interno ou para uma interface de usu√°rio amig√°vel.\nUm teste foi realizado utilizando a ferramenta Cortana. O dataset utilizado, tanto para regress√£o, quanto para classifica√ß√£o, foi o Adult, do reposit√≥rio de Machine Learning da UCI. Na tarefa de classifica√ß√£o, o foco foi buscar subgrupos que apresentam um comportamento diferente da popula√ß√£o em rela√ß√£o √† vari√°vel bin√°ria ‚Äúrenda anual ‚â• 50k‚Äù. Na tarefa de regress√£o, o foco est√° na idade dos indiv√≠duos, verificando se h√° subgrupos com uma distribui√ß√£o de idade at√≠pica em rela√ß√£o √† popula√ß√£o geral.\nPara instalar o Cortana, baixe o arquivo cortana1782.jar e execute-o com o comando java abaixo na linha de comando.\njava -jar cortana1782.jar\nAp√≥s iniciar o programa, selecione o arquivo de dados nos formatos arff ou csv, ajuste os par√¢metros conforme o tipo de objetivo (por exemplo, Single Numeric ou Single Nominal) e as medidas de qualidade desejadas (como Lift ou Z-Score). Verifique se os dados foram identificados corretamente e ajuste os tipos de atributos, desabilitando colunas indesejadas. Configure o m√©todo de descoberta, definindo par√¢metros como profundidade de refinamento e cobertura m√≠nima e m√°xima, e utilize a estrat√©gia de beam search com um tamanho de beam de 100. Clique no bot√£o ‚ÄúSubgroup Discovery‚Äù para iniciar o processo.\n\n\n\nInicializa√ß√£o do programa e carga de dados\n\n\nNo primeiro exemplo, para um problema de classifica√ß√£o onde se deseja identificar pessoas com renda anual ‚â• 50k, foi configurado o m√©todo como Beam Search, com largura do beam de 100, profundidade de refinamento de 2, m√©trica de qualidade Lift (‚â• 1.0) e cobertura entre 10% e 90%. Ap√≥s selecionar o arquivo adult.csv e ajustar os par√¢metros e atributos, a execu√ß√£o do algoritmo resultou em subgrupos como ‚Äúeducation-num &gt; 12.0 AND capital-gain &gt; 5000‚Äù, com uma AUC de 0.85 na curva ROC.\n\n\n\nSubgrupos resultantes classifica√ß√£o\n\n\nNo segundo exemplo do problema de regress√£o, para identificar distribui√ß√µes n√£o usuais de idade, a configura√ß√£o tamb√©m incluiu Beam Search, com largura do beam de 100, profundidade de refinamento de 2 e cobertura entre 10% e 90%. Todavia, a m√©trica de qualidade foi Z-Score (‚â• 2.0). A execu√ß√£o encontrou subgrupos como ‚Äúrelationship = husband AND hours-per-week &gt; 40‚Äù, permitindo a compara√ß√£o da distribui√ß√£o de idade com a popula√ß√£o geral.\n\n\n\nSubgrupos resultantes regress√£o"
  },
  {
    "objectID": "seminario2/artigo5.html#conclus√£o",
    "href": "seminario2/artigo5.html#conclus√£o",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Conclus√£o",
    "text": "Conclus√£o\nO trabalho cumpre um papel importate na realiza√ß√£o de experimentos capazes de confirmar algumas intui√ß√µes n√£o validadas at√© ent√£o e aprimorar o conhecimento em rela√ß√µes a estrat√©gias num√©ricas. Nesse sentido, √© um estudo bastante √∫til tanto em uma perspectiva aplicada, podendo servir como apoio na decis√£o de aspectos em aplica√ß√µes reais, quanto no contexto de pesquisas e desenvolvimento de algoritmos."
  },
  {
    "objectID": "seminario2/artigo5.html#refer√™ncias",
    "href": "seminario2/artigo5.html#refer√™ncias",
    "title": "Artigo 5: For Real: A Thorough Look at Numeric Attributes in Subgroup Discovery",
    "section": "Refer√™ncias",
    "text": "Refer√™ncias\nBoley M, Goldsmith BR, Ghiringhelli LM, Vreeken J (2017) Identifying consistent statements about numerical data with dispersion-corrected subgroup discovery. Data Min Knowl Discov 31(5):1391‚Äì1418. https://doi.org/10.1007/s10618-017-0520-3."
  }
]