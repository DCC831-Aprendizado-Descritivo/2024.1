[
  {
    "objectID": "seminario1/artigo1.html",
    "href": "seminario1/artigo1.html",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "",
    "text": "No campo da mineração e análise de dados, a mineração de padrões frequentes possui uma relevância bastante significativa, sendo importante para encontrar associações e correlações entre diferentes variáveis. Essa área de estudo surgiu juntamente com o crescimento exponencial da quantidade de dados disponíveis em diversos setores da vida cotidiana, em especial o comércio, tendo sido batizada com o nome de “Analise da cesta de compras”.\nPara dar seguimento a este artigo, é necessário definir (ou relembrar) alguns conceitos:\nA análise final dos padrões identificados como frequentes através da mineração executada pode muitas vezes ser complicada, por se tratar de uma técnica de aprendizado não supervisionado. Mas além da complexidade inata da análise de resultados, existe também a possibilidade dos padrões obtidos não significarem nada, ou simplesmente serem pouco úteis para os objetivos do negócio.\nPor exemplo, considere que na análise de uma papelaria os itens “lápis” e “borracha” são frequentemente incluídos em uma mesma transação, o preço final pago pelo consumidor por apenas esse conjunto de itens será muito baixo, não trazendo os benefícios esperados da análise. Porém, na mesma papelaria, pode ser que os itens impressora e cartucho de tinta também são frequentemente comprados juntos, o que leva a um preço final maior pago pelo consumidor.\nO exemplo anterior é básico, mas ilustra a ideia de que os itens serem apenas frequentes pode não ser o suficiente, sendo necessário que as combinações analisadas sejam também úteis para o analista. É nesse contexto que surge a mineração de padrões frequentes de alta utilidade, tratada no artigo “A Survey of High Utility Itemset Mining”, que aborda diferentes algoritmos para resolver esse problema.\nPara entender esses algoritmos, é primeiro necessário fazer uma segunda leva de definições sobre o assunto, dessa vez mais específicas ao escopo de mineração de padrões de alta utilidade:\nPerceba que, de acordo com essas definições, todos os algoritmos que são utilizados para mineração de padrões frequentes de alta utilidade podem também ser utilizados para minerar padrões frequentes, basta que a utilidade interna e externa de todos os itens seja definida com o mesmo valor, preferencialmente “1”. Para entender melhor as semelhanças e diferenças entre as duas técnicas de mineração de dados, verifique a tabela a seguir:"
  },
  {
    "objectID": "seminario1/artigo1.html#técnicas-e-algoritmos-usados",
    "href": "seminario1/artigo1.html#técnicas-e-algoritmos-usados",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Técnicas e Algoritmos usados",
    "text": "Técnicas e Algoritmos usados\nO artigo estudado tem por objetivo apresentar a área de mineração de padrões frequentes de alta utilidade, além de mostrar ao leitor diferentes algoritmos para realizar essa mineração. As principais técnicas para a confecção dos algoritmos são a de “Duas fases” e de “Uma fase”, essas técnicas serão explicadas nas próximas subseções, juntamente com um algoritmo representante de cada classe.\n\nAlgoritmos de duas fases\nAlgoritmos que seguem essa técnica usam o conceito de “Utilidade da transação”, ou Transaction Utility (TU), que pode ser definido como a soma da utilidade de todos os itens que estão presentes em uma transação, para definir limites superiores do quão alta a utilidade de um subconjunto dessa transação pode ser. Esse limite superior é calculado para cada um dos padrões (itemsets) candidatos através de uma “Utilidade com peso em transações”, ou Transaction Weighted Utility (TWU), que é definida como a soma da utilidade de todas as transações que contêm o padrão em evidência.\nO valor obtido de TWU para um itemset, é o limite superior para todos os superconjuntos que possam ser formados a partir dele. Por exemplo, suponha a existência de um itemset base {a, b} que possui TWU igual a 10, isso significa que qualquer itemset da forma {a, b, _}, onde o terceiro e último item pode ser qualquer um do universo de itens disponívei, terá necessariamente uma utilidade menor que 10. A aplicação dessa propriedade nos algoritmos traz um importante avanço, que é o estabelecimento de um decrescimento monotônico do TWU de acordo com o aumento dos itens em um itemset.\nA partir dessas propriedades, é definido um suporte de utilidade mínimo que elimina todos os itemsets que tenham TWU abaixo desse limiar assim que são identificados, evitando a geração de superconjuntos que não têm chances de serem de alta utilidade.\n\n\n\nExemplo de cálculo do TWU.\n\n\nA primeira fase dos algoritmos consiste em gerar o TWU de todos os itens disponíveis, já que eles são o menor itemset possível (excluindo o conjunto vazio). Após o cálculo, todos os itemsets unitários que tenham um TWU que estejam abaixo do suporte de utilidade mínimo definido são eliminados do espaço de busca, evitando que candidatos infrutíferos sejam gerados. Em seguida, a geração de candidatos continua para os itemsets de dois elementos gerados a partir dos remanescentes do filtro anterior, sendo que esses novos candidatos serão também removidos no caso de terem TWU menor que o suporte mínimo. Essa sequência de ações continua em repetição até que já não seja mais possível gerar novos candidatos.\n\nNote que nessa primeira fase está sendo calculado o TWU, que é o limite superior de utilidade, e não a utilidade dos itemsets em si\n\nA segunda fase do algoritmo consiste em calcular a utilidade de todos os candidatos que sobraram da fase anterior, eliminando aqueles que tenham utilidade menor que o limite inferior estabelecido.\nO primeiro algoritmo desenvolvido para essa técnica se chama Two-Phase Algorithm, tendo sido baseado no algoritmo Apriori para mineração de padrões frequentes. É possível ver uma imagem do pseudocódigo desse algoritmo a seguir:\n\n\n\nPseudocódigo do algoritmo Two-Phase.\n\n\nPerceba que a função ITEMSETGENERATION() recebe apenas o conjunto de candidatos da iteração anterior como parâmetro, não verificando a base de dados de transação para gerar os candidatos, o que pode levar a itemsets que não ocorrem em nenhuma transação, resultando em um desperdício de tempo considerável para os cálculos deles.\nOutra limitação do algoritmo é que ele itera pelo conjunto de dados várias vezes para calcular o TWU dos itemsets, elevando o custo do algoritmo. Note que a exploração do espaço de busca desse algoritmo segue a técnica de Breadth First Search (BFS), o que leva a uma maior demora para eliminação de candidatos infrutíferos, principalmente pelo fato de que o TWU é uma métrica de limite extrapolada.\n\n\nAlgoritmos de uma fase\nEsses algoritmos são mais diretos, fazendo o cálculo da utilidade de cada padrão considerado no espaço de busca, o que permite identificar imediatamente se um itemset é de alta ou baixa utilidade sem a necessidade de guardá-lo em memória principal (RAM).\nOutra novidade desses algoritmos é que eles trazem uma nova forma de calcular os limites superiores de utilidade, sendo mais próxima à utilidade real dos itemsets do que o TWU usado nos algoritmos de duas fases. Como exemplo de algoritmo dessa técnica, será utilizado o Fast High-Utility Miner (FHM), que introduz o conceito de Listas de Utilidade, ou Utility List (UL), para representar o banco de dados das transações.\nConsiderando um itemset X, a lista de utilidade UL(X) será uma lista de tuplas para todas as ocorrências de X nas transações do banco, sendo que cada tupla armazenará o ID da transação em que o itemset está presente, a utilidade do itemset naquela transação e a soma da utilidade de todos os itens com ordem lexicográfica superior aos itens de X. O algoritmo se inicia calculando as listas de utilidade de todos os itemsets de um único elemento, sendo que as listas de utilidades dos superconjuntos desses itemsets será calculada a partir dos componentes delas.\nPor exemplo, suponha as listas de utilidade dos conjuntos unitários UL({a}) e UL({d}), para gerar a lista de utilidade e calcular a utilidade do itemset {a, d}, será calculada a interseção das transações que estão em UL({a}) e UL({d}). A utilidade do novo itemset será simplesmente a soma das utilidades dos itemsets geradores, enquanto a utilidade dos itens com ordem lexicográfica superior será igual a presente no itemset gerador de maior ordem lexicográfica, no caso do exemplo, será o mesmo de {b}.\n\n\n\nExemplo de cálculo das listas de utilidade.\n\n\nO cálculo do limite superior para esse algoritmo é chamado de “Limite Superior por Utilidade Residual”, ou Remaining Utility Upper-Bound, é feito somando a utilidade de um item (iutil) com a utilidade dos itens residuais de ordem lexicográfica maior (rutil) para todas as transações presentes na lista de utilidade. Caso esse resultado final seja menor que a utilidade mínima definida, aquele itemset é eliminado do espaço de busca, evitando que novos candidatos sejam gerados. A figura a seguir mostra o pseudocódigo para o algoritmo FHM:\n\n\n\nPseudocódigo do algoritmo FHM.\n\n\nAlgoritmos baseados em listas de utilidade, como o FHM, são até duas ordens de magnitude mais rápidos que os algoritmos de duas fases. Porém, a geração de candidatos ainda é baseada em itemsets anteriores, sem verificar o banco de dados de transações, o que pode levar a candidatos inexistentes e aumento no custo total do algoritmo por gastar recursos verificando possibilidades desnecessárias.\nAlém disso, o custo de memória para o armazenamento das listas de utilidade de cada itemset verificado pode vir a ser preocupante. Outro ponto de atenção de algoritmos que seguem essa estratégia é o fato de que são feitas muitas comparações com listas de utilidade anteriores no processo de geração de candidatos, já que um candidato com k itens deverá fazer comparações com k-1 listas de utilidade anteriores."
  },
  {
    "objectID": "seminario1/artigo1.html#metodologia-do-artigo",
    "href": "seminario1/artigo1.html#metodologia-do-artigo",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Metodologia do artigo",
    "text": "Metodologia do artigo\nO artigo adota uma abordagem metodológica baseada em Survey, delineando inicialmente o problema em questão e, em seguida, apresentando algoritmos destinados à sua resolução. Uma filtragem criteriosa de artigos relevantes no domínio da mineração de itemsets de alta utilidade foi realizada, seguida pela compilação e síntese dos algoritmos destacados, abordando suas estruturas e conceitos fundamentais.\nOs primeiros algoritmos abrangentes para identificar conjuntos de itens de alta utilidade operam em duas fases distintas: primeiro, geram-se candidatos que são subsequentemente avaliados quanto à sua utilidade efetiva. Esses algoritmos introduziram uma inovação crucial ao estabelecer uma medida monótona que serviria como limite superior para a utilidade dos conjuntos de itens. Uma dessas medidas pioneiras foi a TWU (Transaction-Weighted Utilization), a qual permitiu uma poda eficiente do espaço de busca. Em estágios posteriores, surgiram algoritmos de uma única fase, cujo propósito é economizar tempo ao integrar a geração e avaliação de candidatos em um único passo. Vale ressaltar que muitos desses algoritmos propostos representam generalizações de técnicas de mineração de conjuntos de itens frequentes estabelecidas, como o Two Phase (uma extensão do Apriori) e o UP-Growth (uma extensão do FP-Growth).\nDentre os algoritmos apresentados para a mineração de padrões frequentes de alta utilidade são destacados os seguintes:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTipo de Busca\nFases\nRepresentação dos Dados\nExtende\n\n\n\n\nTwo-Phase\nBusca em Largura\nDuas\nHorizontal\nApriori\n\n\nHUP-Growth\nBusca em Profundidade\nDuas\nHorizontal (Árvore de Prefixos)\nFP-Growth\n\n\nD2HUP\nBusca em Profundidade\nUma\nVertical (Hiperestrutura)\nH-Mine\n\n\nFHM\nBusca em Profundidade\nUma\nVertical (Listas de Utilidade)\nEclat\n\n\nEFIM\nBusca em Profundidade\nUma\nVertical (com fusões)\nLCM\n\n\n\nO artigo porém não se contém somente em discutir os algoritmos completos de mineração de padrões, mas também, reconhecendo a importância de representações com um nível maior de significado. É nesse ponto em que são apresentados os algoritmos que mineram representações concisas dos subconjuntos de alta utilidade:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nPadrões\nFases\nRepresentação dos Dados\nExtende\n\n\n\n\nMinFHM\nMinUIs\nUma\nVertical (Listas de Utilidade)\nFHM\n\n\nCHUD\nCHUIs\nDuas\nVertical (Listas de Utilidade)\nDCI Closed\n\n\nEFIM-CLOSED​\nCHUIs\nUma\nHorizontal (com fusões)\nEFM\n\n\nGUIDE\nMHUIs One\nUma\nStream\nUpGrowth\n\n\n\nPor fim, são apresentados algoritmos que retornam apenas os K subconjuntos de alta utilidade mais frequentes no conjunto de transações:\n\n\n\n\n\n\n\n\n\n\nAlgoritmo\nTipo de Busca\nFases\nRepresentação dos Dados\nExtende\n\n\n\n\nTKU​\nBusca em Profundidade​\nDuas\nHorizontal (Árvore de Prefixos)\n​ UP-Growth​\n\n\nTKO​\nBusca em Profundidade​\nUma\nVertical (Listas de Utilidade)\nHUI-Miner​\n\n\nREPT​\nBusca em Profundidade​\nUma\nHorizontal (Árvore de Prefixos)​\nMU-Growth​\n\n\nkHMC​\nBusca em Profundidade​\nUma\nVertical (Listas de Utilidade)​\nFHM​"
  },
  {
    "objectID": "seminario1/artigo1.html#aplicações-e-desafios-éticos-e-sociais",
    "href": "seminario1/artigo1.html#aplicações-e-desafios-éticos-e-sociais",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Aplicações e Desafios Éticos e Sociais",
    "text": "Aplicações e Desafios Éticos e Sociais\nHá uma vasta gama de problemas do mundo real que podem se beneficiar significativamente do uso de algoritmos de mineração de subconjuntos frequentes de alta utilidade. Entre eles:\n\nMercado de Varejo: Potencial para aumentar os lucros ao impulsionar as vendas de produtos mais rentáveis.\nMercado de Compra Conjunta: Oportunidade de melhorar a lucratividade ao associar produtos visando redução de impostos.\nSistema de Recomendação: Aprimoramento da capacidade de gerar lucro ao focar em produtos mais rentáveis.\nCross-Selling e Up-Selling: Estímulo para compras de produtos complementares e promoção de vendas casadas.\nTratamento de Saúde: Desenvolvimento de conjuntos de tratamentos visando maior eficiência.\nDetecção de Fraudes: Identificação de padrões pouco frequentes, porém altamente úteis, na detecção de fraudes. Uso da Internet:__ Análise do comportamento dos usuários para aprimorar a importância do site.\nTelecomunicações: Utilização na identificação de padrões de comunicação que resultam em maior lucratividade.\nMineração de Texto: Identificação de textos com elevado valor agregado.\n\nNo entanto, a implementação de algoritmos de mineração de alta utilidade suscita preocupações sociais e éticas que demandam uma atenção cuidadosa. Um ponto crucial é a ameaça à privacidade, uma vez que a identificação de indivíduos a partir de dados aparentemente anônimos pode comprometer a segurança dos mesmos. Ademais, há o risco de manipulação do mercado e do comportamento do consumidor, onde o conhecimento de padrões de consumo pode ser utilizado de maneira indevida para influenciar escolhas.\nOutra questão relevante é a elisão fiscal, na qual empresas utilizam o conhecimento de padrões de alta utilidade para minimizar suas obrigações fiscais de forma legal, mas questionável do ponto de vista ético. Esses desafios destacam a importância de regulamentações sólidas e transparência no uso de algoritmos de mineração de dados, garantindo que o impacto social e ético seja considerado em todas as etapas, desde a implementação até a operação dessas ferramentas avançadas."
  },
  {
    "objectID": "seminario1/artigo1.html#como-usar",
    "href": "seminario1/artigo1.html#como-usar",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Como usar",
    "text": "Como usar\nNeste guia iremos ensinar o passo a passo para poder executar o SPMF, um software livre que tem implementado vários algoritmos de mineração de itemsets de alta qualidade.\nA execução do SPMF exige o JAVA versão mínima 1.8, aqui iremos mostrar a instalação tanto do JAVA quanto do SPMF para o Windows, o processo de instalação do programa deve ser o mesmo no Linux, já que o programa é baseado em JAVA, a diferença se dará na instalação do JAVA.\n\nInstalação\nInicialmente segui o guia de instalação do JAVA deste link, mas na hora de execução do SPMF o programa não funcionou e a solução foi reinstalar o JAVA de outra forma. Apenas a fim de documentar um possível erro que você encontre ao tentar executar o SPMF, fica aqui o vídeo do processo de instalação que não funcionou.\n\n\n\n\n\nInstalação da versão errada do JAVA\n\n\nA instalação do SPMF é simples e se encontra neste link. O vídeo a seguir mostra o processo inteiro:\n\n\n\n\n\nInstalação do software SPMF\n\n\nComo dito anteriormente, no final obtemos um erro do JAVA que é concertado pela re-instalação de uma versão atual neste link, tal processo é mostrado no vídeo a seguir:\n\n\n\n\n\nInstalação da versão mais recente do JAVA\n\n\n\n\nExecução\n\nArquivo de Entrada\nO SPMF suporta arquivos de entrada no formato .txt.\nA primeira parte do arquivo de entrada é opcional e é usada para nomear os itens presentes no banco de dados.\n\nLinhas começando com @​.\nPrimeira linha com “@CONVERTED_FROM_TEXT”​\nDemais linhas fazem a ligação do item com sua descrição no formato @ITEM={ID}={DESCRICAO}\n\n{ID} é o número do item\n{DESCRICAO} é o nome do item\n\n\n\n\n\nPrimira parte do arquivo de entrada (opcional)\n\n\nA segunda parte contém os dados das transações, com cada linha representando uma transação e cada coluna separada por “:” contendo o itemset, a utilidade total do itemset e a utilidade de cada item do itemset, respectivamente.\n\nLinhas representam as transações​\nCada linha possui 3 colunas separadas pelo caractere ‘:’​\n\nColuna 1: itemset com os ids dos itens separados por espaço simples.\nColuna 2: utilidade total do itemset.\nColuna 3: utilidade respectiva de cada item do itemset separadas por espaço simples.​\n\n\n\n\n\nSegunda parte do arquivo de entrada\n\n\n\n\nExecução do Software\nVídeo tutorial de como se deve executar o programa a partir do dado de entrada, o algoritmo escolhido no tutorial foi o Two-Phase:\n\n\n\n\n\nApesar de no tutorial ser mostrado a execução com o algoritmo Two-Phase, temos várias opções de algoritmos para mineração de itensets de alta utilidade, como UP-Growth, UP-Growth+, FHM e HUI-Miner.\n\n\nArquivo de Saída\nA saída do algoritmo também é um arquivo .txt, contendo os itemsets de alta utilidade encontrados, o suporte do itemset (nem todos os algoritmos geram esse valor) e a utilidade do itemset.\n\nLinhas representam itemsets de alta utilidade encontrados.​\nCada linha possui 3 seções:​\n\nO itemset, com os ids ou nomes dos itens separados por espaço simples, depende da existência da 1ª parte do arquivo de entrada.​\n“#SUP: {VALOR}” onde {VALOR} é o suporte do itemset (nem todos os algoritmos geram esse valor)​\n“#UTIL: {VALOR}” onde {VALOR} é a utilidade do itemset.\n\n\n\n\n\nArquivo de saída"
  },
  {
    "objectID": "seminario1/artigo1.html#referências",
    "href": "seminario1/artigo1.html#referências",
    "title": "Artigo 1: A Survey of High Utility Itemset Mining",
    "section": "Referências",
    "text": "Referências\n\nFournier-Viger, P., Chun-Wei Lin, J., Truong-Chi, T., Nkambou, R. (2019). A Survey of High Utility Itemset Mining. In: Fournier-Viger, P., Lin, JW., Nkambou, R., Vo, B., Tseng, V. (eds) High-Utility Pattern Mining. Studies in Big Data, vol 51. Springer, Cham. https://doi.org/10.1007/978-3-030-04921-8_1\nFOURNIER-VIGER, P. et al. FHM: Faster High-Utility Itemset Mining Using Estimated Utility Co-occurrence Pruning. ReserachGate, Taiwan, jul./2014. Disponível em: https://www.researchgate.net/publication/263696687. Acesso em: 23 abr. 2024.\n\nFournier-Viger, Philippe. “SPMF: A Java Open-Source Pattern Mining Library.” Disponível em: https://www.philippe-fournier-viger.com/spmf/index.php. Acesso em: 22 de Abril de 2024.\nLIU, Mengchi; QU, Junfeng. Mining High Utility Itemsets without Candidate Generation. ResearchGate, Wuhan, nov./2020. Disponível em: https://www.researchgate.net/publication/262369808. Acesso em: 23 abr. 2024."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizado Descritivo",
    "section": "",
    "text": "Aprendizado Descritivo — DCC/UFMG   Prof. Renato Vimieiro \n\nEssa disciplina é ofertada no Programa de Pós-Graduação em Ciência da Computação da Universidade Federal de Minas Gerais. Ela tem como objetivo apresentar técnicas avançadas para identificação de padrões descritivos em bases de dados. A(o) aluna(o) terá contato com técnicas para aprendizado de padrões não-supervisionados e supervisionados. Serão discutidas as dificuldades computacionais da busca por tais padrões, bem como sua utilidade para análise exploratória de dados.\nOs tópicos abordados na disciplina são:\n\nDiferenças entre aprendizado descritivo e preditivo.\nAprendizado descritivo não-supervisionado.\nAprendizado descritivo supervisionado.\nRepresentações condensadas.\nMétricas de qualidade de padrões descritivos.\nAlgoritmos de aprendizado de padrões descritivos supervisionados e não-supervisionados.\nEstudos de casos e aplicações em problemas reais.\n\nOs tópicos são apresentados através de aulas expositivas sobre o assunto, leitura e apresentação de seminários sobre artigos recentes na literatura, e projetos de aplicação dos métodos estudados para extração de conhecimento de bases de dados.\nUtilize o menu acima ou o link a seguir para visualizar o conteúdo produzido nos seminários e projetos desenvolvidos pelos alunos.\n\nSeminários: Padrões frequentes; Descoberta de subgrupos; Aplicações"
  },
  {
    "objectID": "seminario1.html",
    "href": "seminario1.html",
    "title": "Introdução",
    "section": "",
    "text": "Os seminários da disciplina consistem em uma apresentação coletiva (da turma) de um artigo mais recente sobre tópicos diretamente relacionados ao conteúdo visto em sala. A ideia é que a turma como um todo estude os artigos mais recentes da área e discuta esses trabalhos em sala. Em cada sessão, discutimos três artigos recentes relacionados aos tópicos abordados nas aulas teóricas.\nPara isso, adotamos um formato adaptado da proposta apresentada pelos Profs. Alec Jacobson e Colin Raffel, ambos da Universidade de Toronto (Canadá) – veja a proposta original em https://colinraffel.com/blog/role-playing-seminar.html. A proposta consiste em fazer uma encenação de papéis (role play) científicos para a apresentação do seminário. Nessa proposta, cada grupo cumprirá um papel na apresentação. Ao final, uma apresentação em formato de slides e um documento textual são produzidos. A apresentação é usada em sala de aula para fomentar as discussões, enquanto o documento fornece uma descrição textual das impressões da turma com a intenção de descrever o tema do artigo para um público amplo interessado em aprendizado de máquina e mineração de dados.\nSão apresentados a seguir os artigos discutidos no semestre 2024/1, com os respectivos links para os slides e documentos textuais apresentando os artigos.\n\n\nA Survey of High Utility Itemset Mining\nby Fournier-Viger, Philippe, Jerry Chun-Wei Lin, Tin Truong-Chi, and Roger Nkambou. 2019\nhttps://doi.org/10.1007/978-3-030-04921-8_1\n\n\n\nFinding Local Groupings of Time Series\nby Lee, Zed, Marco Trincavelli, and Panagiotis Papapetrou. 2023\nhttps://doi.org/10.1007/978-3-031-26422-1_5\n\n\n\nRepresentation Learning for Frequent Subgraph Mining\nby Ying, Rex, Tianyu Fu, Andrew Wang, Jiaxuan You, Yu Wang, and Jure Leskovec. 2024\nhttps://arxiv.org/abs/2402.14367"
  },
  {
    "objectID": "seminario1.html#artigo-1",
    "href": "seminario1.html#artigo-1",
    "title": "Introdução",
    "section": "",
    "text": "A Survey of High Utility Itemset Mining\nby Fournier-Viger, Philippe, Jerry Chun-Wei Lin, Tin Truong-Chi, and Roger Nkambou. 2019\nhttps://doi.org/10.1007/978-3-030-04921-8_1"
  },
  {
    "objectID": "seminario1.html#artigo-2",
    "href": "seminario1.html#artigo-2",
    "title": "Introdução",
    "section": "",
    "text": "Finding Local Groupings of Time Series\nby Lee, Zed, Marco Trincavelli, and Panagiotis Papapetrou. 2023\nhttps://doi.org/10.1007/978-3-031-26422-1_5"
  },
  {
    "objectID": "seminario1.html#artigo-3",
    "href": "seminario1.html#artigo-3",
    "title": "Introdução",
    "section": "",
    "text": "Representation Learning for Frequent Subgraph Mining\nby Ying, Rex, Tianyu Fu, Andrew Wang, Jiaxuan You, Yu Wang, and Jure Leskovec. 2024\nhttps://arxiv.org/abs/2402.14367"
  },
  {
    "objectID": "seminario1/artigo2.html",
    "href": "seminario1/artigo2.html",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "O estudo e a análise de séries temporais desempenham um papel crucial em uma ampla gama de campos, desde o monitoramento do varejo até a detecção de anomalias de segurança. Ao longo do tempo, observações contínuas capturam nuances e padrões que podem revelar insights valiosos sobre o comportamento de sistemas complexos. Neste contexto, a capacidade de agrupar séries temporais com base em padrões similares torna-se fundamental para extrair conhecimento significativo.\n\n\nA motivação por trás dessa abordagem é multifacetada. No setor de varejo, por exemplo, a identificação de tendências locais de compra, como picos de vendas durante períodos festivos, pode ser crucial para otimizar estratégias de marketing e estoque. Da mesma forma, em análises financeiras, compreender as tendências de mercado pode orientar decisões de investimento. Em setores como saúde e biomedicina, a análise de variações sazonais e padrões de sono pode contribuir para o desenvolvimento de tratamentos mais eficazes. Além disso, o planejamento de recursos, a detecção de anomalias de segurança e a análise de dados ambientais e climáticos também se beneficiam significativamente da capacidade de identificar e compreender padrões em séries temporais.\nNeste contexto, este artigo aborda a importância da abordagem de agrupamento de séries temporais, com foco no algoritmo Z-groupings. Exploraremos como esse método oferece uma perspectiva única para a identificação de grupos locais em séries temporais, destacando sua relevância e aplicabilidade em diversas áreas de estudo e prática. Ao compreendermos melhor as nuances e potenciais aplicações do Z-groupings, podemos abrir novas oportunidades para análises mais precisas e insights mais profundos em uma variedade de domínios.\n\n\n\nO algoritmo Z-groupings não possui comparativos diretos. No entanto, existem alguns métodos clássicos que realizam tarefas comparáveis:\n\nK-means: Este método particiona séries temporais em k clusters, onde os clusters representam grupos locais análogos aos encontrados pelo Z-groupings.\nAgrupamento Hierárquico: Neste método, as séries temporais são hierarquicamente divididas com base em uma métrica de similaridade. Os grupos resultantes são comparáveis aos grupos locais identificados pelo Z-groupings.\n\nContudo, é importante ressaltar que esses algoritmos não são diretamente comparáveis, pois se limitam a encontrar similaridades dentro de uma única série temporal, não considerando relações entre diferentes séries.\nJá em relação aos algoritmos de mineração de sequências, fica evidente que ambos compartilham diversas características fundamentais. Ambos os métodos têm a capacidade de identificar padrões sequenciais em conjuntos de dados, baseando-se na frequência de ocorrência desses padrões. Além disso, ambos utilizam o conceito de suporte para filtrar padrões menos frequentes, priorizando aqueles que são mais relevantes para a análise.\nEntretanto, ao analisar as diferenças entre o Z-groupings e seus equivalentes na mineração de sequência, destacam-se aspectos distintivos que delineiam a aplicação específica do Z-groupings em contextos de séries temporais. Enquanto muitos algoritmos de mineração de sequência são aplicáveis a diversos tipos de dados, o Z-groupings é especialmente projetado para lidar com séries temporais. Sua funcionalidade principal reside na capacidade de agrupar sequências temporais em grupos locais, visando identificar associações significativas entre os padrões temporais presentes nos dados. Essa abordagem mais focalizada confere ao Z-groupings uma vantagem significativa em cenários onde a compreensão das relações temporais é crucial para a análise e interpretação dos dados.\nEssas nuances ressaltam a importância do Z-groupings como uma ferramenta especializada e eficaz para a análise de séries temporais, oferecendo insights valiosos e facilitando a descoberta de padrões e associações relevantes nos dados.\n\n\n\nSerão examinados três casos específicos que destacam a versatilidade e utilidade do Z-groupings: o agrupamento de séries temporais de consumo de energia elétrica em residências, a análise da relação entre manejos madeireiros e desmatamento usando agrupamento de séries temporais, e a análise de consumo de medicamentos para otimização da logística de distribuição. Cada uma dessas aplicações oferece uma perspectiva única sobre como o Z-groupings pode ser empregado para abordar desafios complexos e promover impactos significativos em diversos setores.\n\n\nO agrupamento de séries temporais de consumo de energia elétrica em residências é uma aplicação-chave das redes inteligentes, impulsionadas pela convergência de sistemas computacionais, de medição e de comunicação. Os medidores inteligentes, responsáveis por capturar e transmitir dados de consumo em intervalos regulares, geram uma quantidade substancial de informações. A análise desses dados, conhecida como agrupamento de curvas de carga, é essencial para extrair insights relevantes. Neste contexto, o Z-groupings e outros algoritmos semelhantes emergem como ferramentas valiosas.\nAs implicações dessa aplicação são diversas:\n\nPrevisão de demanda de energia: Identificar padrões de consumo semelhantes entre diferentes regiões possibilita prever com mais precisão a demanda futura de energia. Isso facilita o planejamento da produção e distribuição de eletricidade pelas empresas de energia.\nDetecção de anomalias: Ao conhecer os padrões de consumo típicos, torna-se mais fácil detectar anomalias que possam indicar falhas nos equipamentos, problemas de eficiência energética ou atividades suspeitas, como roubo de energia.\nPotencial para discriminação: O uso das informações sobre padrões de consumo para segmentar clientes ou estabelecer tarifas diferenciadas pode levar à discriminação. Alguns grupos demográficos podem ser penalizados ou excluídos, aumentando as desigualdades.\nRisco de monopólio: Empresas de distribuição de energia com acesso a recursos computacionais avançados para análise de dados têm uma vantagem competitiva significativa. Isso pode resultar em um desequilíbrio de mercado, com grandes empresas dominando e marginalizando empresas menores.\n\nEssas consequências ressaltam a importância não apenas da aplicação eficaz de algoritmos de agrupamento de séries temporais, como o Z-groupings, mas também da consideração cuidadosa dos impactos sociais e éticos das decisões baseadas em dados no setor de energia elétrica.\n\n\n\nA análise da relação entre manejos madeireiros e desmatamento na Amazônia, por meio do agrupamento de séries temporais, destaca-se como uma aplicação vital dessa técnica analítica. Ao examinar as mudanças no índice de cobertura vegetal ao longo do tempo, é possível identificar padrões e tendências cruciais para o monitoramento e prevenção do desmatamento, bem como para o planejamento estratégico de políticas de conservação.\nAs consequências potenciais desse enfoque são variadas:\n\nMonitoramento e prevenção eficazes do desmatamento: O uso do agrupamento de séries temporais pode melhorar substancialmente as estratégias de prevenção do desmatamento, identificando áreas em risco e facilitando intervenções preventivas.\nPlanejamento de políticas de conservação: A identificação de áreas com alto risco de desmatamento possibilita o direcionamento eficiente de recursos e esforços para medidas preventivas, como programas de educação ambiental e reforço da fiscalização.\nRiscos à privacidade: O monitoramento detalhado pode levantar preocupações de privacidade, revelando informações sensíveis sobre padrões de vida e comportamentos das comunidades locais.\nDesigualdade e discriminação: Restrições ao uso da terra e acesso limitado às ferramentas de análise podem resultar em desigualdades na distribuição de recursos para a conservação.\nImpacto nos meios de subsistência locais: As políticas de conservação devem considerar os impactos nas comunidades locais, garantindo que sejam justas e equitativas.\n\nEssas considerações destacam a importância de uma abordagem ética e abrangente no uso do agrupamento de séries temporais para a análise da relação entre manejos madeireiros e desmatamento na Amazônia.\n\n\n\nA aplicação do método Z-Grouping na análise do consumo e distribuição de medicamentos apresenta uma oportunidade significativa para aprimorar a gestão de recursos farmacêuticos, especialmente sob a perspectiva da saúde pública, com foco na atuação da Agência Nacional de Vigilância Sanitária (ANVISA). Ao identificar padrões temporais e regionais no uso de medicamentos, essa abordagem oferece insights valiosos para intervenções estratégicas na logística de distribuição.\nAs aplicações práticas dessa análise são amplas:\n\nRefinamento da Logística de Distribuição: A identificação de agrupamentos locais de consumo permite ajustes precisos na cadeia de suprimentos, garantindo a disponibilidade adequada de medicamentos essenciais nas regiões com maior demanda, o que é crucial para garantir a continuidade dos tratamentos, especialmente em contextos de doenças crônicas ou surtos de doenças infecciosas.\nProjeção de Demandas Futuras: O Z-Grouping possibilita a projeção de demandas com base em tendências históricas, permitindo a antecipação de necessidades, como vacinas ou medicamentos antivirais. Essa capacidade preditiva é fundamental para evitar escassez ou excesso de estoques, possibilitando uma resposta eficiente às flutuações do mercado e demandas emergentes.\nDiagnóstico de Desperdícios e Ineficiências: Além disso, essa abordagem revela padrões de subutilização ou desperdício de medicamentos, indicando áreas potenciais para otimização das políticas de distribuição e uso racional de recursos farmacêuticos.\n\nEntretanto, a implementação dessas análises não está isenta de desafios e consequências, como:\n\nIntegridade e Segurança dos Dados: A gestão cuidadosa da integridade e segurança dos dados é essencial para prevenir riscos de comprometimento das análises, garantindo o cumprimento das normativas de proteção de dados, como a LGPD.\nJustiça na Distribuição de Medicamentos: Há o risco de que análises baseadas em dados não reflitam com precisão a distribuição demográfica, resultando em alocações de recursos que perpetuam desequilíbrios existentes. Portanto, é crucial que as decisões de política farmacêutica considerem profundamente as necessidades locais.\nRiscos da Dependência de Modelos Quantitativos: Apesar da robustez do Z-Grouping, sua aplicação deve ser complementada por análises qualitativas e conhecimento especializado em saúde pública para evitar decisões que não considerem a complexidade dos padrões de saúde específicos.\n\nEssas considerações destacam a importância de uma abordagem holística e cuidadosa na utilização do Z-Grouping para análise de consumo de medicamentos e sua distribuição, visando garantir benefícios significativos sem comprometer a integridade dos dados ou perpetuar desigualdades existentes."
  },
  {
    "objectID": "seminario1/artigo2.html#contextualização-do-problema",
    "href": "seminario1/artigo2.html#contextualização-do-problema",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "A motivação por trás dessa abordagem é multifacetada. No setor de varejo, por exemplo, a identificação de tendências locais de compra, como picos de vendas durante períodos festivos, pode ser crucial para otimizar estratégias de marketing e estoque. Da mesma forma, em análises financeiras, compreender as tendências de mercado pode orientar decisões de investimento. Em setores como saúde e biomedicina, a análise de variações sazonais e padrões de sono pode contribuir para o desenvolvimento de tratamentos mais eficazes. Além disso, o planejamento de recursos, a detecção de anomalias de segurança e a análise de dados ambientais e climáticos também se beneficiam significativamente da capacidade de identificar e compreender padrões em séries temporais.\nNeste contexto, este artigo aborda a importância da abordagem de agrupamento de séries temporais, com foco no algoritmo Z-groupings. Exploraremos como esse método oferece uma perspectiva única para a identificação de grupos locais em séries temporais, destacando sua relevância e aplicabilidade em diversas áreas de estudo e prática. Ao compreendermos melhor as nuances e potenciais aplicações do Z-groupings, podemos abrir novas oportunidades para análises mais precisas e insights mais profundos em uma variedade de domínios."
  },
  {
    "objectID": "seminario1/artigo2.html#relacionamento-com-métodos-clássicos",
    "href": "seminario1/artigo2.html#relacionamento-com-métodos-clássicos",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "O algoritmo Z-groupings não possui comparativos diretos. No entanto, existem alguns métodos clássicos que realizam tarefas comparáveis:\n\nK-means: Este método particiona séries temporais em k clusters, onde os clusters representam grupos locais análogos aos encontrados pelo Z-groupings.\nAgrupamento Hierárquico: Neste método, as séries temporais são hierarquicamente divididas com base em uma métrica de similaridade. Os grupos resultantes são comparáveis aos grupos locais identificados pelo Z-groupings.\n\nContudo, é importante ressaltar que esses algoritmos não são diretamente comparáveis, pois se limitam a encontrar similaridades dentro de uma única série temporal, não considerando relações entre diferentes séries.\nJá em relação aos algoritmos de mineração de sequências, fica evidente que ambos compartilham diversas características fundamentais. Ambos os métodos têm a capacidade de identificar padrões sequenciais em conjuntos de dados, baseando-se na frequência de ocorrência desses padrões. Além disso, ambos utilizam o conceito de suporte para filtrar padrões menos frequentes, priorizando aqueles que são mais relevantes para a análise.\nEntretanto, ao analisar as diferenças entre o Z-groupings e seus equivalentes na mineração de sequência, destacam-se aspectos distintivos que delineiam a aplicação específica do Z-groupings em contextos de séries temporais. Enquanto muitos algoritmos de mineração de sequência são aplicáveis a diversos tipos de dados, o Z-groupings é especialmente projetado para lidar com séries temporais. Sua funcionalidade principal reside na capacidade de agrupar sequências temporais em grupos locais, visando identificar associações significativas entre os padrões temporais presentes nos dados. Essa abordagem mais focalizada confere ao Z-groupings uma vantagem significativa em cenários onde a compreensão das relações temporais é crucial para a análise e interpretação dos dados.\nEssas nuances ressaltam a importância do Z-groupings como uma ferramenta especializada e eficaz para a análise de séries temporais, oferecendo insights valiosos e facilitando a descoberta de padrões e associações relevantes nos dados."
  },
  {
    "objectID": "seminario1/artigo2.html#impacto-social-e-potenciais-aplicações",
    "href": "seminario1/artigo2.html#impacto-social-e-potenciais-aplicações",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "",
    "text": "Serão examinados três casos específicos que destacam a versatilidade e utilidade do Z-groupings: o agrupamento de séries temporais de consumo de energia elétrica em residências, a análise da relação entre manejos madeireiros e desmatamento usando agrupamento de séries temporais, e a análise de consumo de medicamentos para otimização da logística de distribuição. Cada uma dessas aplicações oferece uma perspectiva única sobre como o Z-groupings pode ser empregado para abordar desafios complexos e promover impactos significativos em diversos setores.\n\n\nO agrupamento de séries temporais de consumo de energia elétrica em residências é uma aplicação-chave das redes inteligentes, impulsionadas pela convergência de sistemas computacionais, de medição e de comunicação. Os medidores inteligentes, responsáveis por capturar e transmitir dados de consumo em intervalos regulares, geram uma quantidade substancial de informações. A análise desses dados, conhecida como agrupamento de curvas de carga, é essencial para extrair insights relevantes. Neste contexto, o Z-groupings e outros algoritmos semelhantes emergem como ferramentas valiosas.\nAs implicações dessa aplicação são diversas:\n\nPrevisão de demanda de energia: Identificar padrões de consumo semelhantes entre diferentes regiões possibilita prever com mais precisão a demanda futura de energia. Isso facilita o planejamento da produção e distribuição de eletricidade pelas empresas de energia.\nDetecção de anomalias: Ao conhecer os padrões de consumo típicos, torna-se mais fácil detectar anomalias que possam indicar falhas nos equipamentos, problemas de eficiência energética ou atividades suspeitas, como roubo de energia.\nPotencial para discriminação: O uso das informações sobre padrões de consumo para segmentar clientes ou estabelecer tarifas diferenciadas pode levar à discriminação. Alguns grupos demográficos podem ser penalizados ou excluídos, aumentando as desigualdades.\nRisco de monopólio: Empresas de distribuição de energia com acesso a recursos computacionais avançados para análise de dados têm uma vantagem competitiva significativa. Isso pode resultar em um desequilíbrio de mercado, com grandes empresas dominando e marginalizando empresas menores.\n\nEssas consequências ressaltam a importância não apenas da aplicação eficaz de algoritmos de agrupamento de séries temporais, como o Z-groupings, mas também da consideração cuidadosa dos impactos sociais e éticos das decisões baseadas em dados no setor de energia elétrica.\n\n\n\nA análise da relação entre manejos madeireiros e desmatamento na Amazônia, por meio do agrupamento de séries temporais, destaca-se como uma aplicação vital dessa técnica analítica. Ao examinar as mudanças no índice de cobertura vegetal ao longo do tempo, é possível identificar padrões e tendências cruciais para o monitoramento e prevenção do desmatamento, bem como para o planejamento estratégico de políticas de conservação.\nAs consequências potenciais desse enfoque são variadas:\n\nMonitoramento e prevenção eficazes do desmatamento: O uso do agrupamento de séries temporais pode melhorar substancialmente as estratégias de prevenção do desmatamento, identificando áreas em risco e facilitando intervenções preventivas.\nPlanejamento de políticas de conservação: A identificação de áreas com alto risco de desmatamento possibilita o direcionamento eficiente de recursos e esforços para medidas preventivas, como programas de educação ambiental e reforço da fiscalização.\nRiscos à privacidade: O monitoramento detalhado pode levantar preocupações de privacidade, revelando informações sensíveis sobre padrões de vida e comportamentos das comunidades locais.\nDesigualdade e discriminação: Restrições ao uso da terra e acesso limitado às ferramentas de análise podem resultar em desigualdades na distribuição de recursos para a conservação.\nImpacto nos meios de subsistência locais: As políticas de conservação devem considerar os impactos nas comunidades locais, garantindo que sejam justas e equitativas.\n\nEssas considerações destacam a importância de uma abordagem ética e abrangente no uso do agrupamento de séries temporais para a análise da relação entre manejos madeireiros e desmatamento na Amazônia.\n\n\n\nA aplicação do método Z-Grouping na análise do consumo e distribuição de medicamentos apresenta uma oportunidade significativa para aprimorar a gestão de recursos farmacêuticos, especialmente sob a perspectiva da saúde pública, com foco na atuação da Agência Nacional de Vigilância Sanitária (ANVISA). Ao identificar padrões temporais e regionais no uso de medicamentos, essa abordagem oferece insights valiosos para intervenções estratégicas na logística de distribuição.\nAs aplicações práticas dessa análise são amplas:\n\nRefinamento da Logística de Distribuição: A identificação de agrupamentos locais de consumo permite ajustes precisos na cadeia de suprimentos, garantindo a disponibilidade adequada de medicamentos essenciais nas regiões com maior demanda, o que é crucial para garantir a continuidade dos tratamentos, especialmente em contextos de doenças crônicas ou surtos de doenças infecciosas.\nProjeção de Demandas Futuras: O Z-Grouping possibilita a projeção de demandas com base em tendências históricas, permitindo a antecipação de necessidades, como vacinas ou medicamentos antivirais. Essa capacidade preditiva é fundamental para evitar escassez ou excesso de estoques, possibilitando uma resposta eficiente às flutuações do mercado e demandas emergentes.\nDiagnóstico de Desperdícios e Ineficiências: Além disso, essa abordagem revela padrões de subutilização ou desperdício de medicamentos, indicando áreas potenciais para otimização das políticas de distribuição e uso racional de recursos farmacêuticos.\n\nEntretanto, a implementação dessas análises não está isenta de desafios e consequências, como:\n\nIntegridade e Segurança dos Dados: A gestão cuidadosa da integridade e segurança dos dados é essencial para prevenir riscos de comprometimento das análises, garantindo o cumprimento das normativas de proteção de dados, como a LGPD.\nJustiça na Distribuição de Medicamentos: Há o risco de que análises baseadas em dados não reflitam com precisão a distribuição demográfica, resultando em alocações de recursos que perpetuam desequilíbrios existentes. Portanto, é crucial que as decisões de política farmacêutica considerem profundamente as necessidades locais.\nRiscos da Dependência de Modelos Quantitativos: Apesar da robustez do Z-Grouping, sua aplicação deve ser complementada por análises qualitativas e conhecimento especializado em saúde pública para evitar decisões que não considerem a complexidade dos padrões de saúde específicos.\n\nEssas considerações destacam a importância de uma abordagem holística e cuidadosa na utilização do Z-Grouping para análise de consumo de medicamentos e sua distribuição, visando garantir benefícios significativos sem comprometer a integridade dos dados ou perpetuar desigualdades existentes."
  },
  {
    "objectID": "seminario1/artigo2.html#conceitos-chave",
    "href": "seminario1/artigo2.html#conceitos-chave",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.1 Conceitos Chave",
    "text": "2.1 Conceitos Chave\nPara compreender o algoritmo Z-Grouping, é fundamental dominar alguns conceitos fundamentais.\n\n\nCode\nfrom zgrouping.zgrouping import grouping, syntheticGenerator, utils\nimport matplotlib.pyplot as plt\n\n\n\nSéries Temporais: Uma série temporal consiste em observações coletadas sequencialmente ao longo do tempo. Cada observação está vinculada a um instante específico, sendo a ordem das observações de crucial importância. Exemplo: Uma série temporal pode registrar as vendas diárias de um produto ao longo de um período, como as vendas diárias de um modelo de smartphone em uma loja.\n\n\n\nCode\ntc = 50\ntl = 365\nc = 20\nno_outliers = 10\noutlier_size = 10\n\n# GROUPING GENERATION\nn_bins = 5\nalpha = 0.9\neta = 1.5\n\nX_raw, y = syntheticGenerator.createSyntheticData(tc = tc, tl=tl, c = c, no_outliers = no_outliers, outlier_size=outlier_size)\nplt.plot(X_raw[0])\n\n\n\n\n\n\n\n\n\n\nAbstração Temporal: A abstração temporal é o processo de simplificar ou extrair características mais significativas de uma série temporal, facilitando sua análise. Exemplo: A aplicação do Symbolic Aggregate Approximation (SAX) para converter uma série temporal de vendas diárias em uma sequência de símbolos que representam padrões de vendas ao longo do tempo.\nEventos em Séries Temporais: Um evento em uma série temporal é uma ocorrência distinta ou uma característica identificável nos dados ao longo do tempo, como picos, vales, transições ou padrões recorrentes.\nRótulos de Eventos: Os rótulos de eventos são atributos simbólicos ou categorizações aplicadas aos eventos em uma série temporal para representá-los de maneira simplificada e compreensível. Exemplo: Os rótulos podem ser escolhidos de um conjunto discreto de símbolos ou categorias, como letras, números ou outros identificadores simbólicos.\nMatriz de Sequência de Eventos: Uma matriz que representa a sequência de rótulos de eventos derivados das séries temporais após a abstração temporal. Cada entrada na matriz representa um evento em uma série temporal específica.\nAgrupamento Local: O agrupamento local refere-se à identificação de subconjuntos de séries temporais que exibem padrões semelhantes em intervalos específicos de tempo. No contexto do Z-Grouping, os agrupamentos locais são identificados em cada canal de rótulo de evento.\nAssociação de Agrupamentos Locais: Associações são identificadas entre agrupamentos locais consecutivos ou sobrepostos que compartilham instâncias de séries temporais semelhantes. O objetivo é descobrir padrões mais amplos e complexos que não seriam detectados apenas nos agrupamentos locais individuais.\nSemigeometric Tiling: Um algoritmo utilizado para identificar padrões ou agrupamentos em matrizes binárias, considerando combinações de intervalos de tempo e contagens de eventos.\n\n\n\n\nFonte: Z. Lee et al. (2022)\n\n\n\nMatriz de Associação e Validação: Uma representação matricial usada para identificar e validar associações entre agrupamentos locais. Essa matriz registra as relações entre os agrupamentos locais e os agrupamentos globais pré-definidos.\n\n\n\n\nFonte: Z. Lee et al. (2022)"
  },
  {
    "objectID": "seminario1/artigo2.html#apresentação-do-algoritmo",
    "href": "seminario1/artigo2.html#apresentação-do-algoritmo",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.2 Apresentação do Algoritmo",
    "text": "2.2 Apresentação do Algoritmo\nO algoritmo Z-Grouping é composto por quatro passos distintos, cada um focado em uma etapa específica do processo de análise de séries temporais. São eles:\n\nGeração da Matriz de Sequência de Eventos\nNeste passo, uma coleção de séries temporais é convertida em uma matriz de eventos, utilizando técnicas de abstração temporal como o método SAX. Isso permite uma representação mais simplificada dos dados, facilitando a análise subsequente.\n\n\n\nCode\nX = utils.znorm(X_raw)\nX_sax = utils.SAXify(X, n_bins = 5)\nX_sax[0]\n\n\narray([2, 2, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\n\nCode\nplt.plot(X_raw[0])\nplt.plot(X_sax[0])\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCriação de canais de rótulos\nA matriz de eventos em seguida é subdividida em uma matriz binária de mesmo tamanho para cada rótulo\n\n\n\nCode\nmatrices = utils.createChannels(X_sax)\nmatrices[0]\n\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)\n\n\n\nGeração de Agrupamentos Locais\nO próximo passo envolve a identificação de agrupamentos locais em cada canal de rótulo de evento da matriz de eventos. Esse processo é conduzido pelo algoritmo de semigeometric tiling, que busca candidatos a agrupamentos locais com base na contagem de eventos em intervalos de tempo específicos. Além disso, o algoritmo utiliza um parâmetro 𝝰, variando de 0 a 1, para determinar a pureza de um agrupamento local. Por exemplo, ao definir 𝝰 como 0.75, estamos estabelecendo que pelo menos 75% dos elementos do agrupamento devem conter o evento analisado.\nIdentificação de Associações entre Agrupamentos Locais\nNesta etapa, o algoritmo procura associações entre os agrupamentos locais identificados. Isso é feito através da análise de candidatos a associações consecutivas, verificando a proximidade entre elas e identificando instâncias de séries temporais compartilhadas.\nValidação dos Agrupamentos Locais\nPor fim, os agrupamentos locais são validados em relação aos agrupamentos globais pré-definidos. Isso é feito calculando uma pontuação de validade com base na proporção de instâncias de séries temporais em comum e utilizando um parâmetro de densidade para controlar a validade dos agrupamentos locais.\n\n\n\n\nFonte: Z. Lee et al. (2022)\n\n\n\n\n\n\n\n\nFonte: Z. Lee et al. (2022)\n\n\n\n\nFigure 1: Um exemplo dos quatro passos do Z-grouping"
  },
  {
    "objectID": "seminario1/artigo2.html#metodologia-experimental",
    "href": "seminario1/artigo2.html#metodologia-experimental",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.3 Metodologia Experimental",
    "text": "2.3 Metodologia Experimental\nA metodologia experimental da pesquisa visa avaliar o desempenho do método Z-Grouping na identificação de agrupamentos locais em séries temporais. Para isso, foi utilizada uma abordagem abrangente que inclui a análise de conjuntos de dados reais de diferentes setores, bem como um conjunto de dados sintético para investigação detalhada dos parâmetros do método. Além disso, alguns métodos foram adaptados para efeitos de comparação. Abaixo, é fornecida uma descrição mais detalhada da metodologia utilizada.\n\nDatasets: Os conjuntos de dados reais utilizados abrangem três setores diferentes: indústria de varejo, mercado de ações e epidemias de COVID-19. Além disso, um conjunto de dados sintético foi gerado para investigação detalhada dos parâmetros do método. Este conjunto de dados sintético simula a presença de similaridade local em meio a padrões sinusoidais com diferentes frequências e amplitudes, além de incorporar ruído e outliers para refletir cenários do mundo real.\nConcorrentes: Como não existe um concorrente direto para o problema, foram feitas adaptações nos métodos semigeometric tiling, kmeans, kmeans-FLEX e kNN para identificar agrupamentos locais em séries temporais.\nProtocolo do Experimento: Para avaliar o desempenho do método Z-Grouping, foi desenvolvido um protocolo de experimento que envolve a divisão dos dados em conjuntos de treinamento e teste. Durante a fase de treinamento, os agrupamentos locais são identificados nos dados de treinamento. Na fase de teste, o objetivo é determinar se os agrupamentos identificados podem identificar padrões de similaridade local em novas instâncias não vistas. Para cada amostra de teste, o agrupamento global correspondente é usado como referência. Isso simula situações do mundo real, como identificar padrões de vendas de um novo produto com base em produtos existentes.\nMétricas de Avaliação: Os resultados são avaliados em termos de erros de predição, como erro quadrático médio (MSE) e erro absoluto médio (MAE), bem como a cobertura dos agrupamentos, ou seja, a fração de séries temporais cobertas pelos agrupamentos identificados."
  },
  {
    "objectID": "seminario1/artigo2.html#análise-crítica-dos-resultados",
    "href": "seminario1/artigo2.html#análise-crítica-dos-resultados",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "2.4 Análise Crítica dos Resultados",
    "text": "2.4 Análise Crítica dos Resultados\nEm relação aos resultados alcançados, todos foram validados 10 vezes, e os seguintes parâmetros foram utilizados:\nα: Este é um parâmetro que controla o nível de “pureza” dos agrupamentos.\nλ: Este parâmetro controla o número de rótulos de abstração que o algoritmo pode usar.\nη: Este parâmetro define o número mínimo de amostras necessárias para que um agrupamento seja considerado válido.\nw: Este é o intervalo de tempo (em número de amostras) que esses algoritmos usam para identificar os agrupamentos locais.\nk: Este é o número de agrupamentos (clusters) que esses algoritmos tentam formar.\nCorte de silhueta: Este é um parâmetro que define um valor de corte para a métrica de silhueta.\nOs algoritmos testados utilizaram os seguintes parâmetros:\nZ-Grouping: α = {0.8, 0.9, 1}, λ = {3, 5, 10}, e η = {1, 1.5, 2}.\nSemigeometric: α = {0.8, 0.9, 1}, e η = {1, 1.5, 2}.\nkmeans: intervalo de tempo w = {30, 60, 180} e k = {3, 5, 10}.\nkNN: intervalo de tempo w = {30, 60, 180} e k = {3, 5, 10}.\nkmeans-FLEX: corte de silhueta de 0,1 até falha em detectar quaisquer agrupamentos válidos.\nEm relação aos resultados no conjunto de dados sintéticos, pode-se analisar através da tabela 2 os erros de teste médios do Z-Grouping e seus quatro competidores. Através dela podemos chegar a algumas conclusões em relação ao Z-Grouping e seus concorrentes:\n\nO Z-Grouping sempre consegue encontrar agrupamentos locais válidos de baixos erros considerando MSE e MAE;\nSemigeometric sofre com sua falta de poder de representação com uma forte suposição binária superado pelo Z-Grouping em relação aos agrupamentos locais;\nkNN atinge seu melhor escore com {w: 180, k: 3};\nkmeans não mostra diferenças notáveis com várias configurações de parâmetros, e é geralmente pior do que seus concorrentes;\nKmeans-FLEX tem seu menor MSE sendo apenas 3,4% menor que o menor erro do kmeans;\nO Semigeometric, kmeans, kNN e kmeans-FLEX são piores do que o Z-Grouping em todas as situações.\n\nAlém disso, utilizando os dados de UCR o Z-Grouping apresentou dificuldade para encontrar padrões para o agrupamento, performando de forma semelhante aos competidores devido a perda de informação pelo SAX em conjuntos mais uniformes.\nJá em relação aos resultados no conjunto de dados reais, com os dados de GARMENT e STOCK o Z-Grouping apresentou resultados com diferença de 44.3% (MSE) e 25.2% (MAE) com cobertura de 88% dos dados, sendo superior aos competidores. E com os dados da COVID pode-se perceber que o trade-off de minimização do erro por perda de cobertura acabou levando o algoritmo a desempenhar com pouca melhora, sacrificando bastante da cobertura, cobrindo apenas 40% dos dados.\nPor fim, ao analisarmos o efeito dos parâmetros, um λ maior pode levar a uma menor cobertura, um α maior leva a agrupamentos mais puros o que permite um número menor de rótulos de evento diferentes, e um η maior exige mais amostras no agrupamento local para validade resultando em menos agrupamentos. Os parâmetros mais altos fazem com que o algoritmo perca sua capacidade de crescer mostrando aproximadamente só 10% de cobertura, além de gerar erros mais altos devido à ausência de pontos de dados para comparação. Por isso as associações dos agrupamentos são utilizadas para aumentar a cobertura preenchendo as lacunas criadas pelos altos valores dos parâmetros.\n\n\n\nTable 1: Erros médios de teste dos algoritmos no banco de dados Sintético (CV: Covarege(%))\n\n\n\n\n\nFonte: Z. Lee et al. (2022)"
  },
  {
    "objectID": "seminario1/artigo2.html#sumário-dos-resultados",
    "href": "seminario1/artigo2.html#sumário-dos-resultados",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "3.1 Sumário dos Resultados",
    "text": "3.1 Sumário dos Resultados\nO Z-Grouping foi testado contra quatro soluções alternativas para o problema de agrupamentos locais, baseadas em adaptações para o problema específico proposto no artigo de abordagens utilizadas de maneira geral em agrupamentos de séries temporais. Os cinco foram avaliados em três datasets com dados do mundo real, um dataset gerado sinteticamente e os 128 datasets clássicos de séries temporais da UCR (University of California, Riverside). O resultado dos experimentos constatou que o Z-Grouping atingiu taxas de erro menores do que seus competidores, e ao mesmo tempo gerou agrupamentos locais sem limitações no tamanho dos intervalos de tempo, o que não pode ser feito utilizando as demais abordagens."
  },
  {
    "objectID": "seminario1/artigo2.html#considerações-finais-e-sugestões-para-futuras-pesquisas",
    "href": "seminario1/artigo2.html#considerações-finais-e-sugestões-para-futuras-pesquisas",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "3.2 Considerações Finais e Sugestões para Futuras Pesquisas",
    "text": "3.2 Considerações Finais e Sugestões para Futuras Pesquisas\nPossíveis abordagens de pesquisas futuras podem incluir o uso de outras funções de abstração temporal (além da SAX, utilizada no artigo), a aplicação de técnicas e heurísticas de otimização global na criação dos agrupamentos locais e o estudo de adaptações do algoritmo para séries temporais multivariadas, isto é, para a geração de agrupamentos multidimensionais."
  },
  {
    "objectID": "seminario1/artigo2.html#instalação",
    "href": "seminario1/artigo2.html#instalação",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.1 Instalação",
    "text": "5.1 Instalação\nPara utilizar o Z-Grouping, é necessário ter instaladas as extensões numba, numpy, pyts e o Python em sua versão 3.7 ou superior. Devido às dependências utilizadas, recomenda-se a utilização do Python 3.8 ou superior para evitar conflitos de versão.\nPara instalar o Python 3.8, siga os passos abaixo:\n\nInstale as dependências necessárias:\n\nsudo apt-get install libsqlite3-dev ## (ou sqlite-devel dependendo do SO). \ncd /opt/ \nsudo wget https://www.python.org/ftp/python/3.8.3/Python-3.8.3.tgz \nsudo tar -xzf Python-3.8.3.tgz \ncd Python-3.8.3 \nsudo ./configure --enable-optimizations --enable-loadable-sqlite-extensions \nsudo make altinstall \n\nAtive o ambiente com Python 3.8:\n\npython3.8 -m venv ./.venv \nsource .venv/bin/activate \npip install --upgrade pip \npip install numba numpy==1.19.5 pyts matplotlib==3.3.1 \n\nPor fim, para instalar o Z-Grouping, siga estas instruções:\n\ngit clone https://github.com/zedshape/zgrouping.git \ncd zgrouping \nCertifique-se de seguir esses passos com atenção para garantir uma instalação bem-sucedida do Z-Grouping em seu ambiente de desenvolvimento."
  },
  {
    "objectID": "seminario1/artigo2.html#utilização-do-algoritmo-z-grouping",
    "href": "seminario1/artigo2.html#utilização-do-algoritmo-z-grouping",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.2 Utilização do Algoritmo Z-Grouping",
    "text": "5.2 Utilização do Algoritmo Z-Grouping\nO algoritmo pode ser facilmente executado importando o método createGroupings do repositório fornecido:\nfrom zgrouping.syntheticGenerator import createSyntheticData \nEle recebe os seguintes parâmetros: * matrices: matriz de labels de evento. Essa matriz pode ser gerada utilizando o método utils.createChannel sobre as séries temporais de entrada. * alpha: o limiar de pureza. * debug: opções de print e debug. * accept: habilita a função de validação da qualidade dos agrupamentos."
  },
  {
    "objectID": "seminario1/artigo2.html#datasets",
    "href": "seminario1/artigo2.html#datasets",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.3 Datasets",
    "text": "5.3 Datasets\nO repositório do Z-Grouping já contém bases de dados para teste e avaliação do algoritmo, localizadas na pasta datasets. Algumas das bases de dados incluem: * Covid-19: Base de dados referente ao continente do país, país e contagem de casos de covid no país de 22/01/2020 até 30/09/2021. * Stocks: Base de dados de ações contendo informações como data do registro, valor de abertura do dia, maior valor no dia, menor valor no dia, volume e TAG (nome) da ação.\nAlém disso, o repositório inclui um gerador de bases de dados sintéticas, que cria padrões entre séries temporais. Este gerador pode ser utilizado importando o método createSyntheticData do repositório:\nfrom zgrouping.syntheticGenerator import createSyntheticData\nO método syntheticGenerator.createSyntheticData requer os seguintes argumentos: * c: Número de agrupamentos globais. * tc: Número de membros da instância por agrupamento. * tl: Tamanho de cada série temporal. * no_outliers: Número de outliers. * outlier_size: Tamanho do outlier. * amp: Amplitude. * lineranges: Comprimento de linhas retas. * lineheights: Altura das linhas retas.\nEsses datasets sintéticos podem ser utilizados como substitutos para os datasets reais mencionados anteriormente. No entanto, ainda é necessário passar essas bases pelo método de criação de canais, que é o dado de entrada para o algoritmo de agrupamento."
  },
  {
    "objectID": "seminario1/artigo2.html#exemplo-de-uso",
    "href": "seminario1/artigo2.html#exemplo-de-uso",
    "title": "Artigo 2: Finding Local Groupings of Time Series",
    "section": "5.4 Exemplo de Uso",
    "text": "5.4 Exemplo de Uso\nPara ilustrar o uso do Z-Grouping, apresentamos a seguir um exemplo prático de execução do algoritmo. Os passos a seguir demonstram como gerar dados sintéticos, aplicar transformações e finalmente executar o Z-Grouping para obter os agrupamentos desejados.\nApós a geração e transformação dos dados, será obtida uma matriz com padrões simbólicos, representando séries temporais. A seguir, é apresentado um exemplo dos dados antes e depois da transformação.\n\n\nCode\nfrom zgrouping.zgrouping import grouping, syntheticGenerator, utils \nimport matplotlib.pyplot as plt \n\n# Synthetic generator \ntc = 50 \ntl = 365 \nc = 20 \nno_outliers = 10 \noutlier_size = 10 \n\n# Grouping generation \nn_bins = 5 \nalpha = 0.9 \neta = 1.5 \n\nX_raw, y = syntheticGenerator.createSyntheticData(tc=tc, tl=tl, c=c, no_outliers=no_outliers, outlier_size=outlier_size) \n\n# Normalização e Transformação \nX = utils.znorm(X_raw)  \nX_sax = utils.SAXify(X, n_bins=5) \n\n# Visualização dos dados \nplt.plot(X_raw[150], label='antes') \nplt.plot(X_sax[150], label='depois')\nplt.title('Dados sintéticos antes e depois da transformação')\nplt.legend()\nplt.show()\nprint(X_sax[150]) \n\n\n\n\n\n\n\n\n\n[2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4\n 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3\n 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2\n 2 2 2 2 2 2 3 3 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 4 3 3\n 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 4 1 1 1 1 1 1 1 1 1 2 1 2 2 2]\n\n\nApós a preparação dos dados, eles serão utilizados como entrada para a criação dos canais do Z-Grouping. A matriz resultante deve ter dimensões \\(S \\times T\\), onde \\(S\\) é o número de séries temporais e \\(T\\) é o tamanho de cada série temporal. Isso significa que cada linha da matriz representa uma série temporal e cada coluna representa o valor daquela série temporal em um determinado tempo.\n\n\nCode\nmatrices = utils.createChannels(X_sax)\n\n\nCom os canais devidamente criados, será utilizado o Z-Grouping para obter os agrupamentos desejados. O código a seguir demonstra como executar o algoritmo e obter os agrupamentos:\n\n\nCode\ngroupings, associations = grouping.createGroupings(matrices, alpha=alpha, accept=False, debug=True) \n\n\n[DEBUG] BEGIN Local grouping generation\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 44.951890109000004\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 36.923591759\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 26.490854166999995\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 36.19687330400001\n[DEBUG] Generating local grouping candidates from one event label channel - time taken: 29.767859024000018\n[DEBUG] BEGIN Association generation\n\n\nA variável groupings resultante é uma lista de objetos, onde cada objeto representa um agrupamento detectado. Cada agrupamento contém dois campos importantes: * members: um vetor de booleanos indicando se uma série temporal pertence ou não a esse agrupamento, funcionando como uma máscara. * range: o intervalo de tempo no qual o padrão se repete entre as séries temporais.\nAgora, para melhor visualização dos resultados, foi feita uma função que desenha os gráficos de algumas das séries temporais pertencentes a um determinado agrupamento e destaca o padrão detectado.\n::: {#409c2256 .cell execution_count=9} ``` {.python .cell-code} import random\ndef print_3_examples(data, grouping, number_prints): mask = [(index, value) for (index, value) in enumerate(grouping[‘members’])] members = list(filter(lambda tuple : tuple[1], mask))\nrandIndexList = [random.randint(0, len(members) -1) for i in range(number_prints)] \nchoosedMembers = [members[index][0] for index in randIndexList] \n\ninterval = grouping['range'][0:number_prints] \n\nfig, axs = plt.subplots(nrows=number_prints, ncols=1) \nfig.set_figheight(15) \ni = 0 \nfor ax, i in zip(axs, choosedMembers): \n    thisData = data[i] \n    patternData = list(filter(lambda tuple: interval[0] &lt;= tuple[0] &lt;= interval[1], enumerate(thisData))) \n    patternX = [pattern[0] for pattern in patternData] \n    patternY = [pattern[1] for pattern in patternData] \n    ax.plot(thisData) \n    ax.plot(patternX, patternY, 'r') \n    i += 1 \n\nplt.subplots_adjust(hspace=0.0) \nplt.show() \n\nprint(choosedMembers) \nprint_3_examples(X_raw,groupings[13], 6) ```\n::: {.cell-output .cell-output-display}  :::\n::: {.cell-output .cell-output-stdout} [602, 801, 702, 230, 437, 916] ::: :::"
  }
]